/Users/tegan/Documents/GitHub/prosocial_marl/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020
  warnings.warn(
2025-05-29 16:34:46,732	INFO worker.py:1888 -- Started a local Ray instance.
2025-05-29 16:34:49,432	WARNING deprecation.py:50 -- DeprecationWarning: `build` has been deprecated. Use `AlgorithmConfig.build_algo` instead. This will raise an error in the future!
2025-05-29 16:34:49,433	WARNING algorithm_config.py:4968 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html
2025-05-29 16:34:49,434	WARNING algorithm_config.py:4997 -- You configured a custom `model` config (probably through calling config.training(model=..), whereas your config uses the new API stack! In order to switch off the new API stack, set in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. If you DO want to use the new API stack, configure your model, instead, through: `config.rl_module(model_config={..})`.
/Users/tegan/Documents/GitHub/prosocial_marl/venv/lib/python3.9/site-packages/ray/rllib/algorithms/algorithm.py:521: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
`UnifiedLogger` will be removed in Ray 2.7.
  return UnifiedLogger(config, logdir, loggers=None)
/Users/tegan/Documents/GitHub/prosocial_marl/venv/lib/python3.9/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/Users/tegan/Documents/GitHub/prosocial_marl/venv/lib/python3.9/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/Users/tegan/Documents/GitHub/prosocial_marl/venv/lib/python3.9/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
[36m(MultiAgentEnvRunner pid=22691)[0m 2025-05-29 16:34:55,187	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!
2025-05-29 16:34:55,506	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!
2025-05-29 16:34:55,520	WARNING algorithm_config.py:4997 -- You configured a custom `model` config (probably through calling config.training(model=..), whereas your config uses the new API stack! In order to switch off the new API stack, set in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. If you DO want to use the new API stack, configure your model, instead, through: `config.rl_module(model_config={..})`.
2025-05-29 16:34:56,379	WARNING util.py:61 -- Install gputil for GPU system monitoring.
PettingZoo environment registered with RLlib.
DEBUG: Agent 0 observation space: Box(-inf, inf, (18,), float32)
DEBUG: Agent 0 action space: Discrete(5)
DEBUG: Agent 0 action space shape: ()
RLlib PPO configuration created.
Initializing RLlib PPO trainer...
Starting RLlib training...
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 1, Result: {'timers': {'training_iteration': 1.8316707080000008, 'restore_env_runners': 8.000000001118224e-06, 'training_step': 1.8315625830000002, 'env_runner_sampling_timer': 1.139211416000002, 'learner_update_timer': 0.6903027500000007, 'synch_weights': 0.0010078749999991032}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -25.757019944103785, 'agent_0': -25.656186610770455, 'agent_1': -25.800769944103784}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(31.37149435396863), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 710, 'agent_0': 682}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.07661973725870071), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.204600707760354e-07), 'module_to_agent_unmapping': np.float64(2.1560966487604307e-06), 'get_actions': np.float64(0.00027230182577872087), 'normalize_and_clip_actions': np.float64(1.775102969036855e-05), 'tensor_to_numpy': np.float64(2.90390655338889e-05), 'un_batch_to_individual_items': np.float64(1.1610675673471731e-05), 'listify_data_for_vector_env': np.float64(5.344930559333227e-06)}}, 'connector_pipeline_timer': np.float64(0.0003791962961272724)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 710, 'agent_0': 682, 'agent_1': 710}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 2048, 'episode_return_mean': -77.21397649897803, 'env_to_module_sum_episodes_length_out': np.float64(31.37149435396863), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -149.87891296945975, 'weights_seq_no': 0.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(8.050224093686045e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.8540715513034065e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4697690391462352e-05), 'numpy_to_tensor': np.float64(1.3243046935850606e-05), 'add_states_from_episodes_to_batch': np.float64(3.049880236568738e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.289772036353595e-06), 'batch_individual_items': np.float64(8.733517210028331e-06)}}}, 'episode_return_max': -48.84347597498223, 'episode_duration_sec_mean': 0.03718521702000026, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.005013123668031649), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.472325127758076e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 2102}, 'module_episode_returns_mean': {'shared_policy': -39.264410994739016}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(0.00011228487976889414), 'num_episodes_lifetime': 27, 'num_env_steps_sampled_lifetime_throughput': nan}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(1.0664567), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0042233663), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(0.027259171), 'total_loss': np.float32(7.6367145), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 1.0, 'policy_loss': np.float32(0.0036983646), 'vf_loss_unclipped': np.float32(77.26577), 'curr_kl_coeff': 0.10000000149011612, 'entropy': np.float32(1.5997744), 'num_module_steps_trained_lifetime': 21760, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(7.6481695), 'num_trainable_parameters': 142854, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.02787100000000109, 'add_one_ts_to_episodes_and_truncate': 0.0074748329999998475, 'agent_to_module_mapping': 0.0018580410000019754, 'add_observations_from_episodes_to_batch': 0.0008099580000013873, 'add_states_from_episodes_to_batch': 5.750000003246214e-06, 'numpy_to_tensor': 0.0003685000000004379, 'batch_individual_items': 0.01808233299999884, 'add_time_dim_to_batch_and_zero_pad': 1.4499999998918156e-05, 'general_advantage_estimation': 0.009155916999997515}}, 'connector_pipeline_timer': 0.0658520419999995}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048, 'num_module_steps_trained_lifetime': 21760, 'num_env_steps_trained_lifetime': 348160, 'num_trainable_parameters': 142854, 'num_non_trainable_parameters': 0, 'learner_connector_sum_episodes_length_in': 2048, 'num_env_steps_trained_lifetime_throughput': nan}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 2048, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': nan, 'done': False, 'training_iteration': 1, 'trial_id': 'default', 'date': '2025-05-29_16-34-58', 'timestamp': 1748529298, 'time_this_iter_s': 1.835256814956665, 'time_total_s': 1.835256814956665, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 1.835256814956665, 'iterations_since_restore': 1, 'perf': {'cpu_util_percent': np.float64(20.099999999999998), 'ram_util_percent': np.float64(82.36666666666666)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 2, Result: {'timers': {'training_iteration': 1.8322154942500006, 'restore_env_runners': 8.0050000011056e-06, 'training_step': 1.8321069542600001, 'env_runner_sampling_timer': 1.140177918510002, 'learner_update_timer': 0.6898804433400006, 'synch_weights': 0.0010083041699990858, 'synch_env_connectors': 0.00085820800000036}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -27.867888476892276, 'agent_0': -27.811638476892277, 'agent_1': -28.100388476892277}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(31.540666754008832), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 709, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.07645381020004777), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.280903660046357e-07), 'module_to_agent_unmapping': np.float64(2.168611646550524e-06), 'get_actions': np.float64(0.0002428956285291988), 'normalize_and_clip_actions': np.float64(1.748232393720871e-05), 'tensor_to_numpy': np.float64(2.8746765753312758e-05), 'un_batch_to_individual_items': np.float64(1.1686293193265606e-05), 'listify_data_for_vector_env': np.float64(5.3749667850959005e-06)}}, 'connector_pipeline_timer': np.float64(0.0003494801901628319)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 1419, 'agent_0': 1365, 'agent_1': 1420}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 4096, 'episode_return_mean': -83.77991543067682, 'env_to_module_sum_episodes_length_out': np.float64(31.540666754008832), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -149.87891296945975, 'weights_seq_no': 1.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(8.121012305220971e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.8593943408235548e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4842556131486428e-05), 'numpy_to_tensor': np.float64(1.3475342137428612e-05), 'add_states_from_episodes_to_batch': np.float64(3.0657858912978457e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.356329273117671e-06), 'batch_individual_items': np.float64(8.837069506847438e-06)}}}, 'episode_return_max': -39.76468952359625, 'episode_duration_sec_mean': 0.03977242480750003, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.005994738344814463), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.580074288185111e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 4204}, 'module_episode_returns_mean': {'shared_policy': -41.84939317237746}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(0.00010440329722670383), 'num_episodes_lifetime': 54, 'num_env_steps_sampled_lifetime_throughput': 1078.732931633627}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(3.475257), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0041972543), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(-0.03654194), 'total_loss': np.float32(7.5204096), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 2.0, 'policy_loss': np.float32(0.01634287), 'vf_loss_unclipped': np.float32(96.46834), 'curr_kl_coeff': 0.05000000074505806, 'entropy': np.float32(1.5974281), 'num_module_steps_trained_lifetime': 43520, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(7.519622), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.02787111430830109, 'add_one_ts_to_episodes_and_truncate': 0.007474790812599848, 'agent_to_module_mapping': 0.0018580452709019751, 'add_observations_from_episodes_to_batch': 0.0008099593833013873, 'add_states_from_episodes_to_batch': 5.749895803245763e-06, 'numpy_to_tensor': 0.00036847503750043803, 'batch_individual_items': 0.01808243877509884, 'add_time_dim_to_batch_and_zero_pad': 1.4500158398918117e-05, 'general_advantage_estimation': 0.009155477712497515}}, 'connector_pipeline_timer': 0.06585175412909951}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 43520, 'num_env_steps_trained_lifetime': 696320, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 4096, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1078.732931633627, 'done': False, 'training_iteration': 2, 'trial_id': 'default', 'date': '2025-05-29_16-35-00', 'timestamp': 1748529300, 'time_this_iter_s': 1.8899059295654297, 'time_total_s': 3.7251627445220947, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 3.7251627445220947, 'iterations_since_restore': 2, 'perf': {'cpu_util_percent': np.float64(36.7), 'ram_util_percent': np.float64(82.6)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 3, Result: {'timers': {'training_iteration': 1.8317188005575005, 'restore_env_runners': 7.997030001089911e-06, 'training_step': 1.8316098809674002, 'env_runner_sampling_timer': 1.140181192244902, 'learner_update_timer': 0.6893800084866006, 'synch_weights': 0.0010080686282991013, 'synch_env_connectors': 0.0008596059200003481}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -25.71405971372728, 'agent_0': -25.66030971372728, 'agent_1': -25.49280971372728}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(31.660608001599826), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 709, 'agent_2': 710, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.07613011471582286), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.257339567313532e-07), 'module_to_agent_unmapping': np.float64(2.159750266136889e-06), 'get_actions': np.float64(0.00021655461796404128), 'normalize_and_clip_actions': np.float64(1.707225498305009e-05), 'tensor_to_numpy': np.float64(2.823766267490261e-05), 'un_batch_to_individual_items': np.float64(1.1634500476633193e-05), 'listify_data_for_vector_env': np.float64(5.346573045190559e-06)}}, 'connector_pipeline_timer': np.float64(0.0003219479128992706)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 2129, 'agent_0': 2048, 'agent_1': 2129}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 6144, 'episode_return_mean': -76.86717914118182, 'env_to_module_sum_episodes_length_out': np.float64(31.660608001599826), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -132.34738930705882, 'weights_seq_no': 2.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(8.091871461098379e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.8359106961556945e-06), 'add_observations_from_episodes_to_batch': np.float64(1.480158080342002e-05), 'numpy_to_tensor': np.float64(1.3417361725282711e-05), 'add_states_from_episodes_to_batch': np.float64(3.058562395498012e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.348046161494187e-06), 'batch_individual_items': np.float64(8.796422031959239e-06)}}}, 'episode_return_max': -50.22661330037247, 'episode_duration_sec_mean': 0.036836099915000024, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.0076160400694973), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.567859300647532e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 6306}, 'module_episode_returns_mean': {'shared_policy': -37.19204227454671}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(9.66405198878774e-05), 'num_episodes_lifetime': 81, 'num_env_steps_sampled_lifetime_throughput': 1141.294443909427}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(2.9536567), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.002986264), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(-0.0009020567), 'total_loss': np.float32(6.524319), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 3.0, 'policy_loss': np.float32(-0.141081), 'vf_loss_unclipped': np.float32(69.9007), 'curr_kl_coeff': 0.02500000037252903, 'entropy': np.float32(1.5914832), 'num_module_steps_trained_lifetime': 65280, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.6811657), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027871264442935088, 'add_one_ts_to_episodes_and_truncate': 0.007474698677247847, 'agent_to_module_mapping': 0.0018580515480839746, 'add_observations_from_episodes_to_batch': 0.0008099601015353872, 'add_states_from_episodes_to_batch': 5.749656187244958e-06, 'numpy_to_tensor': 0.0003684249909504381, 'batch_individual_items': 0.01808255121389684, 'add_time_dim_to_batch_and_zero_pad': 1.4500626130918e-05, 'general_advantage_estimation': 0.009154552864947516}}, 'connector_pipeline_timer': 0.06585094114891751}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 65280, 'num_env_steps_trained_lifetime': 1044480, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 6144, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1141.294443909427, 'done': False, 'training_iteration': 3, 'trial_id': 'default', 'date': '2025-05-29_16-35-01', 'timestamp': 1748529301, 'time_this_iter_s': 1.7861969470977783, 'time_total_s': 5.511359691619873, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 5.511359691619873, 'iterations_since_restore': 3, 'perf': {'cpu_util_percent': np.float64(32.4), 'ram_util_percent': np.float64(82.35)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 4, Result: {'timers': {'training_iteration': 1.8309724404719254, 'restore_env_runners': 7.992469701101214e-06, 'training_step': 1.8308631738277261, 'env_runner_sampling_timer': 1.140025981992453, 'learner_update_timer': 0.6887884184017345, 'synch_weights': 0.0010071446120161205, 'synch_env_connectors': 0.0008605761108003506}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -23.976708433182374, 'agent_0': -24.131708433182375, 'agent_1': -24.226708433182374}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(31.74369293616304), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 711, 'agent_2': 711, 'agent_0': 682}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.07564623575119696), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.221917048323366e-07), 'module_to_agent_unmapping': np.float64(2.1467405441091633e-06), 'get_actions': np.float64(0.00019381600393704904), 'normalize_and_clip_actions': np.float64(1.6684483097597128e-05), 'tensor_to_numpy': np.float64(2.772523983297463e-05), 'un_batch_to_individual_items': np.float64(1.1564545540670075e-05), 'listify_data_for_vector_env': np.float64(5.313531533746956e-06)}}, 'connector_pipeline_timer': np.float64(0.0002979511053289448)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 2840, 'agent_0': 2730, 'agent_1': 2840}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 8192, 'episode_return_mean': -72.33512529954709, 'env_to_module_sum_episodes_length_out': np.float64(31.74369293616304), 'num_module_steps_sampled': {'shared_policy': 2104}, 'episode_return_min': -142.06138902750172, 'weights_seq_no': 3.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(8.04812874168811e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.809908485847946e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4728491104880067e-05), 'numpy_to_tensor': np.float64(1.331063459102567e-05), 'add_states_from_episodes_to_batch': np.float64(3.054913253041242e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.3212364975469105e-06), 'batch_individual_items': np.float64(8.733070397889696e-06)}}}, 'episode_return_max': -43.675431271793855, 'episode_duration_sec_mean': 0.036034403019999994, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.009661063973217119), 'episode_len_mean': 75.0, 'num_episodes': 28, 'env_step_timer': np.float64(7.534156570804781e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 8410}, 'module_episode_returns_mean': {'shared_policy': -38.354660923450496}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(8.980490692262547e-05), 'num_episodes_lifetime': 109, 'num_env_steps_sampled_lifetime_throughput': 1157.5805513575742}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(1.7165836), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0031374255), 'num_module_steps_trained': 21888, 'vf_explained_var': np.float32(-0.070376515), 'total_loss': np.float32(7.194177), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 4.0, 'policy_loss': np.float32(-0.0022230307), 'vf_loss_unclipped': np.float32(54.098083), 'curr_kl_coeff': 0.012500000186264515, 'entropy': np.float32(1.5955274), 'num_module_steps_trained_lifetime': 87168, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(7.2122774), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027871562946745577, 'add_one_ts_to_episodes_and_truncate': 0.007474583130521627, 'agent_to_module_mapping': 0.0018580611035952442, 'add_observations_from_episodes_to_batch': 0.000809963784466377, 'add_states_from_episodes_to_batch': 5.7492672739838545e-06, 'numpy_to_tensor': 0.0003683493811276881, 'batch_individual_items': 0.01808269828504137, 'add_time_dim_to_batch_and_zero_pad': 1.450117619243801e-05, 'general_advantage_estimation': 0.009153163179077268}}, 'connector_pipeline_timer': 0.06584979344872624}, 'num_module_steps_trained': 21888, 'num_env_steps_trained': 350208, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 87168, 'num_env_steps_trained_lifetime': 1394688, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 8192, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1157.5805513575742, 'done': False, 'training_iteration': 4, 'trial_id': 'default', 'date': '2025-05-29_16-35-03', 'timestamp': 1748529303, 'time_this_iter_s': 1.7607166767120361, 'time_total_s': 7.272076368331909, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 7.272076368331909, 'iterations_since_restore': 4, 'perf': {'cpu_util_percent': np.float64(24.833333333333332), 'ram_util_percent': np.float64(82.26666666666667)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 5, Result: {'timers': {'training_iteration': 1.8302505877372062, 'restore_env_runners': 7.980455004095814e-06, 'training_step': 1.830141045839449, 'env_runner_sampling_timer': 1.1399041284225284, 'learner_update_timer': 0.6881883196377173, 'synch_weights': 0.001006083575895947, 'synch_env_connectors': 0.0008613932696923599}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -25.88169466056502, 'agent_0': -25.85419466056502, 'agent_1': -25.901694660565028}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(31.855669003544737), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 709, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.07504138844685958), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.192698446005882e-07), 'module_to_agent_unmapping': np.float64(2.137580167636095e-06), 'get_actions': np.float64(0.00017448797207496092), 'normalize_and_clip_actions': np.float64(1.6362902304880478e-05), 'tensor_to_numpy': np.float64(2.72991480385454e-05), 'un_batch_to_individual_items': np.float64(1.1512646111758586e-05), 'listify_data_for_vector_env': np.float64(5.288194734614471e-06)}}, 'connector_pipeline_timer': np.float64(0.00027760292191055067)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 3549, 'agent_0': 3413, 'agent_1': 3550}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 10240, 'episode_return_mean': -77.63758398169506, 'env_to_module_sum_episodes_length_out': np.float64(31.855669003544737), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -151.85980075328592, 'weights_seq_no': 4.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(8.012505974531766e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7889057136145406e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4668901665790826e-05), 'numpy_to_tensor': np.float64(1.3228162342390623e-05), 'add_states_from_episodes_to_batch': np.float64(3.0473289823519506e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.298581344418749e-06), 'batch_individual_items': np.float64(8.679689585183272e-06)}}}, 'episode_return_max': -40.08414685629581, 'episode_duration_sec_mean': 0.036080784485000114, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.011959592795980124), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.508134385959892e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 10512}, 'module_episode_returns_mean': {'shared_policy': -37.71056084694834}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(8.398393067685509e-05), 'num_episodes_lifetime': 136, 'num_env_steps_sampled_lifetime_throughput': 1156.5672021263515}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(1.3764132), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0029516574), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(-0.033259034), 'total_loss': np.float32(7.137546), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 5.0, 'policy_loss': np.float32(0.21561374), 'vf_loss_unclipped': np.float32(128.88304), 'curr_kl_coeff': 0.0062500000931322575, 'entropy': np.float32(1.5928938), 'num_module_steps_trained_lifetime': 108928, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.9378242), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027871873345635564, 'add_one_ts_to_episodes_and_truncate': 0.007474411045662206, 'agent_to_module_mapping': 0.00185806781284148, 'add_observations_from_episodes_to_batch': 0.0008099656394285934, 'add_states_from_episodes_to_batch': 5.748715273369287e-06, 'numpy_to_tensor': 0.0003682478160022978, 'batch_individual_items': 0.01808283271794162, 'add_time_dim_to_batch_and_zero_pad': 1.450149859011462e-05, 'general_advantage_estimation': 0.009151319885837927}}, 'connector_pipeline_timer': 0.0658480922667239}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 108928, 'num_env_steps_trained_lifetime': 1742848, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 10240, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1156.5672021263515, 'done': False, 'training_iteration': 5, 'trial_id': 'default', 'date': '2025-05-29_16-35-05', 'timestamp': 1748529305, 'time_this_iter_s': 1.7624320983886719, 'time_total_s': 9.034508466720581, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 9.034508466720581, 'iterations_since_restore': 5, 'perf': {'cpu_util_percent': np.float64(22.4), 'ram_util_percent': np.float64(82.15)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 6, Result: {'timers': {'training_iteration': 1.8308009985298341, 'restore_env_runners': 7.99274045407161e-06, 'training_step': 1.8306904262110544, 'env_runner_sampling_timer': 1.1398065042183032, 'learner_update_timer': 0.6888265910313401, 'synch_weights': 0.001011373580136991, 'synch_env_connectors': 0.0008620864169954213}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -25.455537771717268, 'agent_0': -25.61428777171727, 'agent_1': -25.370537771717267}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(31.9349168879732), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 709, 'agent_2': 710, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.0743579283494295), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.170443212384345e-07), 'module_to_agent_unmapping': np.float64(2.1322208285285213e-06), 'get_actions': np.float64(0.0001580302835932833), 'normalize_and_clip_actions': np.float64(1.6092078681982927e-05), 'tensor_to_numpy': np.float64(2.6936199667805663e-05), 'un_batch_to_individual_items': np.float64(1.1472276506700618e-05), 'listify_data_for_vector_env': np.float64(5.268175577000281e-06)}}, 'connector_pipeline_timer': np.float64(0.0002602879488291751)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 4259, 'agent_0': 4096, 'agent_1': 4259}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 12288, 'episode_return_mean': -76.44036331515179, 'env_to_module_sum_episodes_length_out': np.float64(31.9349168879732), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -129.76328632339755, 'weights_seq_no': 5.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.98345643734391e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7717765444303837e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4629209602164665e-05), 'numpy_to_tensor': np.float64(1.3152285003196198e-05), 'add_states_from_episodes_to_batch': np.float64(3.0398012012401797e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.2796815100952005e-06), 'batch_individual_items': np.float64(8.64242608218981e-06)}}}, 'episode_return_max': -38.094239507057544, 'episode_duration_sec_mean': 0.03600803033499982, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.014390808887765883), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.48797388964793e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 12614}, 'module_episode_returns_mean': {'shared_policy': -37.11211371860391}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(7.902975379110173e-05), 'num_episodes_lifetime': 163, 'num_env_steps_sampled_lifetime_throughput': 1078.7872913800265}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(2.731132), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0027128907), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(0.104987144), 'total_loss': np.float32(7.8087497), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0079365), 'weights_seq_no': 6.0, 'policy_loss': np.float32(0.16150051), 'vf_loss_unclipped': np.float32(81.69026), 'curr_kl_coeff': 0.0031250000465661287, 'entropy': np.float32(1.5853859), 'num_module_steps_trained_lifetime': 130688, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(7.663085), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027872376146953075, 'add_one_ts_to_episodes_and_truncate': 0.007474199765086922, 'agent_to_module_mapping': 0.0018580852692924319, 'add_observations_from_episodes_to_batch': 0.0008099829109131187, 'add_states_from_episodes_to_batch': 5.748053586039535e-06, 'numpy_to_tensor': 0.00036812234304130237, 'batch_individual_items': 0.01809439560895536, 'add_time_dim_to_batch_and_zero_pad': 1.4502097822218346e-05, 'general_advantage_estimation': 0.009149048512945467}}, 'connector_pipeline_timer': 0.06585754114151675}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 130688, 'num_env_steps_trained_lifetime': 2091008, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 12288, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1078.7872913800265, 'done': False, 'training_iteration': 6, 'trial_id': 'default', 'date': '2025-05-29_16-35-07', 'timestamp': 1748529307, 'time_this_iter_s': 1.8896281719207764, 'time_total_s': 10.924136638641357, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 10.924136638641357, 'iterations_since_restore': 6, 'perf': {'cpu_util_percent': np.float64(24.566666666666666), 'ram_util_percent': np.float64(82.23333333333333)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 7, Result: {'timers': {'training_iteration': 1.8313802702145359, 'restore_env_runners': 8.047813049545324e-06, 'training_step': 1.831268731118944, 'env_runner_sampling_timer': 1.1408126058361203, 'learner_update_timer': 0.6883974838710267, 'synch_weights': 0.0010114052643356217, 'synch_env_connectors': 0.0008659151428254414}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -26.14828521814341, 'agent_0': -26.09703521814341, 'agent_1': -25.94578521814341}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(31.974527280640977), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 711, 'agent_2': 711, 'agent_0': 682}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.07373724274306687), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.242728027293377e-07), 'module_to_agent_unmapping': np.float64(2.145194407138388e-06), 'get_actions': np.float64(0.00014545282645479863), 'normalize_and_clip_actions': np.float64(1.606586962301265e-05), 'tensor_to_numpy': np.float64(2.690322028572751e-05), 'un_batch_to_individual_items': np.float64(1.1547350940020401e-05), 'listify_data_for_vector_env': np.float64(5.282008496100536e-06)}}, 'connector_pipeline_timer': np.float64(0.0002479307323006849)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 4970, 'agent_0': 4778, 'agent_1': 4970}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 14336, 'episode_return_mean': -78.19110565443023, 'env_to_module_sum_episodes_length_out': np.float64(31.974527280640977), 'num_module_steps_sampled': {'shared_policy': 2104}, 'episode_return_min': -137.4767354728922, 'weights_seq_no': 6.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(8.049000160526414e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.787150981269545e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4761086126159838e-05), 'numpy_to_tensor': np.float64(1.3349637479418927e-05), 'add_states_from_episodes_to_batch': np.float64(3.054449364790068e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.335504230655921e-06), 'batch_individual_items': np.float64(8.735798143771754e-06)}}}, 'episode_return_max': -39.24309388630442, 'episode_duration_sec_mean': 0.039462292962500464, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.01705239665044267), 'episode_len_mean': 75.0, 'num_episodes': 28, 'env_step_timer': np.float64(7.577382914635563e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 14718}, 'module_episode_returns_mean': {'shared_policy': -38.400896145182166}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(7.591458420800652e-05), 'num_episodes_lifetime': 191, 'num_env_steps_sampled_lifetime_throughput': 1074.9915998172273}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(2.7127516), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0039768484), 'num_module_steps_trained': 21888, 'vf_explained_var': np.float32(-0.07477617), 'total_loss': np.float32(7.458618), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 7.0, 'policy_loss': np.float32(0.015436914), 'vf_loss_unclipped': np.float32(75.41439), 'curr_kl_coeff': 0.0015625000232830644, 'entropy': np.float32(1.5874726), 'num_module_steps_trained_lifetime': 152576, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(7.459044), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027872945850809672, 'add_one_ts_to_episodes_and_truncate': 0.007473958148118577, 'agent_to_module_mapping': 0.0018581013073330804, 'add_observations_from_episodes_to_batch': 0.0008100041279040106, 'add_states_from_episodes_to_batch': 5.747363560929113e-06, 'numpy_to_tensor': 0.00036797852555792686, 'batch_individual_items': 0.018105777925477032, 'add_time_dim_to_batch_and_zero_pad': 1.450369331982118e-05, 'general_advantage_estimation': 0.009146354252122272}}, 'connector_pipeline_timer': 0.06586639840048705}, 'num_module_steps_trained': 21888, 'num_env_steps_trained': 350208, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 152576, 'num_env_steps_trained_lifetime': 2441216, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 14336, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1074.9915998172273, 'done': False, 'training_iteration': 7, 'trial_id': 'default', 'date': '2025-05-29_16-35-09', 'timestamp': 1748529309, 'time_this_iter_s': 1.892404317855835, 'time_total_s': 12.816540956497192, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 12.816540956497192, 'iterations_since_restore': 7, 'perf': {'cpu_util_percent': np.float64(35.4), 'ram_util_percent': np.float64(82.76666666666667)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 8, Result: {'timers': {'training_iteration': 1.8308041258423904, 'restore_env_runners': 8.064424919054e-06, 'training_step': 1.8306922738077545, 'env_runner_sampling_timer': 1.1406867160277592, 'learner_update_timer': 0.6879467790323165, 'synch_weights': 0.0010104799616922654, 'synch_env_connectors': 0.0008666718213972172}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -26.412472670909132, 'agent_0': -26.49497267090913, 'agent_1': -26.387472670909133}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.038707679128535), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 709, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.07311757979328506), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.21522850252849e-07), 'module_to_agent_unmapping': np.float64(2.1384303586106417e-06), 'get_actions': np.float64(0.00013330646860678765), 'normalize_and_clip_actions': np.float64(1.583491812407183e-05), 'tensor_to_numpy': np.float64(2.6585567661041647e-05), 'un_batch_to_individual_items': np.float64(1.149594080302034e-05), 'listify_data_for_vector_env': np.float64(5.260163151656588e-06)}}, 'connector_pipeline_timer': np.float64(0.00023500287127597164)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 5679, 'agent_0': 5461, 'agent_1': 5680}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 16384, 'episode_return_mean': -79.29491801272738, 'env_to_module_sum_episodes_length_out': np.float64(32.038707679128535), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -137.4767354728922, 'weights_seq_no': 7.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(8.012153622862513e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7708854442220753e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4697770130129585e-05), 'numpy_to_tensor': np.float64(1.3257541333569295e-05), 'add_states_from_episodes_to_batch': np.float64(3.0479769111071137e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.313149428823665e-06), 'batch_individual_items': np.float64(8.684739299295357e-06)}}}, 'episode_return_max': -44.78118172318655, 'episode_duration_sec_mean': 0.036062063762500395, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.01966243115761377), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.544752929742067e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 16820}, 'module_episode_returns_mean': {'shared_policy': -39.54233543156527}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(7.217716377727103e-05), 'num_episodes_lifetime': 218, 'num_env_steps_sampled_lifetime_throughput': 1146.8280830926785}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(2.0964556), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0032853244), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(0.008222401), 'total_loss': np.float32(7.2672095), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 8.0, 'policy_loss': np.float32(0.11680995), 'vf_loss_unclipped': np.float32(93.37811), 'curr_kl_coeff': 0.0007812500116415322, 'entropy': np.float32(1.5854752), 'num_module_steps_trained_lifetime': 174336, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(7.1662483), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027873588597974442, 'add_one_ts_to_episodes_and_truncate': 0.007473682960213089, 'agent_to_module_mapping': 0.001858123532685987, 'add_observations_from_episodes_to_batch': 0.0008100261764639936, 'add_states_from_episodes_to_batch': 5.746533330962296e-06, 'numpy_to_tensor': 0.00036781309718991485, 'batch_individual_items': 0.018117043306107375, 'add_time_dim_to_batch_and_zero_pad': 1.4505094197689682e-05, 'general_advantage_estimation': 0.009143402825864247}}, 'connector_pipeline_timer': 0.06587489709346381}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 174336, 'num_env_steps_trained_lifetime': 2789376, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 16384, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1146.8280830926785, 'done': False, 'training_iteration': 8, 'trial_id': 'default', 'date': '2025-05-29_16-35-11', 'timestamp': 1748529311, 'time_this_iter_s': 1.777458906173706, 'time_total_s': 14.593999862670898, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 14.593999862670898, 'iterations_since_restore': 8, 'perf': {'cpu_util_percent': np.float64(24.35), 'ram_util_percent': np.float64(82.55)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 9, Result: {'timers': {'training_iteration': 1.8299790354239662, 'restore_env_runners': 8.063780669839116e-06, 'training_step': 1.8298668685696768, 'env_runner_sampling_timer': 1.1405318184574815, 'learner_update_timer': 0.6872755358219933, 'synch_weights': 0.001010192242075319, 'synch_env_connectors': 0.0008678405231832468}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -27.07344215125317, 'agent_0': -27.188442151253174, 'agent_1': -27.173442151253177}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.10642193729174), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 709, 'agent_2': 710, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.07246652544723989), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.193565983171534e-07), 'module_to_agent_unmapping': np.float64(2.1290951882343935e-06), 'get_actions': np.float64(0.00012291757693350545), 'normalize_and_clip_actions': np.float64(1.5625038450005644e-05), 'tensor_to_numpy': np.float64(2.6308522992144545e-05), 'un_batch_to_individual_items': np.float64(1.1448962104592993e-05), 'listify_data_for_vector_env': np.float64(5.239332234980382e-06)}}, 'connector_pipeline_timer': np.float64(0.00022390301802311112)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 6389, 'agent_0': 6144, 'agent_1': 6389}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 18432, 'episode_return_mean': -81.43532645375956, 'env_to_module_sum_episodes_length_out': np.float64(32.10642193729174), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -137.35058133909445, 'weights_seq_no': 8.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.979441690556431e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7569934927969417e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4640249433738179e-05), 'numpy_to_tensor': np.float64(1.3170515699111567e-05), 'add_states_from_episodes_to_batch': np.float64(3.0402952013017176e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.29075272493157e-06), 'batch_individual_items': np.float64(8.637441828993085e-06)}}}, 'episode_return_max': -44.82702956605327, 'episode_duration_sec_mean': 0.0359120345699999, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.022168674931387973), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.512790613642565e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 18922}, 'module_episode_returns_mean': {'shared_policy': -40.24982258509551}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(6.894795845211892e-05), 'num_episodes_lifetime': 245, 'num_env_steps_sampled_lifetime_throughput': 1163.1890698539962}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(1.6993053), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0036578453), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(0.038837492), 'total_loss': np.float32(7.999175), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 9.0, 'policy_loss': np.float32(0.10294683), 'vf_loss_unclipped': np.float32(94.22437), 'curr_kl_coeff': 0.0003906250058207661, 'entropy': np.float32(1.581154), 'num_module_steps_trained_lifetime': 196096, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(7.9120374), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027874297016410837, 'add_one_ts_to_episodes_and_truncate': 0.0074733782302509, 'agent_to_module_mapping': 0.0018581449326011018, 'add_observations_from_episodes_to_batch': 0.0008100496336399869, 'add_states_from_episodes_to_batch': 5.745553369239118e-06, 'numpy_to_tensor': 0.0003676237170367074, 'batch_individual_items': 0.018128112430532563, 'add_time_dim_to_batch_and_zero_pad': 1.4506179188668738e-05, 'general_advantage_estimation': 0.00914001098020617}}, 'connector_pipeline_timer': 0.06588276009774097}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 196096, 'num_env_steps_trained_lifetime': 3137536, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 18432, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1163.1890698539962, 'done': False, 'training_iteration': 9, 'trial_id': 'default', 'date': '2025-05-29_16-35-12', 'timestamp': 1748529312, 'time_this_iter_s': 1.7518579959869385, 'time_total_s': 16.345857858657837, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 16.345857858657837, 'iterations_since_restore': 9, 'perf': {'cpu_util_percent': np.float64(22.400000000000002), 'ram_util_percent': np.float64(82.66666666666667)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 10, Result: {'timers': {'training_iteration': 1.8301646234097266, 'restore_env_runners': 8.066062863180345e-06, 'training_step': 1.83005207655398, 'env_runner_sampling_timer': 1.1404153727729067, 'learner_update_timer': 0.6875747533837734, 'synch_weights': 0.0010100511496545345, 'synch_env_connectors': 0.0008680746179514366}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -27.86193271807939, 'agent_0': -27.848182718079393, 'agent_1': -27.971932718079394}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.130385776006676), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 711, 'agent_2': 711, 'agent_0': 682}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.07181076367792366), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.179126230095587e-07), 'module_to_agent_unmapping': np.float64(2.1225769629547593e-06), 'get_actions': np.float64(0.00011415759679988242), 'normalize_and_clip_actions': np.float64(1.5463449502252132e-05), 'tensor_to_numpy': np.float64(2.6096058705266125e-05), 'un_batch_to_individual_items': np.float64(1.1418782879423467e-05), 'listify_data_for_vector_env': np.float64(5.226698232100524e-06)}}, 'connector_pipeline_timer': np.float64(0.00021461527042396879)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 7100, 'agent_0': 6826, 'agent_1': 7100}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 20480, 'episode_return_mean': -83.68204815423816, 'env_to_module_sum_episodes_length_out': np.float64(32.130385776006676), 'num_module_steps_sampled': {'shared_policy': 2104}, 'episode_return_min': -119.26637407487573, 'weights_seq_no': 9.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.956966276249217e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.745616923564993e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4599465305655451e-05), 'numpy_to_tensor': np.float64(1.3101803799911666e-05), 'add_states_from_episodes_to_batch': np.float64(3.035861514432446e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.278445300110263e-06), 'batch_individual_items': np.float64(8.604392822658412e-06)}}}, 'episode_return_max': -50.1130103147016, 'episode_duration_sec_mean': 0.03610009142749968, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.024512801260002288), 'episode_len_mean': 75.0, 'num_episodes': 28, 'env_step_timer': np.float64(7.489776936412559e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 21026}, 'module_episode_returns_mean': {'shared_policy': -41.39173860202888}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(6.6196731841097e-05), 'num_episodes_lifetime': 273, 'num_env_steps_sampled_lifetime_throughput': 1100.8847104088204}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(1.6776576), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.003263825), 'num_module_steps_trained': 21888, 'vf_explained_var': np.float32(0.024146974), 'total_loss': np.float32(8.063486), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 10.0, 'policy_loss': np.float32(0.11621082), 'vf_loss_unclipped': np.float32(112.90767), 'curr_kl_coeff': 0.00019531250291038305, 'entropy': np.float32(1.583282), 'num_module_steps_trained_lifetime': 217984, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(7.963106), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027875080428418707, 'add_one_ts_to_episodes_and_truncate': 0.007473053951591934, 'agent_to_module_mapping': 0.0018581658546646456, 'add_observations_from_episodes_to_batch': 0.0008100740065548141, 'add_states_from_episodes_to_batch': 5.744401653417402e-06, 'numpy_to_tensor': 0.0003674112681768448, 'batch_individual_items': 0.018138994613938638, 'add_time_dim_to_batch_and_zero_pad': 1.4508079470409065e-05, 'general_advantage_estimation': 0.009136208656178669}}, 'connector_pipeline_timer': 0.06589004967302324}, 'num_module_steps_trained': 21888, 'num_env_steps_trained': 350208, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 217984, 'num_env_steps_trained_lifetime': 3487744, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 20480, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1100.8847104088204, 'done': False, 'training_iteration': 10, 'trial_id': 'default', 'date': '2025-05-29_16-35-14', 'timestamp': 1748529314, 'time_this_iter_s': 1.8522961139678955, 'time_total_s': 18.198153972625732, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 18.198153972625732, 'iterations_since_restore': 10, 'perf': {'cpu_util_percent': np.float64(21.0), 'ram_util_percent': np.float64(82.6)}}
Checkpoint saved at TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/tegan/ray_results/simple_spread_rllib), metrics={'timers': {'training_iteration': 1.8301646234097266, 'restore_env_runners': 8.066062863180345e-06, 'training_step': 1.83005207655398, 'env_runner_sampling_timer': 1.1404153727729067, 'learner_update_timer': 0.6875747533837734, 'synch_weights': 0.0010100511496545345, 'synch_env_connectors': 0.0008680746179514366}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -27.86193271807939, 'agent_0': -27.848182718079393, 'agent_1': -27.971932718079394}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.130385776006676), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 711, 'agent_2': 711, 'agent_0': 682}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.07181076367792366), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.179126230095587e-07), 'module_to_agent_unmapping': np.float64(2.1225769629547593e-06), 'get_actions': np.float64(0.00011415759679988242), 'normalize_and_clip_actions': np.float64(1.5463449502252132e-05), 'tensor_to_numpy': np.float64(2.6096058705266125e-05), 'un_batch_to_individual_items': np.float64(1.1418782879423467e-05), 'listify_data_for_vector_env': np.float64(5.226698232100524e-06)}}, 'connector_pipeline_timer': np.float64(0.00021461527042396879)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 7100, 'agent_0': 6826, 'agent_1': 7100}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 20480, 'episode_return_mean': -83.68204815423816, 'env_to_module_sum_episodes_length_out': np.float64(32.130385776006676), 'num_module_steps_sampled': {'shared_policy': 2104}, 'episode_return_min': -119.26637407487573, 'weights_seq_no': 9.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.956966276249217e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.745616923564993e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4599465305655451e-05), 'numpy_to_tensor': np.float64(1.3101803799911666e-05), 'add_states_from_episodes_to_batch': np.float64(3.035861514432446e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.278445300110263e-06), 'batch_individual_items': np.float64(8.604392822658412e-06)}}}, 'episode_return_max': -50.1130103147016, 'episode_duration_sec_mean': 0.03610009142749968, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.024512801260002288), 'episode_len_mean': 75.0, 'num_episodes': 28, 'env_step_timer': np.float64(7.489776936412559e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 21026}, 'module_episode_returns_mean': {'shared_policy': -41.39173860202888}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(6.6196731841097e-05), 'num_episodes_lifetime': 273, 'num_env_steps_sampled_lifetime_throughput': 1100.8847104088204}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(1.6776576), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.003263825), 'num_module_steps_trained': 21888, 'vf_explained_var': np.float32(0.024146974), 'total_loss': np.float32(8.063486), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 10.0, 'policy_loss': np.float32(0.11621082), 'vf_loss_unclipped': np.float32(112.90767), 'curr_kl_coeff': 0.00019531250291038305, 'entropy': np.float32(1.583282), 'num_module_steps_trained_lifetime': 217984, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(7.963106), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027875080428418707, 'add_one_ts_to_episodes_and_truncate': 0.007473053951591934, 'agent_to_module_mapping': 0.0018581658546646456, 'add_observations_from_episodes_to_batch': 0.0008100740065548141, 'add_states_from_episodes_to_batch': 5.744401653417402e-06, 'numpy_to_tensor': 0.0003674112681768448, 'batch_individual_items': 0.018138994613938638, 'add_time_dim_to_batch_and_zero_pad': 1.4508079470409065e-05, 'general_advantage_estimation': 0.009136208656178669}}, 'connector_pipeline_timer': 0.06589004967302324}, 'num_module_steps_trained': 21888, 'num_env_steps_trained': 350208, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 217984, 'num_env_steps_trained_lifetime': 3487744, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 20480, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1100.8847104088204, 'done': False, 'training_iteration': 10, 'trial_id': 'default', 'date': '2025-05-29_16-35-14', 'timestamp': 1748529314, 'time_this_iter_s': 1.8522961139678955, 'time_total_s': 18.198153972625732, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 18.198153972625732, 'iterations_since_restore': 10, 'perf': {'cpu_util_percent': np.float64(21.0), 'ram_util_percent': np.float64(82.6)}})
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 11, Result: {'timers': {'training_iteration': 1.8296134196756293, 'restore_env_runners': 8.089572234534512e-06, 'training_step': 1.8295004462084403, 'env_runner_sampling_timer': 1.1403614573751775, 'learner_update_timer': 0.6870765204299356, 'synch_weights': 0.0010095556381579684, 'synch_env_connectors': 0.0008700313717719236}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -25.007979866198692, 'agent_0': -25.070479866198692, 'agent_1': -25.092979866198693}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.15738517533313), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 709, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.07116485035816457), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.168052788205573e-07), 'module_to_agent_unmapping': np.float64(2.1175631932717613e-06), 'get_actions': np.float64(0.00010672425865576409), 'normalize_and_clip_actions': np.float64(1.533146284004492e-05), 'tensor_to_numpy': np.float64(2.591789440476254e-05), 'un_batch_to_individual_items': np.float64(1.1397084569368275e-05), 'listify_data_for_vector_env': np.float64(5.217355246843118e-06)}}, 'connector_pipeline_timer': np.float64(0.0002067623927770782)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 7809, 'agent_0': 7509, 'agent_1': 7810}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 22528, 'episode_return_mean': -75.17143959859604, 'env_to_module_sum_episodes_length_out': np.float64(32.15738517533313), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -126.56804979328865, 'weights_seq_no': 10.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.942160708263317e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7378971511278533e-06), 'add_observations_from_episodes_to_batch': np.float64(1.457807405709999e-05), 'numpy_to_tensor': np.float64(1.3058195794288374e-05), 'add_states_from_episodes_to_batch': np.float64(3.0329938733183964e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.2673876776453655e-06), 'batch_individual_items': np.float64(8.57847813967337e-06)}}}, 'episode_return_max': -47.941137747130256, 'episode_duration_sec_mean': 0.03603900361250029, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.026839664846356755), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.475902002647505e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 23128}, 'module_episode_returns_mean': {'shared_policy': -38.097143211847914}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(6.392168495393252e-05), 'num_episodes_lifetime': 300, 'num_env_steps_sampled_lifetime_throughput': 1137.3471914001666}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(0.9563317), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0035312327), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(0.024121404), 'total_loss': np.float32(7.9145412), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 11.0, 'policy_loss': np.float32(0.15498918), 'vf_loss_unclipped': np.float32(75.02761), 'curr_kl_coeff': 9.765625145519152e-05, 'entropy': np.float32(1.5797814), 'num_module_steps_trained_lifetime': 239744, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(7.775349), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.02787595206338478, 'add_one_ts_to_episodes_and_truncate': 0.007472677070683122, 'agent_to_module_mapping': 0.0018581881728936581, 'add_observations_from_episodes_to_batch': 0.0008100971370479807, 'add_states_from_episodes_to_batch': 5.743123416574835e-06, 'numpy_to_tensor': 0.00036717694752247604, 'batch_individual_items': 0.018149675104933538, 'add_time_dim_to_batch_and_zero_pad': 1.4509820328595562e-05, 'general_advantage_estimation': 0.009131988927533696}}, 'connector_pipeline_timer': 0.0658967236307901}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 239744, 'num_env_steps_trained_lifetime': 3835904, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 22528, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1137.3471914001666, 'done': False, 'training_iteration': 11, 'trial_id': 'default', 'date': '2025-05-29_16-35-16', 'timestamp': 1748529316, 'time_this_iter_s': 1.7787277698516846, 'time_total_s': 19.976881742477417, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 19.976881742477417, 'iterations_since_restore': 11, 'perf': {'cpu_util_percent': np.float64(32.50000000000001), 'ram_util_percent': np.float64(81.93333333333334)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 12, Result: {'timers': {'training_iteration': 1.828765450898873, 'restore_env_runners': 8.07950651218769e-06, 'training_step': 1.8286522692463558, 'env_runner_sampling_timer': 1.1402402811314258, 'learner_update_timer': 0.6863485377256362, 'synch_weights': 0.001009344661776337, 'synch_env_connectors': 0.0008710148080542689}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -24.586649352355916, 'agent_0': -24.476649352355917, 'agent_1': -24.661649352355916}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.20791309423565), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 709, 'agent_2': 710, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.07054862215980573), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.149260013365702e-07), 'module_to_agent_unmapping': np.float64(2.1132144228889344e-06), 'get_actions': np.float64(0.000100325588687854), 'normalize_and_clip_actions': np.float64(1.5213450135345939e-05), 'tensor_to_numpy': np.float64(2.5755889376233954e-05), 'un_batch_to_individual_items': np.float64(1.1372522769551122e-05), 'listify_data_for_vector_env': np.float64(5.207268890821018e-06)}}, 'connector_pipeline_timer': np.float64(0.00019996511987504612)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 8519, 'agent_0': 8192, 'agent_1': 8519}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 24576, 'episode_return_mean': -73.72494805706778, 'env_to_module_sum_episodes_length_out': np.float64(32.20791309423565), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -126.56804979328865, 'weights_seq_no': 11.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.923102414467447e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7294321582511428e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4543630259566988e-05), 'numpy_to_tensor': np.float64(1.3005493778456984e-05), 'add_states_from_episodes_to_batch': np.float64(3.0297813288575813e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.2538227751953825e-06), 'batch_individual_items': np.float64(8.551358037326371e-06)}}}, 'episode_return_max': -47.941137747130256, 'episode_duration_sec_mean': 0.0361608903900001, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.02897442007688642), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.45609254788354e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 25230}, 'module_episode_returns_mean': {'shared_policy': -35.82095341546864}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(6.1916876029905e-05), 'num_episodes_lifetime': 327, 'num_env_steps_sampled_lifetime_throughput': 1165.9056014806272}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(1.2100279), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0030583018), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(-0.07135868), 'total_loss': np.float32(6.5740066), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 12.0, 'policy_loss': np.float32(-0.056072928), 'vf_loss_unclipped': np.float32(66.143776), 'curr_kl_coeff': 4.882812572759576e-05, 'entropy': np.float32(1.570669), 'num_module_steps_trained_lifetime': 261504, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.6457853), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027876866365908685, 'add_one_ts_to_episodes_and_truncate': 0.007472243259497327, 'agent_to_module_mapping': 0.0018582109281726235, 'add_observations_from_episodes_to_batch': 0.0008101164725306284, 'add_states_from_episodes_to_batch': 5.74172970430411e-06, 'numpy_to_tensor': 0.0003669206096543765, 'batch_individual_items': 0.018160146619947144, 'add_time_dim_to_batch_and_zero_pad': 1.4511488061671275e-05, 'general_advantage_estimation': 0.009127376968396005}}, 'connector_pipeline_timer': 0.06590274713783432}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 261504, 'num_env_steps_trained_lifetime': 4184064, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 24576, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1165.9056014806272, 'done': False, 'training_iteration': 12, 'trial_id': 'default', 'date': '2025-05-29_16-35-18', 'timestamp': 1748529318, 'time_this_iter_s': 1.7483789920806885, 'time_total_s': 21.725260734558105, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 21.725260734558105, 'iterations_since_restore': 12, 'perf': {'cpu_util_percent': np.float64(23.266666666666666), 'ram_util_percent': np.float64(81.96666666666667)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 13, Result: {'timers': {'training_iteration': 1.8301594826398844, 'restore_env_runners': 8.069121447029584e-06, 'training_step': 1.8300460053038923, 'env_runner_sampling_timer': 1.1400687554001117, 'learner_update_timer': 0.6879130515183799, 'synch_weights': 0.001008954545158624, 'synch_env_connectors': 0.0008714521599737236}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -26.467996278077273, 'agent_0': -26.32049627807727, 'agent_1': -26.53299627807727}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.21600819530229), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 710, 'agent_0': 682}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06995887885224829), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.145002689977273e-07), 'module_to_agent_unmapping': np.float64(2.107711978613609e-06), 'get_actions': np.float64(9.48328882413134e-05), 'normalize_and_clip_actions': np.float64(1.5099930572025787e-05), 'tensor_to_numpy': np.float64(2.560620818812216e-05), 'un_batch_to_individual_items': np.float64(1.134688433776593e-05), 'listify_data_for_vector_env': np.float64(5.196385890304242e-06)}}, 'connector_pipeline_timer': np.float64(0.00019407938643936385)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 9229, 'agent_0': 8874, 'agent_1': 9229}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 26624, 'episode_return_mean': -79.32148883423186, 'env_to_module_sum_episodes_length_out': np.float64(32.21600819530229), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -150.14239471103517, 'weights_seq_no': 12.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.904117504005789e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7215107514335736e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4509450276166748e-05), 'numpy_to_tensor': np.float64(1.295453574077896e-05), 'add_states_from_episodes_to_batch': np.float64(3.025032626990997e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.2416837220137825e-06), 'batch_individual_items': np.float64(8.524128615370692e-06)}}}, 'episode_return_max': -36.9251757199654, 'episode_duration_sec_mean': 0.03595575504750011, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.030890981018144407), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.435741111138408e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 27332}, 'module_episode_returns_mean': {'shared_policy': -37.90055221751648}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(6.018625813853547e-05), 'num_episodes_lifetime': 354, 'num_env_steps_sampled_lifetime_throughput': 1034.3159006452051}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(1.4687996), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0035173849), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(0.03521079), 'total_loss': np.float32(6.9887495), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 13.0, 'policy_loss': np.float32(-0.114816226), 'vf_loss_unclipped': np.float32(77.829865), 'curr_kl_coeff': 2.441406286379788e-05, 'entropy': np.float32(1.5733917), 'num_module_steps_trained_lifetime': 283264, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(7.1193), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027877817487175775, 'add_one_ts_to_episodes_and_truncate': 0.00747177059432818, 'agent_to_module_mapping': 0.0018582342345287194, 'add_observations_from_episodes_to_batch': 0.0008101347740899188, 'add_states_from_episodes_to_batch': 5.740197853937174e-06, 'numpy_to_tensor': 0.00036664311834888656, 'batch_individual_items': 0.018190953562149986, 'add_time_dim_to_batch_and_zero_pad': 1.4512804758052948e-05, 'general_advantage_estimation': 0.009122357416148315}}, 'connector_pipeline_timer': 0.06592866557317457}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 283264, 'num_env_steps_trained_lifetime': 4532224, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 26624, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1034.3159006452051, 'done': False, 'training_iteration': 13, 'trial_id': 'default', 'date': '2025-05-29_16-35-20', 'timestamp': 1748529320, 'time_this_iter_s': 1.9717340469360352, 'time_total_s': 23.69699478149414, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 23.69699478149414, 'iterations_since_restore': 13, 'perf': {'cpu_util_percent': np.float64(21.4), 'ram_util_percent': np.float64(81.95)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 14, Result: {'timers': {'training_iteration': 1.8295103490634854, 'restore_env_runners': 8.05843023259572e-06, 'training_step': 1.8293965894208533, 'env_runner_sampling_timer': 1.1399750415961105, 'learner_update_timer': 0.6873556472531961, 'synch_weights': 0.001008918749707092, 'synch_env_connectors': 0.0008719855583739792}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -25.422931078047906, 'agent_0': -25.335431078047904, 'agent_1': -25.3391810780479}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.20842743729721), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 711, 'agent_2': 710, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06940002232888584), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.136105292409305e-07), 'module_to_agent_unmapping': np.float64(2.1043039310923104e-06), 'get_actions': np.float64(9.021627327240033e-05), 'normalize_and_clip_actions': np.float64(1.5016736234437459e-05), 'tensor_to_numpy': np.float64(2.5503555972261027e-05), 'un_batch_to_individual_items': np.float64(1.133252955928321e-05), 'listify_data_for_vector_env': np.float64(5.188736727073045e-06)}}, 'connector_pipeline_timer': np.float64(0.00018919599139274822)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 9939, 'agent_0': 9557, 'agent_1': 9940}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 28672, 'episode_return_mean': -76.0975432341437, 'env_to_module_sum_episodes_length_out': np.float64(32.20842743729721), 'num_module_steps_sampled': {'shared_policy': 2104}, 'episode_return_min': -125.74337427675587, 'weights_seq_no': 13.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.893473418758993e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.716617940900093e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4487909501135482e-05), 'numpy_to_tensor': np.float64(1.292021569464241e-05), 'add_states_from_episodes_to_batch': np.float64(3.022610115556505e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.23219782329116e-06), 'batch_individual_items': np.float64(8.507771079846781e-06)}}}, 'episode_return_max': -41.40403730849785, 'episode_duration_sec_mean': 0.03603604602249984, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.032920222199253134), 'episode_len_mean': 75.0, 'num_episodes': 28, 'env_step_timer': np.float64(7.423038845538716e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 29436}, 'module_episode_returns_mean': {'shared_policy': -37.72933711014619}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.873895529015748e-05), 'num_episodes_lifetime': 382, 'num_env_steps_sampled_lifetime_throughput': 1152.8137780186858}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(1.3351464), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.004181421), 'num_module_steps_trained': 21888, 'vf_explained_var': np.float32(-0.018942833), 'total_loss': np.float32(6.980559), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0084746), 'weights_seq_no': 14.0, 'policy_loss': np.float32(-0.0266152), 'vf_loss_unclipped': np.float32(77.56033), 'curr_kl_coeff': 1.220703143189894e-05, 'entropy': np.float32(1.567458), 'num_module_steps_trained_lifetime': 305152, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(7.0228477), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027878808928580936, 'add_one_ts_to_episodes_and_truncate': 0.007471275216436466, 'agent_to_module_mapping': 0.0018582580536648757, 'add_observations_from_episodes_to_batch': 0.0008101537395707706, 'add_states_from_episodes_to_batch': 5.738534967607526e-06, 'numpy_to_tensor': 0.0003663433764085413, 'batch_individual_items': 0.018221175717546775, 'add_time_dim_to_batch_and_zero_pad': 1.4513773071700805e-05, 'general_advantage_estimation': 0.009116955896348738}}, 'connector_pipeline_timer': 0.06595360296509424}, 'num_module_steps_trained': 21888, 'num_env_steps_trained': 350208, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 305152, 'num_env_steps_trained_lifetime': 4882432, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 28672, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1152.8137780186858, 'done': False, 'training_iteration': 14, 'trial_id': 'default', 'date': '2025-05-29_16-35-21', 'timestamp': 1748529321, 'time_this_iter_s': 1.7689540386199951, 'time_total_s': 25.465948820114136, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 25.465948820114136, 'iterations_since_restore': 14, 'perf': {'cpu_util_percent': np.float64(22.733333333333334), 'ram_util_percent': np.float64(81.76666666666667)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 15, Result: {'timers': {'training_iteration': 1.8290725530728507, 'restore_env_runners': 8.050765930263577e-06, 'training_step': 1.8289584214466448, 'env_runner_sampling_timer': 1.1400125082601495, 'learner_update_timer': 0.6868768203606641, 'synch_weights': 0.0010099116522100373, 'synch_env_connectors': 0.0008736744527902499}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -26.692568991084453, 'agent_0': -26.695068991084455, 'agent_1': -26.663818991084455}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.257614971811556), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 709, 'agent_2': 710, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06887799856137611), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.147015873945448e-07), 'module_to_agent_unmapping': np.float64(2.1042160425139356e-06), 'get_actions': np.float64(8.639335462902147e-05), 'normalize_and_clip_actions': np.float64(1.4962289085166112e-05), 'tensor_to_numpy': np.float64(2.5425589451329064e-05), 'un_batch_to_individual_items': np.float64(1.1327220859906275e-05), 'listify_data_for_vector_env': np.float64(5.1869202873549016e-06)}}, 'connector_pipeline_timer': np.float64(0.00018523114133072154)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 10649, 'agent_0': 10240, 'agent_1': 10649}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 30720, 'episode_return_mean': -80.05145697325335, 'env_to_module_sum_episodes_length_out': np.float64(32.257614971811556), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -134.534190402152, 'weights_seq_no': 14.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.892838845664749e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7140396135048035e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4485205532099598e-05), 'numpy_to_tensor': np.float64(1.2915608342546491e-05), 'add_states_from_episodes_to_batch': np.float64(3.022105054199478e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.230419847823478e-06), 'batch_individual_items': np.float64(8.506496073752065e-06)}}}, 'episode_return_max': -42.35522943641465, 'episode_duration_sec_mean': 0.03613839319500002, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.03469903003680239), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.423352048981204e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 31538}, 'module_episode_returns_mean': {'shared_policy': -37.433754190669895}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.762477144825505e-05), 'num_episodes_lifetime': 409, 'num_env_steps_sampled_lifetime_throughput': 1138.6797335859508}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(1.3927755), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.003657889), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(0.04947883), 'total_loss': np.float32(6.8745375), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 15.0, 'policy_loss': np.float32(0.09593227), 'vf_loss_unclipped': np.float32(110.47947), 'curr_kl_coeff': 6.10351571594947e-06, 'entropy': np.float32(1.5714782), 'num_module_steps_trained_lifetime': 326912, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.79432), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027879844405209273, 'add_one_ts_to_episodes_and_truncate': 0.0074707353565431536, 'agent_to_module_mapping': 0.0018582808521948563, 'add_observations_from_episodes_to_batch': 0.0008101719372645961, 'add_states_from_episodes_to_batch': 5.736885519218746e-06, 'numpy_to_tensor': 0.000366026789995168, 'batch_individual_items': 0.018250906030379415, 'add_time_dim_to_batch_and_zero_pad': 1.4516058238599967e-05, 'general_advantage_estimation': 0.00911118021700354}}, 'connector_pipeline_timer': 0.06597765098011821}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 326912, 'num_env_steps_trained_lifetime': 5230592, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 30720, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1138.6797335859508, 'done': False, 'training_iteration': 15, 'trial_id': 'default', 'date': '2025-05-29_16-35-23', 'timestamp': 1748529323, 'time_this_iter_s': 1.7892510890960693, 'time_total_s': 27.255199909210205, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 27.255199909210205, 'iterations_since_restore': 15, 'perf': {'cpu_util_percent': np.float64(24.4), 'ram_util_percent': np.float64(81.75)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 16, Result: {'timers': {'training_iteration': 1.8283577896221221, 'restore_env_runners': 8.061088270980023e-06, 'training_step': 1.8282433026421785, 'env_runner_sampling_timer': 1.1399313352575482, 'learner_update_timer': 0.6862413554870576, 'synch_weights': 0.0010092912856879508, 'synch_env_connectors': 0.0008732360382623214}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -25.99133306331273, 'agent_0': -25.886333063312733, 'agent_1': -26.03008306331273}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.27165994464702), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 710, 'agent_0': 682}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.0684104344905102), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.13931935929913e-07), 'module_to_agent_unmapping': np.float64(2.1026828679620914e-06), 'get_actions': np.float64(8.305376204228974e-05), 'normalize_and_clip_actions': np.float64(1.490206481285847e-05), 'tensor_to_numpy': np.float64(2.534250015848401e-05), 'un_batch_to_individual_items': np.float64(1.132054210141873e-05), 'listify_data_for_vector_env': np.float64(5.182712124787904e-06)}}, 'connector_pipeline_timer': np.float64(0.00018169918935844728)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 11359, 'agent_0': 10922, 'agent_1': 11359}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 32768, 'episode_return_mean': -77.9077491899382, 'env_to_module_sum_episodes_length_out': np.float64(32.27165994464702), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -184.59910060025715, 'weights_seq_no': 15.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.885521478645035e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.709710711295569e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4476975879405575e-05), 'numpy_to_tensor': np.float64(1.2897123960376146e-05), 'add_states_from_episodes_to_batch': np.float64(3.0203084416787895e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.226169610535803e-06), 'batch_individual_items': np.float64(8.495425629223145e-06)}}}, 'episode_return_max': -34.77502235003345, 'episode_duration_sec_mean': 0.03633229890250028, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.03627156742489789), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.41626985960583e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 33640}, 'module_episode_returns_mean': {'shared_policy': -36.16312544449884}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.663142878439565e-05), 'num_episodes_lifetime': 436, 'num_env_steps_sampled_lifetime_throughput': 1157.4977891693336}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(2.144245), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0039661145), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(0.011783838), 'total_loss': np.float32(6.8950806), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 16.0, 'policy_loss': np.float32(-0.0073865126), 'vf_loss_unclipped': np.float32(100.40827), 'curr_kl_coeff': 3.051757857974735e-06, 'entropy': np.float32(1.5593755), 'num_module_steps_trained_lifetime': 348672, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.9180603), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027880934441412184, 'add_one_ts_to_episodes_and_truncate': 0.007470157508026064, 'agent_to_module_mapping': 0.0018583039064488706, 'add_observations_from_episodes_to_batch': 0.0008101891306305875, 'add_states_from_episodes_to_batch': 5.735116106301346e-06, 'numpy_to_tensor': 0.00036569040937242176, 'batch_individual_items': 0.018280063977683645, 'add_time_dim_to_batch_and_zero_pad': 1.4518004624853537e-05, 'general_advantage_estimation': 0.00910504479315561}}, 'connector_pipeline_timer': 0.06600075279534516}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 348672, 'num_env_steps_trained_lifetime': 5578752, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 32768, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1157.4977891693336, 'done': False, 'training_iteration': 16, 'trial_id': 'default', 'date': '2025-05-29_16-35-25', 'timestamp': 1748529325, 'time_this_iter_s': 1.7612018585205078, 'time_total_s': 29.016401767730713, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 29.016401767730713, 'iterations_since_restore': 16, 'perf': {'cpu_util_percent': np.float64(25.933333333333334), 'ram_util_percent': np.float64(81.66666666666667)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 17, Result: {'timers': {'training_iteration': 1.827567780895901, 'restore_env_runners': 8.049227388309808e-06, 'training_step': 1.8274529879557568, 'env_runner_sampling_timer': 1.1398061652349727, 'learner_update_timer': 0.6855757323521869, 'synch_weights': 0.001008384622831042, 'synch_env_connectors': 0.0008738078378797259}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -27.403344737194193, 'agent_0': -27.460844737194193, 'agent_1': -27.34959473719419}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.26093908819047), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 711, 'agent_2': 710, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.0679795327332553), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.123054575053673e-07), 'module_to_agent_unmapping': np.float64(2.0992301353340616e-06), 'get_actions': np.float64(8.014999108789842e-05), 'normalize_and_clip_actions': np.float64(1.4841738588397232e-05), 'tensor_to_numpy': np.float64(2.5252562721656762e-05), 'un_batch_to_individual_items': np.float64(1.1303312125846904e-05), 'listify_data_for_vector_env': np.float64(5.177828759660727e-06)}}, 'connector_pipeline_timer': np.float64(0.00017855574342942013)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 12069, 'agent_0': 11605, 'agent_1': 12070}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 34816, 'episode_return_mean': -82.21378421158262, 'env_to_module_sum_episodes_length_out': np.float64(32.26093908819047), 'num_module_steps_sampled': {'shared_policy': 2104}, 'episode_return_min': -157.28589478111363, 'weights_seq_no': 16.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.874645934745617e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7058504132613726e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4458025720596047e-05), 'numpy_to_tensor': np.float64(1.2868387713907413e-05), 'add_states_from_episodes_to_batch': np.float64(3.0168453326456e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.218275043929424e-06), 'batch_individual_items': np.float64(8.479511353363252e-06)}}}, 'episode_return_max': -40.39048617844372, 'episode_duration_sec_mean': 0.036013985277499855, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.037631807138259005), 'episode_len_mean': 75.0, 'num_episodes': 28, 'env_step_timer': np.float64(7.404877382538428e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 35744}, 'module_episode_returns_mean': {'shared_policy': -38.63534003008721}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.570356941809555e-05), 'num_episodes_lifetime': 464, 'num_env_steps_sampled_lifetime_throughput': 1163.1563964017657}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(3.2676206), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0029216777), 'num_module_steps_trained': 21888, 'vf_explained_var': np.float32(0.033388674), 'total_loss': np.float32(7.4558845), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 17.0, 'policy_loss': np.float32(0.029539993), 'vf_loss_unclipped': np.float32(121.27228), 'curr_kl_coeff': 1.5258789289873675e-06, 'entropy': np.float32(1.5627065), 'num_module_steps_trained_lifetime': 370560, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(7.4419713), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027882145134150518, 'add_one_ts_to_episodes_and_truncate': 0.007469554305443661, 'agent_to_module_mapping': 0.001858327729832585, 'add_observations_from_episodes_to_batch': 0.0008102121962355331, 'add_states_from_episodes_to_batch': 5.733216693090404e-06, 'numpy_to_tensor': 0.00036533441198313097, 'batch_individual_items': 0.018308666287938754, 'add_time_dim_to_batch_and_zero_pad': 1.4520018777558145e-05, 'general_advantage_estimation': 0.009098539401462939}}, 'connector_pipeline_timer': 0.06602300469666958}, 'num_module_steps_trained': 21888, 'num_env_steps_trained': 350208, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 370560, 'num_env_steps_trained_lifetime': 5928960, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 34816, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1163.1563964017657, 'done': False, 'training_iteration': 17, 'trial_id': 'default', 'date': '2025-05-29_16-35-27', 'timestamp': 1748529327, 'time_this_iter_s': 1.7529101371765137, 'time_total_s': 30.769311904907227, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 30.769311904907227, 'iterations_since_restore': 17, 'perf': {'cpu_util_percent': np.float64(21.8), 'ram_util_percent': np.float64(81.65)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 18, Result: {'timers': {'training_iteration': 1.826800062676942, 'restore_env_runners': 8.047075114442652e-06, 'training_step': 1.8266849405761991, 'env_runner_sampling_timer': 1.1397207385826231, 'learner_update_timer': 0.6848925471186651, 'synch_weights': 0.0010077445266026914, 'synch_env_connectors': 0.000873802259500908}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -25.614733370611894, 'agent_0': -25.637233370611895, 'agent_1': -25.695983370611895}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.29703986289019), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 709, 'agent_2': 710, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06758498117528183), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.143725926530984e-07), 'module_to_agent_unmapping': np.float64(2.0978023234418485e-06), 'get_actions': np.float64(7.774973783902166e-05), 'normalize_and_clip_actions': np.float64(1.4804964222647285e-05), 'tensor_to_numpy': np.float64(2.5199216068537455e-05), 'un_batch_to_individual_items': np.float64(1.1296094987652738e-05), 'listify_data_for_vector_env': np.float64(5.180402496073098e-06)}}, 'connector_pipeline_timer': np.float64(0.00017603010991320314)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 12779, 'agent_0': 12288, 'agent_1': 12779}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 36864, 'episode_return_mean': -76.9479501118357, 'env_to_module_sum_episodes_length_out': np.float64(32.29703986289019), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -132.41768860423633, 'weights_seq_no': 17.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.871594024740593e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7027423855240698e-06), 'add_observations_from_episodes_to_batch': np.float64(1.445493121630301e-05), 'numpy_to_tensor': np.float64(1.2858344435398607e-05), 'add_states_from_episodes_to_batch': np.float64(3.0162603837452643e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.215491744784005e-06), 'batch_individual_items': np.float64(8.474743461121595e-06)}}}, 'episode_return_max': -32.38086364993266, 'episode_duration_sec_mean': 0.03616969539500078, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.03880261842233896), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.400831228782932e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 37846}, 'module_episode_returns_mean': {'shared_policy': -36.63079711755158}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.496133061191108e-05), 'num_episodes_lifetime': 491, 'num_env_steps_sampled_lifetime_throughput': 1162.2131200908966}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(2.1113262), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0038168244), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(-0.05662954), 'total_loss': np.float32(7.85487), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0082644), 'weights_seq_no': 18.0, 'policy_loss': np.float32(0.199664), 'vf_loss_unclipped': np.float32(131.15791), 'curr_kl_coeff': 7.629394644936838e-07, 'entropy': np.float32(1.5559827), 'num_module_steps_trained_lifetime': 392320, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(7.670766), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027883412219589943, 'add_one_ts_to_episodes_and_truncate': 0.007468918542862104, 'agent_to_module_mapping': 0.00185835149635798, 'add_observations_from_episodes_to_batch': 0.0008102344149153166, 'add_states_from_episodes_to_batch': 5.731235856533319e-06, 'numpy_to_tensor': 0.00036495882380068904, 'batch_individual_items': 0.018336706733090992, 'add_time_dim_to_batch_and_zero_pad': 1.452192414674659e-05, 'general_advantage_estimation': 0.009091678446424804}}, 'connector_pipeline_timer': 0.06604433348888797}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 392320, 'num_env_steps_trained_lifetime': 6277120, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 36864, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1162.2131200908966, 'done': False, 'training_iteration': 18, 'trial_id': 'default', 'date': '2025-05-29_16-35-29', 'timestamp': 1748529329, 'time_this_iter_s': 1.7543330192565918, 'time_total_s': 32.52364492416382, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 32.52364492416382, 'iterations_since_restore': 18, 'perf': {'cpu_util_percent': np.float64(21.833333333333332), 'ram_util_percent': np.float64(81.6)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 19, Result: {'timers': {'training_iteration': 1.8260162528801727, 'restore_env_runners': 8.047014363307804e-06, 'training_step': 1.8259007815904371, 'env_runner_sampling_timer': 1.139593645776797, 'learner_update_timer': 0.6842351549774786, 'synch_weights': 0.001007446251336666, 'synch_env_connectors': 0.0008738346569059605}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -29.900387132692494, 'agent_0': -30.020387132692505, 'agent_1': -29.899137132692502}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.318506415392605), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 710, 'agent_0': 682}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06721929405903951), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.130907947287847e-07), 'module_to_agent_unmapping': np.float64(2.0958463533123055e-06), 'get_actions': np.float64(7.563792791994475e-05), 'normalize_and_clip_actions': np.float64(1.4766595462877264e-05), 'tensor_to_numpy': np.float64(2.5143379698038825e-05), 'un_batch_to_individual_items': np.float64(1.1284068767500447e-05), 'listify_data_for_vector_env': np.float64(5.1763510990692634e-06)}}, 'connector_pipeline_timer': np.float64(0.00017376602601245497)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 13489, 'agent_0': 12970, 'agent_1': 13489}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 38912, 'episode_return_mean': -89.81991139807745, 'env_to_module_sum_episodes_length_out': np.float64(32.318506415392605), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -220.7111730577314, 'weights_seq_no': 18.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.864891014267426e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.698630197741122e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4440081523077342e-05), 'numpy_to_tensor': np.float64(1.2840537891162721e-05), 'add_states_from_episodes_to_batch': np.float64(3.016150507691821e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.21106493941932e-06), 'batch_individual_items': np.float64(8.463371686557265e-06)}}}, 'episode_return_max': -34.022650042948776, 'episode_duration_sec_mean': 0.03600071354999956, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.03980766631414925), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.392821218169164e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 39948}, 'module_episode_returns_mean': {'shared_policy': -40.90501066087949}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.430227451239241e-05), 'num_episodes_lifetime': 518, 'num_env_steps_sampled_lifetime_throughput': 1162.7603842270603}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(1.8888291), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0031742125), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(0.023465455), 'total_loss': np.float32(8.215111), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 19.0, 'policy_loss': np.float32(0.15214649), 'vf_loss_unclipped': np.float32(159.45491), 'curr_kl_coeff': 3.814697322468419e-07, 'entropy': np.float32(1.5619694), 'num_module_steps_trained_lifetime': 414080, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(8.078585), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027884731511307163, 'add_one_ts_to_episodes_and_truncate': 0.007468242290101634, 'agent_to_module_mapping': 0.0018583738838798835, 'add_observations_from_episodes_to_batch': 0.0008102543430018806, 'add_states_from_episodes_to_batch': 5.729138015038084e-06, 'numpy_to_tensor': 0.00036456449314069766, 'batch_individual_items': 0.018364178531811392, 'add_time_dim_to_batch_and_zero_pad': 1.4523481106673116e-05, 'general_advantage_estimation': 0.009084473214947287}}, 'connector_pipeline_timer': 0.06606472894639233}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 414080, 'num_env_steps_trained_lifetime': 6625280, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 38912, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1162.7603842270603, 'done': False, 'training_iteration': 19, 'trial_id': 'default', 'date': '2025-05-29_16-35-30', 'timestamp': 1748529330, 'time_this_iter_s': 1.7521138191223145, 'time_total_s': 34.27575874328613, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 34.27575874328613, 'iterations_since_restore': 19, 'perf': {'cpu_util_percent': np.float64(22.2), 'ram_util_percent': np.float64(81.6)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 20, Result: {'timers': {'training_iteration': 1.826546479101371, 'restore_env_runners': 8.026134219666954e-06, 'training_step': 1.8264306196045328, 'env_runner_sampling_timer': 1.139508124729029, 'learner_update_timer': 0.6848502855177038, 'synch_weights': 0.0010064317888233045, 'synch_env_connectors': 0.0008749150603369088}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -25.538580133317588, 'agent_0': -25.437330133317587, 'agent_1': -25.569830133317588}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.30179587428921), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 711, 'agent_2': 710, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06689001618699421), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.125617134384854e-07), 'module_to_agent_unmapping': np.float64(2.0944788476694983e-06), 'get_actions': np.float64(7.38726752611481e-05), 'normalize_and_clip_actions': np.float64(1.4736987043280732e-05), 'tensor_to_numpy': np.float64(2.5101783764878982e-05), 'un_batch_to_individual_items': np.float64(1.1281655179081543e-05), 'listify_data_for_vector_env': np.float64(5.1754998600427326e-06)}}, 'connector_pipeline_timer': np.float64(0.00017190198564212046)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 14199, 'agent_0': 13653, 'agent_1': 14200}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 40960, 'episode_return_mean': -76.54574039995278, 'env_to_module_sum_episodes_length_out': np.float64(32.30179587428921), 'num_module_steps_sampled': {'shared_policy': 2104}, 'episode_return_min': -141.69766052735872, 'weights_seq_no': 19.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.861646902572214e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.6971558455963485e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4434105076882097e-05), 'numpy_to_tensor': np.float64(1.2826889826465817e-05), 'add_states_from_episodes_to_batch': np.float64(3.015727165458613e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.20839848563938e-06), 'batch_individual_items': np.float64(8.459507956631282e-06)}}}, 'episode_return_max': -34.022650042948776, 'episode_duration_sec_mean': 0.03613412823749886, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.04067135142270587), 'episode_len_mean': 75.0, 'num_episodes': 28, 'env_step_timer': np.float64(7.388963202535566e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 42052}, 'module_episode_returns_mean': {'shared_policy': -37.157203108285195}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.374004857866476e-05), 'num_episodes_lifetime': 546, 'num_env_steps_sampled_lifetime_throughput': 1083.3277205796167}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(1.6220257), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0045792335), 'num_module_steps_trained': 21888, 'vf_explained_var': np.float32(0.056981266), 'total_loss': np.float32(6.8506756), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 20.0, 'policy_loss': np.float32(0.1403307), 'vf_loss_unclipped': np.float32(89.72666), 'curr_kl_coeff': 1.9073486612342094e-07, 'entropy': np.float32(1.5564795), 'num_module_steps_trained_lifetime': 435968, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.7259097), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.02788615259686808, 'add_one_ts_to_episodes_and_truncate': 0.007467548624742087, 'agent_to_module_mapping': 0.001858398155201713, 'add_observations_from_episodes_to_batch': 0.0008102759074852218, 'add_states_from_episodes_to_batch': 5.726950706787053e-06, 'numpy_to_tensor': 0.0003641519574115257, 'batch_individual_items': 0.018401668144784073, 'add_time_dim_to_batch_and_zero_pad': 1.452478813498688e-05, 'general_advantage_estimation': 0.009076935191054679}}, 'connector_pipeline_timer': 0.0660948712363977}, 'num_module_steps_trained': 21888, 'num_env_steps_trained': 350208, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 435968, 'num_env_steps_trained_lifetime': 6975488, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 40960, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1083.3277205796167, 'done': False, 'training_iteration': 20, 'trial_id': 'default', 'date': '2025-05-29_16-35-32', 'timestamp': 1748529332, 'time_this_iter_s': 1.882763147354126, 'time_total_s': 36.15852189064026, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 36.15852189064026, 'iterations_since_restore': 20, 'perf': {'cpu_util_percent': np.float64(21.766666666666666), 'ram_util_percent': np.float64(81.63333333333334)}}
Checkpoint saved at TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/tegan/ray_results/simple_spread_rllib), metrics={'timers': {'training_iteration': 1.826546479101371, 'restore_env_runners': 8.026134219666954e-06, 'training_step': 1.8264306196045328, 'env_runner_sampling_timer': 1.139508124729029, 'learner_update_timer': 0.6848502855177038, 'synch_weights': 0.0010064317888233045, 'synch_env_connectors': 0.0008749150603369088}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -25.538580133317588, 'agent_0': -25.437330133317587, 'agent_1': -25.569830133317588}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.30179587428921), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 711, 'agent_2': 710, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06689001618699421), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.125617134384854e-07), 'module_to_agent_unmapping': np.float64(2.0944788476694983e-06), 'get_actions': np.float64(7.38726752611481e-05), 'normalize_and_clip_actions': np.float64(1.4736987043280732e-05), 'tensor_to_numpy': np.float64(2.5101783764878982e-05), 'un_batch_to_individual_items': np.float64(1.1281655179081543e-05), 'listify_data_for_vector_env': np.float64(5.1754998600427326e-06)}}, 'connector_pipeline_timer': np.float64(0.00017190198564212046)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 14199, 'agent_0': 13653, 'agent_1': 14200}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 40960, 'episode_return_mean': -76.54574039995278, 'env_to_module_sum_episodes_length_out': np.float64(32.30179587428921), 'num_module_steps_sampled': {'shared_policy': 2104}, 'episode_return_min': -141.69766052735872, 'weights_seq_no': 19.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.861646902572214e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.6971558455963485e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4434105076882097e-05), 'numpy_to_tensor': np.float64(1.2826889826465817e-05), 'add_states_from_episodes_to_batch': np.float64(3.015727165458613e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.20839848563938e-06), 'batch_individual_items': np.float64(8.459507956631282e-06)}}}, 'episode_return_max': -34.022650042948776, 'episode_duration_sec_mean': 0.03613412823749886, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.04067135142270587), 'episode_len_mean': 75.0, 'num_episodes': 28, 'env_step_timer': np.float64(7.388963202535566e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 42052}, 'module_episode_returns_mean': {'shared_policy': -37.157203108285195}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.374004857866476e-05), 'num_episodes_lifetime': 546, 'num_env_steps_sampled_lifetime_throughput': 1083.3277205796167}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(1.6220257), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0045792335), 'num_module_steps_trained': 21888, 'vf_explained_var': np.float32(0.056981266), 'total_loss': np.float32(6.8506756), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 20.0, 'policy_loss': np.float32(0.1403307), 'vf_loss_unclipped': np.float32(89.72666), 'curr_kl_coeff': 1.9073486612342094e-07, 'entropy': np.float32(1.5564795), 'num_module_steps_trained_lifetime': 435968, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.7259097), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.02788615259686808, 'add_one_ts_to_episodes_and_truncate': 0.007467548624742087, 'agent_to_module_mapping': 0.001858398155201713, 'add_observations_from_episodes_to_batch': 0.0008102759074852218, 'add_states_from_episodes_to_batch': 5.726950706787053e-06, 'numpy_to_tensor': 0.0003641519574115257, 'batch_individual_items': 0.018401668144784073, 'add_time_dim_to_batch_and_zero_pad': 1.452478813498688e-05, 'general_advantage_estimation': 0.009076935191054679}}, 'connector_pipeline_timer': 0.0660948712363977}, 'num_module_steps_trained': 21888, 'num_env_steps_trained': 350208, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 435968, 'num_env_steps_trained_lifetime': 6975488, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 40960, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1083.3277205796167, 'done': False, 'training_iteration': 20, 'trial_id': 'default', 'date': '2025-05-29_16-35-32', 'timestamp': 1748529332, 'time_this_iter_s': 1.882763147354126, 'time_total_s': 36.15852189064026, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 36.15852189064026, 'iterations_since_restore': 20, 'perf': {'cpu_util_percent': np.float64(21.766666666666666), 'ram_util_percent': np.float64(81.63333333333334)}})
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 21, Result: {'timers': {'training_iteration': 1.8258180689003574, 'restore_env_runners': 8.030452877505146e-06, 'training_step': 1.8257018363184876, 'env_runner_sampling_timer': 1.1394238789017388, 'learner_update_timer': 0.6842045889125268, 'synch_weights': 0.001005923300935068, 'synch_env_connectors': 0.0008762954897335087}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -28.56648094364388, 'agent_0': -28.748980943643883, 'agent_1': -28.755230943643884}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.31232565033497), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 709, 'agent_2': 710, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06659414826738126), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.120752023994577e-07), 'module_to_agent_unmapping': np.float64(2.0932401006502984e-06), 'get_actions': np.float64(7.237878741044398e-05), 'normalize_and_clip_actions': np.float64(1.4713341276001663e-05), 'tensor_to_numpy': np.float64(2.5074995379353185e-05), 'un_batch_to_individual_items': np.float64(1.1281265293976788e-05), 'listify_data_for_vector_env': np.float64(5.173316439152798e-06)}}, 'connector_pipeline_timer': np.float64(0.0001703375804385548)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 14909, 'agent_0': 14336, 'agent_1': 14909}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 43008, 'episode_return_mean': -86.07069283093169, 'env_to_module_sum_episodes_length_out': np.float64(32.31232565033497), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -188.36192155299014, 'weights_seq_no': 20.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.859497132137908e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.6945265729853636e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4432082489192216e-05), 'numpy_to_tensor': np.float64(1.2821472960186463e-05), 'add_states_from_episodes_to_batch': np.float64(3.015733179831448e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.203033930114021e-06), 'batch_individual_items': np.float64(8.456348376796937e-06)}}}, 'episode_return_max': -41.663997725207196, 'episode_duration_sec_mean': 0.03609838080250011, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.04160052070526405), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.38580596074081e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 44154}, 'module_episode_returns_mean': {'shared_policy': -42.457772064621565}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.324606713301479e-05), 'num_episodes_lifetime': 573, 'num_env_steps_sampled_lifetime_throughput': 1154.8511562982171}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(2.7048252), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0030128697), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(-0.055460334), 'total_loss': np.float32(8.064), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 21.0, 'policy_loss': np.float32(0.10652402), 'vf_loss_unclipped': np.float32(134.13332), 'curr_kl_coeff': 9.536743306171047e-08, 'entropy': np.float32(1.5554284), 'num_module_steps_trained_lifetime': 457728, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(7.9730306), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027887593283366652, 'add_one_ts_to_episodes_and_truncate': 0.007466811020960721, 'agent_to_module_mapping': 0.0018584214162087186, 'add_observations_from_episodes_to_batch': 0.0008102953319445964, 'add_states_from_episodes_to_batch': 5.724634230899239e-06, 'numpy_to_tensor': 0.0003637205617476226, 'batch_individual_items': 0.01843839060594412, 'add_time_dim_to_batch_and_zero_pad': 1.4525779174624319e-05, 'general_advantage_estimation': 0.009069067838618428}}, 'connector_pipeline_timer': 0.06612386127430833}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 457728, 'num_env_steps_trained_lifetime': 7323648, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 43008, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1154.8511562982171, 'done': False, 'training_iteration': 21, 'trial_id': 'default', 'date': '2025-05-29_16-35-34', 'timestamp': 1748529334, 'time_this_iter_s': 1.7573208808898926, 'time_total_s': 37.91584277153015, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 37.91584277153015, 'iterations_since_restore': 21, 'perf': {'cpu_util_percent': np.float64(22.333333333333332), 'ram_util_percent': np.float64(81.56666666666666)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 22, Result: {'timers': {'training_iteration': 1.8256502065413538, 'restore_env_runners': 8.015988348706542e-06, 'training_step': 1.8255337283653026, 'env_runner_sampling_timer': 1.1398789717727213, 'learner_update_timer': 0.6835802367734015, 'synch_weights': 0.0010056590679257142, 'synch_env_connectors': 0.0008769354548362014}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -27.01817666964312, 'agent_0': -27.216926669643115, 'agent_1': -27.118176669643116}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.33435544718702), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 710, 'agent_0': 682}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06635150598817732), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.149253215236003e-07), 'module_to_agent_unmapping': np.float64(2.100203037478465e-06), 'get_actions': np.float64(7.202345886768807e-05), 'normalize_and_clip_actions': np.float64(1.4757812846439884e-05), 'tensor_to_numpy': np.float64(2.5154025701056585e-05), 'un_batch_to_individual_items': np.float64(1.1315756345620832e-05), 'listify_data_for_vector_env': np.float64(5.1888468293558476e-06)}}, 'connector_pipeline_timer': np.float64(0.00017032527529029184)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 15619, 'agent_0': 15018, 'agent_1': 15619}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 45056, 'episode_return_mean': -81.35328000892935, 'env_to_module_sum_episodes_length_out': np.float64(32.33435544718702), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -146.62444518029295, 'weights_seq_no': 21.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.929043639310752e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7117486667866284e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4743829071127464e-05), 'numpy_to_tensor': np.float64(1.289446139914409e-05), 'add_states_from_episodes_to_batch': np.float64(3.0247403963930432e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.239438076380764e-06), 'batch_individual_items': np.float64(8.494202671160403e-06)}}}, 'episode_return_max': -37.77804532766347, 'episode_duration_sec_mean': 0.037697155767499185, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.04237365033907124), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.428670776894478e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 46256}, 'module_episode_returns_mean': {'shared_policy': -40.13932542881682}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.3348334560109723e-05), 'num_episodes_lifetime': 600, 'num_env_steps_sampled_lifetime_throughput': 1125.112397519892}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(2.5797188), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0034357423), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(-0.016444206), 'total_loss': np.float32(7.816243), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 22.0, 'policy_loss': np.float32(0.12858362), 'vf_loss_unclipped': np.float32(102.05423), 'curr_kl_coeff': 4.7683716530855236e-08, 'entropy': np.float32(1.5526301), 'num_module_steps_trained_lifetime': 479488, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(7.7031865), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027889054840875564, 'add_one_ts_to_episodes_and_truncate': 0.007466035856092509, 'agent_to_module_mapping': 0.0018584442971800632, 'add_observations_from_episodes_to_batch': 0.0008103131028240354, 'add_states_from_episodes_to_batch': 5.722199689457825e-06, 'numpy_to_tensor': 0.0003632714663012565, 'batch_individual_items': 0.01847439040936649, 'add_time_dim_to_batch_and_zero_pad': 1.4527539614655895e-05, 'general_advantage_estimation': 0.009060885110511795}}, 'connector_pipeline_timer': 0.06615176887843711}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 479488, 'num_env_steps_trained_lifetime': 7671808, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 45056, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1125.112397519892, 'done': False, 'training_iteration': 22, 'trial_id': 'default', 'date': '2025-05-29_16-35-36', 'timestamp': 1748529336, 'time_this_iter_s': 1.8125710487365723, 'time_total_s': 39.728413820266724, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 39.728413820266724, 'iterations_since_restore': 22, 'perf': {'cpu_util_percent': np.float64(29.25), 'ram_util_percent': np.float64(81.6)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 23, Result: {'timers': {'training_iteration': 1.8250627390559402, 'restore_env_runners': 8.028748465162796e-06, 'training_step': 1.8249459869116493, 'env_runner_sampling_timer': 1.139816110804994, 'learner_update_timer': 0.6830549119056674, 'synch_weights': 0.0010049533072464738, 'synch_env_connectors': 0.0008770077602878267}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -27.37784155935877, 'agent_0': -27.354091559358775, 'agent_1': -27.294091559358776}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.325157590441904), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 711, 'agent_2': 710, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.0661762405143353), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.139037287156558e-07), 'module_to_agent_unmapping': np.float64(2.0985214537509507e-06), 'get_actions': np.float64(7.083096756669161e-05), 'normalize_and_clip_actions': np.float64(1.4732157590969055e-05), 'tensor_to_numpy': np.float64(2.5129541826107e-05), 'un_batch_to_individual_items': np.float64(1.1313512967526534e-05), 'listify_data_for_vector_env': np.float64(5.185816787590784e-06)}}, 'connector_pipeline_timer': np.float64(0.00016904524360826295)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 16329, 'agent_0': 15701, 'agent_1': 16330}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 47104, 'episode_return_mean': -82.02602467807634, 'env_to_module_sum_episodes_length_out': np.float64(32.325157590441904), 'num_module_steps_sampled': {'shared_policy': 2104}, 'episode_return_min': -131.44923973934155, 'weights_seq_no': 22.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.917314370410274e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7091844651113866e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4690589672817595e-05), 'numpy_to_tensor': np.float64(1.2878670861769498e-05), 'add_states_from_episodes_to_batch': np.float64(3.023326221342453e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.230812772843497e-06), 'batch_individual_items': np.float64(8.489826037030743e-06)}}}, 'episode_return_max': -52.0007187070338, 'episode_duration_sec_mean': 0.03620140340999994, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.04302300063897655), 'episode_len_mean': 75.0, 'num_episodes': 28, 'env_step_timer': np.float64(7.419493188149126e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 48360}, 'module_episode_returns_mean': {'shared_policy': -40.99268833240408}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.2924287414641786e-05), 'num_episodes_lifetime': 628, 'num_env_steps_sampled_lifetime_throughput': 1150.6884491173548}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(1.626804), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.002813728), 'num_module_steps_trained': 21888, 'vf_explained_var': np.float32(0.055633307), 'total_loss': np.float32(7.320213), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 23.0, 'policy_loss': np.float32(0.16395323), 'vf_loss_unclipped': np.float32(93.75168), 'curr_kl_coeff': 2.3841858265427618e-08, 'entropy': np.float32(1.5618726), 'num_module_steps_trained_lifetime': 501376, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(7.1718783), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.02789059056200596, 'add_one_ts_to_episodes_and_truncate': 0.007465256059319563, 'agent_to_module_mapping': 0.0018584699533903603, 'add_observations_from_episodes_to_batch': 0.0008103339845526914, 'add_states_from_episodes_to_batch': 5.719653875422528e-06, 'numpy_to_tensor': 0.00036280523910764266, 'batch_individual_items': 0.018509671602659813, 'add_time_dim_to_batch_and_zero_pad': 1.4529087267969e-05, 'general_advantage_estimation': 0.009052373921783435}}, 'connector_pipeline_timer': 0.06617867953185588}, 'num_module_steps_trained': 21888, 'num_env_steps_trained': 350208, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 501376, 'num_env_steps_trained_lifetime': 8022016, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 47104, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1150.6884491173548, 'done': False, 'training_iteration': 23, 'trial_id': 'default', 'date': '2025-05-29_16-35-38', 'timestamp': 1748529338, 'time_this_iter_s': 1.7704639434814453, 'time_total_s': 41.49887776374817, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 41.49887776374817, 'iterations_since_restore': 23, 'perf': {'cpu_util_percent': np.float64(21.900000000000002), 'ram_util_percent': np.float64(81.89999999999999)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 24, Result: {'timers': {'training_iteration': 1.8242994274953808, 'restore_env_runners': 8.016790980516002e-06, 'training_step': 1.8241823862125328, 'env_runner_sampling_timer': 1.1397040701069439, 'learner_update_timer': 0.6824026644566106, 'synch_weights': 0.0010046379441740532, 'synch_env_connectors': 0.0008770951826849675}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -25.045972923558974, 'agent_0': -24.762222923558976, 'agent_1': -24.919722923558975}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.32549748420403), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 709, 'agent_2': 710, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06600335310938006), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.127475626332096e-07), 'module_to_agent_unmapping': np.float64(2.097084292628986e-06), 'get_actions': np.float64(6.977979699256305e-05), 'normalize_and_clip_actions': np.float64(1.470352205981004e-05), 'tensor_to_numpy': np.float64(2.508217743381056e-05), 'un_batch_to_individual_items': np.float64(1.1305482065782088e-05), 'listify_data_for_vector_env': np.float64(5.181355085454483e-06)}}, 'connector_pipeline_timer': np.float64(0.0001678585552840272)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 17039, 'agent_0': 16384, 'agent_1': 17039}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 49152, 'episode_return_mean': -74.72791877067692, 'env_to_module_sum_episodes_length_out': np.float64(32.32549748420403), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -128.0823665441888, 'weights_seq_no': 23.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.905785561695573e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.705344599314807e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4643676904633449e-05), 'numpy_to_tensor': np.float64(1.2859199774884391e-05), 'add_states_from_episodes_to_batch': np.float64(3.0240093241362238e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.223540493473461e-06), 'batch_individual_items': np.float64(8.48032067781632e-06)}}}, 'episode_return_max': -47.010269800770125, 'episode_duration_sec_mean': 0.036052163574999824, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.04357573344516588), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.411845749044971e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 50462}, 'module_episode_returns_mean': {'shared_policy': -37.14391242300924}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.256602161827864e-05), 'num_episodes_lifetime': 655, 'num_env_steps_sampled_lifetime_throughput': 1163.3804417525582}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(1.700895), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.003413089), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(0.11253142), 'total_loss': np.float32(6.9217963), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 24.0, 'policy_loss': np.float32(0.15249069), 'vf_loss_unclipped': np.float32(84.587036), 'curr_kl_coeff': 1.1920929132713809e-08, 'entropy': np.float32(1.5516958), 'num_module_steps_trained_lifetime': 523136, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.784823), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.02789215812572966, 'add_one_ts_to_episodes_and_truncate': 0.007464445125796468, 'agent_to_module_mapping': 0.001858495772846734, 'add_observations_from_episodes_to_batch': 0.0008103547756364915, 'add_states_from_episodes_to_batch': 5.716986757698693e-06, 'numpy_to_tensor': 0.00036232147601127155, 'batch_individual_items': 0.018544228470546337, 'add_time_dim_to_batch_and_zero_pad': 1.4530313714254284e-05, 'general_advantage_estimation': 0.009043548401718591}}, 'connector_pipeline_timer': 0.06620452576611845}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 523136, 'num_env_steps_trained_lifetime': 8370176, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 49152, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1163.3804417525582, 'done': False, 'training_iteration': 24, 'trial_id': 'default', 'date': '2025-05-29_16-35-39', 'timestamp': 1748529339, 'time_this_iter_s': 1.7522518634796143, 'time_total_s': 43.25112962722778, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 43.25112962722778, 'iterations_since_restore': 24, 'perf': {'cpu_util_percent': np.float64(20.7), 'ram_util_percent': np.float64(81.9)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 25, Result: {'timers': {'training_iteration': 1.823671399060427, 'restore_env_runners': 8.006623070676217e-06, 'training_step': 1.8235541415104075, 'env_runner_sampling_timer': 1.1396351519058743, 'learner_update_timer': 0.6818437594820445, 'synch_weights': 0.0010035557347323114, 'synch_env_connectors': 0.0008770629808581524}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -26.271421704732987, 'agent_0': -26.115171704732987, 'agent_1': -26.306421704732987}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.35113620581666), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 710, 'agent_0': 682}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06584218153600262), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.13928411762523e-07), 'module_to_agent_unmapping': np.float64(2.0979263088262014e-06), 'get_actions': np.float64(6.891384386005647e-05), 'normalize_and_clip_actions': np.float64(1.4688659700416575e-05), 'tensor_to_numpy': np.float64(2.506676299173115e-05), 'un_batch_to_individual_items': np.float64(1.1305842431260404e-05), 'listify_data_for_vector_env': np.float64(5.182045925282632e-06)}}, 'connector_pipeline_timer': np.float64(0.0001669476167577101)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 17749, 'agent_0': 17066, 'agent_1': 17749}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 51200, 'episode_return_mean': -78.693015114199, 'env_to_module_sum_episodes_length_out': np.float64(32.35113620581666), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -136.9357796690051, 'weights_seq_no': 24.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.900748303270961e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7046743429777924e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4615226354365666e-05), 'numpy_to_tensor': np.float64(1.2848871627437681e-05), 'add_states_from_episodes_to_batch': np.float64(3.025099397581819e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.220255649365636e-06), 'batch_individual_items': np.float64(8.477749982181732e-06)}}}, 'episode_return_max': -42.34299509920992, 'episode_duration_sec_mean': 0.03621488227000118, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.044026760161162845), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.408136501721357e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 52564}, 'module_episode_returns_mean': {'shared_policy': -37.944720831679284}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.226620223876275e-05), 'num_episodes_lifetime': 682, 'num_env_steps_sampled_lifetime_throughput': 1155.341021013483}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(1.5887021), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0020904124), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(0.013116896), 'total_loss': np.float32(7.3525186), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 25.0, 'policy_loss': np.float32(0.05715383), 'vf_loss_unclipped': np.float32(92.0091), 'curr_kl_coeff': 5.9604645663569045e-09, 'entropy': np.float32(1.5547633), 'num_module_steps_trained_lifetime': 544896, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(7.310912), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027893766304122686, 'add_one_ts_to_episodes_and_truncate': 0.007463603197837903, 'agent_to_module_mapping': 0.0018585204497186406, 'add_observations_from_episodes_to_batch': 0.0008103739008001602, 'add_states_from_episodes_to_batch': 5.714196916941508e-06, 'numpy_to_tensor': 0.00036182072855291705, 'batch_individual_items': 0.01857808472561486, 'add_time_dim_to_batch_and_zero_pad': 1.4531216822886988e-05, 'general_advantage_estimation': 0.009034432154662866}}, 'connector_pipeline_timer': 0.06622936202854257}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 544896, 'num_env_steps_trained_lifetime': 8718336, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 51200, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1155.341021013483, 'done': False, 'training_iteration': 25, 'trial_id': 'default', 'date': '2025-05-29_16-35-41', 'timestamp': 1748529341, 'time_this_iter_s': 1.764965295791626, 'time_total_s': 45.01609492301941, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 45.01609492301941, 'iterations_since_restore': 25, 'perf': {'cpu_util_percent': np.float64(23.066666666666666), 'ram_util_percent': np.float64(81.93333333333334)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 26, Result: {'timers': {'training_iteration': 1.8229595408998227, 'restore_env_runners': 8.012396839966462e-06, 'training_step': 1.8228419388453034, 'env_runner_sampling_timer': 1.1395609503868156, 'learner_update_timer': 0.681204861047224, 'synch_weights': 0.001003703087385, 'synch_env_connectors': 0.0008766694310496302}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -26.01268762896578, 'agent_0': -26.018937628965777, 'agent_1': -25.982687628965778}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.337473300105316), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 709, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.0656923206783594), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.133907812710701e-07), 'module_to_agent_unmapping': np.float64(2.1017325159621973e-06), 'get_actions': np.float64(6.815860715347006e-05), 'normalize_and_clip_actions': np.float64(1.4671750427102907e-05), 'tensor_to_numpy': np.float64(2.504339030738385e-05), 'un_batch_to_individual_items': np.float64(1.1302429848301445e-05), 'listify_data_for_vector_env': np.float64(5.181945241279739e-06)}}, 'connector_pipeline_timer': np.float64(0.00016612834987746633)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 18458, 'agent_0': 17749, 'agent_1': 18459}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 53248, 'episode_return_mean': -78.0143128868973, 'env_to_module_sum_episodes_length_out': np.float64(32.337473300105316), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -110.39012997526507, 'weights_seq_no': 25.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.894041998471354e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7026797841440146e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4584096357000849e-05), 'numpy_to_tensor': np.float64(1.283631535448133e-05), 'add_states_from_episodes_to_batch': np.float64(3.0239212746594285e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.21459065437214e-06), 'batch_individual_items': np.float64(8.472232701644876e-06)}}}, 'episode_return_max': -46.7338735771083, 'episode_duration_sec_mean': 0.036132269590000855, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.044406353990798314), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.405145825610174e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 54666}, 'module_episode_returns_mean': {'shared_policy': -38.4884328797383}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.20150194891903e-05), 'num_episodes_lifetime': 709, 'num_env_steps_sampled_lifetime_throughput': 1160.867951469476}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(3.5333), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0030905227), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(-0.005329132), 'total_loss': np.float32(7.1030083), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 26.0, 'policy_loss': np.float32(0.07206931), 'vf_loss_unclipped': np.float32(54.26395), 'curr_kl_coeff': 2.9802322831784522e-09, 'entropy': np.float32(1.5651842), 'num_module_steps_trained_lifetime': 566656, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(7.046591), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.02789540614063528, 'add_one_ts_to_episodes_and_truncate': 0.00746273144732593, 'agent_to_module_mapping': 0.0018585461751758243, 'add_observations_from_episodes_to_batch': 0.0008103913162829915, 'add_states_from_episodes_to_batch': 5.711332874324361e-06, 'numpy_to_tensor': 0.00036130297639612864, 'batch_individual_items': 0.018611248549334963, 'add_time_dim_to_batch_and_zero_pad': 1.4531811337975521e-05, 'general_advantage_estimation': 0.009025028194308083}}, 'connector_pipeline_timer': 0.06625319389644159}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 566656, 'num_env_steps_trained_lifetime': 9066496, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 53248, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1160.867951469476, 'done': False, 'training_iteration': 26, 'trial_id': 'default', 'date': '2025-05-29_16-35-43', 'timestamp': 1748529343, 'time_this_iter_s': 1.7561290264129639, 'time_total_s': 46.77222394943237, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 46.77222394943237, 'iterations_since_restore': 26, 'perf': {'cpu_util_percent': np.float64(21.5), 'ram_util_percent': np.float64(81.95)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 27, Result: {'timers': {'training_iteration': 1.8224128696608246, 'restore_env_runners': 8.009362871585896e-06, 'training_step': 1.8222949498768506, 'env_runner_sampling_timer': 1.1396203050429474, 'learner_update_timer': 0.6805990228567517, 'synch_weights': 0.0010024331365112195, 'synch_env_connectors': 0.00087759773673917}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -25.580542987306032, 'agent_0': -25.683042987306035, 'agent_1': -25.778042987306033}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.307854540829815), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 711, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06556561070060019), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.139235785878865e-07), 'module_to_agent_unmapping': np.float64(2.103656800023984e-06), 'get_actions': np.float64(6.768009423308184e-05), 'normalize_and_clip_actions': np.float64(1.4677706702998784e-05), 'tensor_to_numpy': np.float64(2.506461921881967e-05), 'un_batch_to_individual_items': np.float64(1.1312301484013846e-05), 'listify_data_for_vector_env': np.float64(5.1841262495569435e-06)}}, 'connector_pipeline_timer': np.float64(0.00016570853779012334)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 19169, 'agent_0': 18432, 'agent_1': 19169}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 55296, 'episode_return_mean': -77.04162896191811, 'env_to_module_sum_episodes_length_out': np.float64(32.307854540829815), 'num_module_steps_sampled': {'shared_policy': 2104}, 'episode_return_min': -162.12088861738425, 'weights_seq_no': 26.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.898338618390541e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7033882995580967e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4582196298873293e-05), 'numpy_to_tensor': np.float64(1.2852833750781817e-05), 'add_states_from_episodes_to_batch': np.float64(3.0258105783439512e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.2181190433879056e-06), 'batch_individual_items': np.float64(8.483339295976657e-06)}}}, 'episode_return_max': -45.889083269529856, 'episode_duration_sec_mean': 0.03659702985750016, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.044717582161779325), 'episode_len_mean': 75.0, 'num_episodes': 28, 'env_step_timer': np.float64(7.415205714617835e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 56770}, 'module_episode_returns_mean': {'shared_policy': -37.36689185129671}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.193991577420908e-05), 'num_episodes_lifetime': 737, 'num_env_steps_sampled_lifetime_throughput': 1149.6005682794407}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(1.5486722), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0029660373), 'num_module_steps_trained': 21888, 'vf_explained_var': np.float32(0.020244777), 'total_loss': np.float32(6.6077003), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 27.0, 'policy_loss': np.float32(0.028207548), 'vf_loss_unclipped': np.float32(79.274155), 'curr_kl_coeff': 1.4901161415892261e-09, 'entropy': np.float32(1.5669587), 'num_module_steps_trained_lifetime': 588544, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.5951624), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027897116695387206, 'add_one_ts_to_episodes_and_truncate': 0.007461848950704412, 'agent_to_module_mapping': 0.0018585723381788917, 'add_observations_from_episodes_to_batch': 0.0008104128210660863, 'add_states_from_episodes_to_batch': 5.708363092867549e-06, 'numpy_to_tensor': 0.00036076963470962046, 'batch_individual_items': 0.018643749725608103, 'add_time_dim_to_batch_and_zero_pad': 1.4532124241080564e-05, 'general_advantage_estimation': 0.00901533402824493}}, 'connector_pipeline_timer': 0.06627611394497979}, 'num_module_steps_trained': 21888, 'num_env_steps_trained': 350208, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 588544, 'num_env_steps_trained_lifetime': 9416704, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 55296, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1149.6005682794407, 'done': False, 'training_iteration': 27, 'trial_id': 'default', 'date': '2025-05-29_16-35-45', 'timestamp': 1748529345, 'time_this_iter_s': 1.7718760967254639, 'time_total_s': 48.54410004615784, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 48.54410004615784, 'iterations_since_restore': 27, 'perf': {'cpu_util_percent': np.float64(24.100000000000005), 'ram_util_percent': np.float64(81.76666666666667)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 28, Result: {'timers': {'training_iteration': 1.8229390463742163, 'restore_env_runners': 8.002599242862248e-06, 'training_step': 1.8228209007880822, 'env_runner_sampling_timer': 1.1395460044925179, 'learner_update_timer': 0.6811993201281841, 'synch_weights': 0.0010017408851461713, 'synch_env_connectors': 0.0008777738493717012}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -25.468392030668465, 'agent_0': -25.655892030668465, 'agent_1': -25.622142030668464}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.34236691620904), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 710, 'agent_0': 682}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06545338625578398), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.138387015452737e-07), 'module_to_agent_unmapping': np.float64(2.1022368578025588e-06), 'get_actions': np.float64(6.714091191510664e-05), 'normalize_and_clip_actions': np.float64(1.4668350480948584e-05), 'tensor_to_numpy': np.float64(2.5046593345550536e-05), 'un_batch_to_individual_items': np.float64(1.1309697895933543e-05), 'listify_data_for_vector_env': np.float64(5.1813698249660376e-06)}}, 'connector_pipeline_timer': np.float64(0.0001651222313358268)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 19879, 'agent_0': 19114, 'agent_1': 19879}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 57344, 'episode_return_mean': -76.74642609200541, 'env_to_module_sum_episodes_length_out': np.float64(32.34236691620904), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -127.20119133367542, 'weights_seq_no': 27.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.893220619758579e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.701914031917933e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4558738690534693e-05), 'numpy_to_tensor': np.float64(1.284801645887161e-05), 'add_states_from_episodes_to_batch': np.float64(3.023478720179224e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.214634106757891e-06), 'batch_individual_items': np.float64(8.478362467406227e-06)}}}, 'episode_return_max': -44.861927425464344, 'episode_duration_sec_mean': 0.03619141005749997, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.04497214552245515), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.410442281709047e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 58872}, 'module_episode_returns_mean': {'shared_policy': -38.045965230502254}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.173274919877278e-05), 'num_episodes_lifetime': 764, 'num_env_steps_sampled_lifetime_throughput': 1085.7156034773648}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(2.2210982), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0033720918), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(-0.064041734), 'total_loss': np.float32(6.6245503), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 28.0, 'policy_loss': np.float32(-0.025356393), 'vf_loss_unclipped': np.float32(58.277653), 'curr_kl_coeff': 7.450580707946131e-10, 'entropy': np.float32(1.5554), 'num_module_steps_trained_lifetime': 610304, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.665461), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.02789889361503003, 'add_one_ts_to_episodes_and_truncate': 0.007460945701670591, 'agent_to_module_mapping': 0.0018585983400043803, 'add_observations_from_episodes_to_batch': 0.0008104339441218909, 'add_states_from_episodes_to_batch': 5.705264873751824e-06, 'numpy_to_tensor': 0.0003602213711592039, 'batch_individual_items': 0.018687461245200845, 'add_time_dim_to_batch_and_zero_pad': 1.4532123604990374e-05, 'general_advantage_estimation': 0.00900535423848361}}, 'connector_pipeline_timer': 0.06630998248145757}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 610304, 'num_env_steps_trained_lifetime': 9764864, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 57344, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1085.7156034773648, 'done': False, 'training_iteration': 28, 'trial_id': 'default', 'date': '2025-05-29_16-35-47', 'timestamp': 1748529347, 'time_this_iter_s': 1.8785767555236816, 'time_total_s': 50.42267680168152, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 50.42267680168152, 'iterations_since_restore': 28, 'perf': {'cpu_util_percent': np.float64(21.5), 'ram_util_percent': np.float64(81.65)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 29, Result: {'timers': {'training_iteration': 1.822499352990474, 'restore_env_runners': 7.997983250455829e-06, 'training_step': 1.8223808846902014, 'env_runner_sampling_timer': 1.139630565697593, 'learner_update_timer': 0.6806732665169022, 'synch_weights': 0.001001885136294704, 'synch_env_connectors': 0.0008778140208779606}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -27.075299124005866, 'agent_0': -27.166549124005865, 'agent_1': -27.071549124005866}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.35061997659169), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 709, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06535130966022515), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.140575850035887e-07), 'module_to_agent_unmapping': np.float64(2.103562061956933e-06), 'get_actions': np.float64(6.684579953657092e-05), 'normalize_and_clip_actions': np.float64(1.4676611482843926e-05), 'tensor_to_numpy': np.float64(2.5065989945942584e-05), 'un_batch_to_individual_items': np.float64(1.131938892665469e-05), 'listify_data_for_vector_env': np.float64(5.185764414767415e-06)}}, 'connector_pipeline_timer': np.float64(0.00016488414101913803)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 20588, 'agent_0': 19797, 'agent_1': 20589}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 59392, 'episode_return_mean': -81.31339737201762, 'env_to_module_sum_episodes_length_out': np.float64(32.35061997659169), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -145.11198733098206, 'weights_seq_no': 28.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.897805144844993e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7014696599849113e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4560440456250826e-05), 'numpy_to_tensor': np.float64(1.2863884182477567e-05), 'add_states_from_episodes_to_batch': np.float64(3.0246580621546696e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.216249087127041e-06), 'batch_individual_items': np.float64(8.489395350157891e-06)}}}, 'episode_return_max': -49.73713620593438, 'episode_duration_sec_mean': 0.03662882129749999, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.04534619806566683), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.424607516814522e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 60974}, 'module_episode_returns_mean': {'shared_policy': -38.00841479405084}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.175370070848349e-05), 'num_episodes_lifetime': 791, 'num_env_steps_sampled_lifetime_throughput': 1143.8535995584666}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(3.239492), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0033137808), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(-0.013271809), 'total_loss': np.float32(6.234614), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 29.0, 'policy_loss': np.float32(0.034092274), 'vf_loss_unclipped': np.float32(80.27681), 'curr_kl_coeff': 3.7252903539730653e-10, 'entropy': np.float32(1.5545017), 'num_module_steps_trained_lifetime': 632064, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.2160664), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027900671651210462, 'add_one_ts_to_episodes_and_truncate': 0.007460005074422375, 'agent_to_module_mapping': 0.0018586231854595416, 'add_observations_from_episodes_to_batch': 0.0008104522867344733, 'add_states_from_episodes_to_batch': 5.702049382708844e-06, 'numpy_to_tensor': 0.00035965797511632475, 'batch_individual_items': 0.01873025113022917, 'add_time_dim_to_batch_and_zero_pad': 1.453191556919793e-05, 'general_advantage_estimation': 0.008995114648614692}}, 'connector_pipeline_timer': 0.0663426075941113}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 632064, 'num_env_steps_trained_lifetime': 10113024, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 59392, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1143.8535995584666, 'done': False, 'training_iteration': 29, 'trial_id': 'default', 'date': '2025-05-29_16-35-48', 'timestamp': 1748529348, 'time_this_iter_s': 1.7827258110046387, 'time_total_s': 52.20540261268616, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 52.20540261268616, 'iterations_since_restore': 29, 'perf': {'cpu_util_percent': np.float64(23.733333333333334), 'ram_util_percent': np.float64(81.66666666666667)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 30, Result: {'timers': {'training_iteration': 1.8219543223805692, 'restore_env_runners': 7.988003417916646e-06, 'training_step': 1.8218355937632993, 'env_runner_sampling_timer': 1.139581641710617, 'learner_update_timer': 0.6801760555217331, 'synch_weights': 0.00100182170493174, 'synch_env_connectors': 0.0008792275506691359}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -27.61482030437981, 'agent_0': -27.59357030437981, 'agent_1': -27.51732030437981}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.32797909356907), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 711, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06526943533052539), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.133374386877435e-07), 'module_to_agent_unmapping': np.float64(2.102711177768625e-06), 'get_actions': np.float64(6.644124679137519e-05), 'normalize_and_clip_actions': np.float64(1.4665088308977418e-05), 'tensor_to_numpy': np.float64(2.505266582396023e-05), 'un_batch_to_individual_items': np.float64(1.131440265076034e-05), 'listify_data_for_vector_env': np.float64(5.185579094577138e-06)}}, 'connector_pipeline_timer': np.float64(0.00016442625581295346)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 21299, 'agent_0': 20480, 'agent_1': 21299}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 61440, 'episode_return_mean': -82.72571091313941, 'env_to_module_sum_episodes_length_out': np.float64(32.32797909356907), 'num_module_steps_sampled': {'shared_policy': 2104}, 'episode_return_min': -149.36819655694472, 'weights_seq_no': 29.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.892283967552006e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.700192840661003e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4537793648045532e-05), 'numpy_to_tensor': np.float64(1.2855182043184043e-05), 'add_states_from_episodes_to_batch': np.float64(3.023409699397655e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.2135436766007564e-06), 'batch_individual_items': np.float64(8.484471581462142e-06)}}}, 'episode_return_max': -34.2407229177677, 'episode_duration_sec_mean': 0.036211338532499956, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.045647950282308024), 'episode_len_mean': 75.0, 'num_episodes': 28, 'env_step_timer': np.float64(7.419523556179144e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 63078}, 'module_episode_returns_mean': {'shared_policy': -41.02656627667416}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.157140528816502e-05), 'num_episodes_lifetime': 819, 'num_env_steps_sampled_lifetime_throughput': 1150.5225584699504}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(2.625818), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.003240794), 'num_module_steps_trained': 21888, 'vf_explained_var': np.float32(0.06411797), 'total_loss': np.float32(6.7081923), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 30.0, 'policy_loss': np.float32(-0.04842046), 'vf_loss_unclipped': np.float32(81.31705), 'curr_kl_coeff': 1.8626451769865326e-10, 'entropy': np.float32(1.5532975), 'num_module_steps_trained_lifetime': 653952, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.772146), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027902560929005782, 'add_one_ts_to_episodes_and_truncate': 0.007459089881848957, 'agent_to_module_mapping': 0.0018586525157715987, 'add_observations_from_episodes_to_batch': 0.0008104761691003926, 'add_states_from_episodes_to_batch': 5.698735974998669e-06, 'numpy_to_tensor': 0.0003590795915571864, 'batch_individual_items': 0.01877217917143241, 'add_time_dim_to_batch_and_zero_pad': 1.4531875181760664e-05, 'general_advantage_estimation': 0.008984610902619304}}, 'connector_pipeline_timer': 0.06637423501466382}, 'num_module_steps_trained': 21888, 'num_env_steps_trained': 350208, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 653952, 'num_env_steps_trained_lifetime': 10463232, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 61440, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1150.5225584699504, 'done': False, 'training_iteration': 30, 'trial_id': 'default', 'date': '2025-05-29_16-35-50', 'timestamp': 1748529350, 'time_this_iter_s': 1.7716143131256104, 'time_total_s': 53.97701692581177, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 53.97701692581177, 'iterations_since_restore': 30, 'perf': {'cpu_util_percent': np.float64(22.799999999999997), 'ram_util_percent': np.float64(81.8)}}
Checkpoint saved at TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/tegan/ray_results/simple_spread_rllib), metrics={'timers': {'training_iteration': 1.8219543223805692, 'restore_env_runners': 7.988003417916646e-06, 'training_step': 1.8218355937632993, 'env_runner_sampling_timer': 1.139581641710617, 'learner_update_timer': 0.6801760555217331, 'synch_weights': 0.00100182170493174, 'synch_env_connectors': 0.0008792275506691359}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -27.61482030437981, 'agent_0': -27.59357030437981, 'agent_1': -27.51732030437981}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.32797909356907), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 711, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06526943533052539), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.133374386877435e-07), 'module_to_agent_unmapping': np.float64(2.102711177768625e-06), 'get_actions': np.float64(6.644124679137519e-05), 'normalize_and_clip_actions': np.float64(1.4665088308977418e-05), 'tensor_to_numpy': np.float64(2.505266582396023e-05), 'un_batch_to_individual_items': np.float64(1.131440265076034e-05), 'listify_data_for_vector_env': np.float64(5.185579094577138e-06)}}, 'connector_pipeline_timer': np.float64(0.00016442625581295346)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 21299, 'agent_0': 20480, 'agent_1': 21299}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 61440, 'episode_return_mean': -82.72571091313941, 'env_to_module_sum_episodes_length_out': np.float64(32.32797909356907), 'num_module_steps_sampled': {'shared_policy': 2104}, 'episode_return_min': -149.36819655694472, 'weights_seq_no': 29.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.892283967552006e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.700192840661003e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4537793648045532e-05), 'numpy_to_tensor': np.float64(1.2855182043184043e-05), 'add_states_from_episodes_to_batch': np.float64(3.023409699397655e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.2135436766007564e-06), 'batch_individual_items': np.float64(8.484471581462142e-06)}}}, 'episode_return_max': -34.2407229177677, 'episode_duration_sec_mean': 0.036211338532499956, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.045647950282308024), 'episode_len_mean': 75.0, 'num_episodes': 28, 'env_step_timer': np.float64(7.419523556179144e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 63078}, 'module_episode_returns_mean': {'shared_policy': -41.02656627667416}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.157140528816502e-05), 'num_episodes_lifetime': 819, 'num_env_steps_sampled_lifetime_throughput': 1150.5225584699504}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(2.625818), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.003240794), 'num_module_steps_trained': 21888, 'vf_explained_var': np.float32(0.06411797), 'total_loss': np.float32(6.7081923), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 30.0, 'policy_loss': np.float32(-0.04842046), 'vf_loss_unclipped': np.float32(81.31705), 'curr_kl_coeff': 1.8626451769865326e-10, 'entropy': np.float32(1.5532975), 'num_module_steps_trained_lifetime': 653952, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.772146), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027902560929005782, 'add_one_ts_to_episodes_and_truncate': 0.007459089881848957, 'agent_to_module_mapping': 0.0018586525157715987, 'add_observations_from_episodes_to_batch': 0.0008104761691003926, 'add_states_from_episodes_to_batch': 5.698735974998669e-06, 'numpy_to_tensor': 0.0003590795915571864, 'batch_individual_items': 0.01877217917143241, 'add_time_dim_to_batch_and_zero_pad': 1.4531875181760664e-05, 'general_advantage_estimation': 0.008984610902619304}}, 'connector_pipeline_timer': 0.06637423501466382}, 'num_module_steps_trained': 21888, 'num_env_steps_trained': 350208, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 653952, 'num_env_steps_trained_lifetime': 10463232, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 61440, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1150.5225584699504, 'done': False, 'training_iteration': 30, 'trial_id': 'default', 'date': '2025-05-29_16-35-50', 'timestamp': 1748529350, 'time_this_iter_s': 1.7716143131256104, 'time_total_s': 53.97701692581177, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 53.97701692581177, 'iterations_since_restore': 30, 'perf': {'cpu_util_percent': np.float64(22.799999999999997), 'ram_util_percent': np.float64(81.8)}})
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 31, Result: {'timers': {'training_iteration': 1.8214821270767636, 'restore_env_runners': 8.001043383751854e-06, 'training_step': 1.821363049905666, 'env_runner_sampling_timer': 1.139512476953511, 'learner_update_timer': 0.6797716412165158, 'synch_weights': 0.0010013664078825438, 'synch_env_connectors': 0.0008801152751624476}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -27.687415833787, 'agent_0': -27.769915833787, 'agent_1': -27.681165833787}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.34832888424279), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 710, 'agent_0': 682}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06519087513274138), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.125604597320662e-07), 'module_to_agent_unmapping': np.float64(2.1020771785423617e-06), 'get_actions': np.float64(6.60774592711482e-05), 'normalize_and_clip_actions': np.float64(1.465020545455077e-05), 'tensor_to_numpy': np.float64(2.5043029085544764e-05), 'un_batch_to_individual_items': np.float64(1.1311122563386219e-05), 'listify_data_for_vector_env': np.float64(5.18350770293754e-06)}}, 'connector_pipeline_timer': np.float64(0.00016402013924124757)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 22009, 'agent_0': 21162, 'agent_1': 22009}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 63488, 'episode_return_mean': -83.13849750136102, 'env_to_module_sum_episodes_length_out': np.float64(32.34832888424279), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -188.8554703132288, 'weights_seq_no': 30.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.888099358575465e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7004322355773226e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4522867516297465e-05), 'numpy_to_tensor': np.float64(1.2851246368022011e-05), 'add_states_from_episodes_to_batch': np.float64(3.022660088389683e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.210640503095817e-06), 'batch_individual_items': np.float64(8.479168288064138e-06)}}}, 'episode_return_max': -44.41085443044978, 'episode_duration_sec_mean': 0.03618574682250102, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.04590331052838914), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.414896477987006e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 65180}, 'module_episode_returns_mean': {'shared_policy': -40.357468306937996}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.1417946186488676e-05), 'num_episodes_lifetime': 846, 'num_env_steps_sampled_lifetime_throughput': 1140.7755883569228}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(2.7135034), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0038234096), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(-0.17000926), 'total_loss': np.float32(6.984922), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 31.0, 'policy_loss': np.float32(-0.014098195), 'vf_loss_unclipped': np.float32(89.837654), 'curr_kl_coeff': 9.313225884932663e-11, 'entropy': np.float32(1.5484917), 'num_module_steps_trained_lifetime': 675712, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(7.0145054), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027904465604080074, 'add_one_ts_to_episodes_and_truncate': 0.0074581477759195665, 'agent_to_module_mapping': 0.0018586798346588676, 'add_observations_from_episodes_to_batch': 0.0008104980577903193, 'add_states_from_episodes_to_batch': 5.695377030505407e-06, 'numpy_to_tensor': 0.0003584871181717191, 'batch_individual_items': 0.018813243251698565, 'add_time_dim_to_batch_and_zero_pad': 1.4531690710515113e-05, 'general_advantage_estimation': 0.008973842307578962}}, 'connector_pipeline_timer': 0.06640469652194586}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 675712, 'num_env_steps_trained_lifetime': 10811392, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 63488, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1140.7755883569228, 'done': False, 'training_iteration': 31, 'trial_id': 'default', 'date': '2025-05-29_16-35-52', 'timestamp': 1748529352, 'time_this_iter_s': 1.7783501148223877, 'time_total_s': 55.755367040634155, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 55.755367040634155, 'iterations_since_restore': 31, 'perf': {'cpu_util_percent': np.float64(27.73333333333333), 'ram_util_percent': np.float64(81.86666666666666)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 32, Result: {'timers': {'training_iteration': 1.820836527055996, 'restore_env_runners': 7.996862949900234e-06, 'training_step': 1.8207172156566094, 'env_runner_sampling_timer': 1.139448431763976, 'learner_update_timer': 0.6791896193843507, 'synch_weights': 0.0010008285738037036, 'synch_env_connectors': 0.0008804899624108917}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -25.73824267519657, 'agent_0': -25.72949267519657, 'agent_1': -25.63699267519657}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.36577430859761), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 709, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06511802515350236), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.128288313748227e-07), 'module_to_agent_unmapping': np.float64(2.1030247170156966e-06), 'get_actions': np.float64(6.577270812733175e-05), 'normalize_and_clip_actions': np.float64(1.464155601592214e-05), 'tensor_to_numpy': np.float64(2.5037697657597865e-05), 'un_batch_to_individual_items': np.float64(1.1309344110169143e-05), 'listify_data_for_vector_env': np.float64(5.183423848984715e-06)}}, 'connector_pipeline_timer': np.float64(0.00016369021864681406)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 22718, 'agent_0': 21845, 'agent_1': 22719}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 65536, 'episode_return_mean': -77.10472802558971, 'env_to_module_sum_episodes_length_out': np.float64(32.36577430859761), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -127.29488648449197, 'weights_seq_no': 31.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.884785454773604e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7006103433855317e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4513789035529878e-05), 'numpy_to_tensor': np.float64(1.284450558352066e-05), 'add_states_from_episodes_to_batch': np.float64(3.0230134130403026e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.209025251917559e-06), 'batch_individual_items': np.float64(8.473204827512456e-06)}}}, 'episode_return_max': -41.121692011931664, 'episode_duration_sec_mean': 0.036232323375001416, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.046118818074325045), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.411781706497111e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 67282}, 'module_episode_returns_mean': {'shared_policy': -38.06365644498489}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.128851810026217e-05), 'num_episodes_lifetime': 873, 'num_env_steps_sampled_lifetime_throughput': 1157.9371417667273}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(3.2964988), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0035131194), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(0.1517806), 'total_loss': np.float32(6.586872), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 32.0, 'policy_loss': np.float32(0.04282891), 'vf_loss_unclipped': np.float32(66.87289), 'curr_kl_coeff': 4.6566129424663316e-11, 'entropy': np.float32(1.5471399), 'num_module_steps_trained_lifetime': 697472, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.559515), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027906402658659978, 'add_one_ts_to_episodes_and_truncate': 0.007457173198920579, 'agent_to_module_mapping': 0.0018587055169168136, 'add_observations_from_episodes_to_batch': 0.0008105193777895375, 'add_states_from_episodes_to_batch': 5.6919278913048905e-06, 'numpy_to_tensor': 0.00035788051969480524, 'batch_individual_items': 0.018853458161642255, 'add_time_dim_to_batch_and_zero_pad': 1.4531260841176807e-05, 'general_advantage_estimation': 0.008962826802549164}}, 'connector_pipeline_timer': 0.0664340382630808}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 697472, 'num_env_steps_trained_lifetime': 11159552, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 65536, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1157.9371417667273, 'done': False, 'training_iteration': 32, 'trial_id': 'default', 'date': '2025-05-29_16-35-54', 'timestamp': 1748529354, 'time_this_iter_s': 1.760580062866211, 'time_total_s': 57.515947103500366, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 57.515947103500366, 'iterations_since_restore': 32, 'perf': {'cpu_util_percent': np.float64(23.8), 'ram_util_percent': np.float64(82.05)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 33, Result: {'timers': {'training_iteration': 1.820193761785436, 'restore_env_runners': 7.987734320294e-06, 'training_step': 1.8200741760000432, 'env_runner_sampling_timer': 1.1393640395263362, 'learner_update_timer': 0.6786298736005074, 'synch_weights': 0.0010009890380655725, 'synch_env_connectors': 0.0008812213127868645}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -26.442201142331136, 'agent_0': -26.469701142331143, 'agent_1': -26.083451142331135}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.34886209051219), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 711, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06504871625995534), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.127109579786803e-07), 'module_to_agent_unmapping': np.float64(2.105144145918072e-06), 'get_actions': np.float64(6.547560668450369e-05), 'normalize_and_clip_actions': np.float64(1.4634732606061415e-05), 'tensor_to_numpy': np.float64(2.50226515936913e-05), 'un_batch_to_individual_items': np.float64(1.1303311132730863e-05), 'listify_data_for_vector_env': np.float64(5.181033165161495e-06)}}, 'connector_pipeline_timer': np.float64(0.0001633472583145286)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 23429, 'agent_0': 22528, 'agent_1': 23429}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 67584, 'episode_return_mean': -78.99535342699343, 'env_to_module_sum_episodes_length_out': np.float64(32.34886209051219), 'num_module_steps_sampled': {'shared_policy': 2104}, 'episode_return_min': -163.04567346810984, 'weights_seq_no': 32.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.88000288047061e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.699833008895751e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4498003381614662e-05), 'numpy_to_tensor': np.float64(1.283420928294716e-05), 'add_states_from_episodes_to_batch': np.float64(3.0215785066507138e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.206623667244758e-06), 'batch_individual_items': np.float64(8.466011045748656e-06)}}}, 'episode_return_max': -40.52749429695794, 'episode_duration_sec_mean': 0.03614807121999952, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.046275005536212825), 'episode_len_mean': 75.0, 'num_episodes': 28, 'env_step_timer': np.float64(7.407448572542609e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 69386}, 'module_episode_returns_mean': {'shared_policy': -38.36444872302943}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.117278692220629e-05), 'num_episodes_lifetime': 901, 'num_env_steps_sampled_lifetime_throughput': 1158.1728804884883}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(2.1194339), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0040046303), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(-0.13404906), 'total_loss': np.float32(6.879683), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 33.0, 'policy_loss': np.float32(0.0033932782), 'vf_loss_unclipped': np.float32(89.90845), 'curr_kl_coeff': 2.3283064712331658e-11, 'entropy': np.float32(1.5668517), 'num_module_steps_trained_lifetime': 719232, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.8919587), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027908361679687875, 'add_one_ts_to_episodes_and_truncate': 0.007456174098683979, 'agent_to_module_mapping': 0.0018587300216461355, 'add_observations_from_episodes_to_batch': 0.0008105396090829925, 'add_states_from_episodes_to_batch': 5.688386497186076e-06, 'numpy_to_tensor': 0.0003572595252756121, 'batch_individual_items': 0.0188928076490619, 'add_time_dim_to_batch_and_zero_pad': 1.4530544800154849e-05, 'general_advantage_estimation': 0.008951555635889206}}, 'connector_pipeline_timer': 0.06646223236644083}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 719232, 'num_env_steps_trained_lifetime': 11507712, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 67584, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1158.1728804884883, 'done': False, 'training_iteration': 33, 'trial_id': 'default', 'date': '2025-05-29_16-35-55', 'timestamp': 1748529355, 'time_this_iter_s': 1.7602558135986328, 'time_total_s': 59.276202917099, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 59.276202917099, 'iterations_since_restore': 33, 'perf': {'cpu_util_percent': np.float64(21.3), 'ram_util_percent': np.float64(82.1)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 34, Result: {'timers': {'training_iteration': 1.8198278958275818, 'restore_env_runners': 7.988686977064336e-06, 'training_step': 1.8197080200700426, 'env_runner_sampling_timer': 1.1392704178810729, 'learner_update_timer': 0.6783564944445023, 'synch_weights': 0.0010004612376849225, 'synch_env_connectors': 0.0008822207696590576}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -25.045986352844338, 'agent_0': -25.065986352844337, 'agent_1': -25.07223635284434}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.35020439088353), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 710, 'agent_0': 682}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06497888930804803), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.12599565661795e-07), 'module_to_agent_unmapping': np.float64(2.1040654759510186e-06), 'get_actions': np.float64(6.519444428883374e-05), 'normalize_and_clip_actions': np.float64(1.4621124812609696e-05), 'tensor_to_numpy': np.float64(2.4999579750404387e-05), 'un_batch_to_individual_items': np.float64(1.1297657109121956e-05), 'listify_data_for_vector_env': np.float64(5.180194988716382e-06)}}, 'connector_pipeline_timer': np.float64(0.00016299546667581887)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 24139, 'agent_0': 23210, 'agent_1': 24139}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 69632, 'episode_return_mean': -75.184209058533, 'env_to_module_sum_episodes_length_out': np.float64(32.35020439088353), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -130.77961704706163, 'weights_seq_no': 33.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.875509085034427e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.699962916313411e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4484572703492898e-05), 'numpy_to_tensor': np.float64(1.2825974940470574e-05), 'add_states_from_episodes_to_batch': np.float64(3.021450757691324e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.203834267076634e-06), 'batch_individual_items': np.float64(8.457477546172838e-06)}}}, 'episode_return_max': -41.650479553503374, 'episode_duration_sec_mean': 0.036078134612499646, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.046387022442423854), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.401921094394905e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 71488}, 'module_episode_returns_mean': {'shared_policy': -37.5001145239101}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.106681913347975e-05), 'num_episodes_lifetime': 928, 'num_env_steps_sampled_lifetime_throughput': 1140.8199109687646}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(2.7385733), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0036494264), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(-0.22000432), 'total_loss': np.float32(6.9199667), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 34.0, 'policy_loss': np.float32(0.16033773), 'vf_loss_unclipped': np.float32(73.02361), 'curr_kl_coeff': 1.1641532356165829e-11, 'entropy': np.float32(1.5549678), 'num_module_steps_trained_lifetime': 740992, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.775179), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.02791034995922935, 'add_one_ts_to_episodes_and_truncate': 0.007455139108932219, 'agent_to_module_mapping': 0.0018587535282291788, 'add_observations_from_episodes_to_batch': 0.0008105581921127986, 'add_states_from_episodes_to_batch': 5.6849133381612025e-06, 'numpy_to_tensor': 0.00035662477099283353, 'batch_individual_items': 0.018931315142616985, 'add_time_dim_to_batch_and_zero_pad': 1.4530048353868582e-05, 'general_advantage_estimation': 0.008940046459882191}}, 'connector_pipeline_timer': 0.06648931738810737}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 740992, 'num_env_steps_trained_lifetime': 11855872, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 69632, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1140.8199109687646, 'done': False, 'training_iteration': 34, 'trial_id': 'default', 'date': '2025-05-29_16-35-57', 'timestamp': 1748529357, 'time_this_iter_s': 1.7872560024261475, 'time_total_s': 61.06345891952515, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 61.06345891952515, 'iterations_since_restore': 34, 'perf': {'cpu_util_percent': np.float64(24.599999999999998), 'ram_util_percent': np.float64(82.03333333333333)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 35, Result: {'timers': {'training_iteration': 1.819451126869306, 'restore_env_runners': 8.016720107270196e-06, 'training_step': 1.819330674039342, 'env_runner_sampling_timer': 1.1392094312022623, 'learner_update_timer': 0.6780342145000573, 'synch_weights': 0.001002763705308158, 'synch_env_connectors': 0.000882582311962586}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -24.368792059198473, 'agent_0': -24.263792059198476, 'agent_1': -24.368792059198473}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.36440283980311), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 709, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06491574835178164), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.126810089053544e-07), 'module_to_agent_unmapping': np.float64(2.1035438954190953e-06), 'get_actions': np.float64(6.500731598823292e-05), 'normalize_and_clip_actions': np.float64(1.4616201509993835e-05), 'tensor_to_numpy': np.float64(2.4990050257222276e-05), 'un_batch_to_individual_items': np.float64(1.1297140903599481e-05), 'listify_data_for_vector_env': np.float64(5.180984382092708e-06)}}, 'connector_pipeline_timer': np.float64(0.0001627791955069534)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 24848, 'agent_0': 23893, 'agent_1': 24849}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 71680, 'episode_return_mean': -73.0013761775954, 'env_to_module_sum_episodes_length_out': np.float64(32.36440283980311), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -109.78931722557842, 'weights_seq_no': 34.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.873282904908201e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.70023232072307e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4478134568250675e-05), 'numpy_to_tensor': np.float64(1.2822679337788582e-05), 'add_states_from_episodes_to_batch': np.float64(3.021001866411444e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.199937828159547e-06), 'batch_individual_items': np.float64(8.453872533972715e-06)}}}, 'episode_return_max': -34.41631449102167, 'episode_duration_sec_mean': 0.03618686276999988, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.04650515447023751), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.399845313108488e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 73590}, 'module_episode_returns_mean': {'shared_policy': -36.34463307726617}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.097322557196591e-05), 'num_episodes_lifetime': 955, 'num_env_steps_sampled_lifetime_throughput': 1140.9550739713945}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(3.5612528), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0033505799), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(0.043666124), 'total_loss': np.float32(5.401092), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 35.0, 'policy_loss': np.float32(-0.02095762), 'vf_loss_unclipped': np.float32(41.218014), 'curr_kl_coeff': 5.8207661780829145e-12, 'entropy': np.float32(1.5549583), 'num_module_steps_trained_lifetime': 762752, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(5.437599), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027912366532812025, 'add_one_ts_to_episodes_and_truncate': 0.007454076697365624, 'agent_to_module_mapping': 0.0018587768082783964, 'add_observations_from_episodes_to_batch': 0.0008105755911211002, 'add_states_from_episodes_to_batch': 5.6813325036671875e-06, 'numpy_to_tensor': 0.0003559761400431822, 'batch_individual_items': 0.018968997901436063, 'add_time_dim_to_batch_and_zero_pad': 1.4529225382027334e-05, 'general_advantage_estimation': 0.008928296711831728}}, 'connector_pipeline_timer': 0.06651531579030394}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 762752, 'num_env_steps_trained_lifetime': 12204032, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 71680, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1140.9550739713945, 'done': False, 'training_iteration': 35, 'trial_id': 'default', 'date': '2025-05-29_16-35-59', 'timestamp': 1748529359, 'time_this_iter_s': 1.7870440483093262, 'time_total_s': 62.85050296783447, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 62.85050296783447, 'iterations_since_restore': 35, 'perf': {'cpu_util_percent': np.float64(21.5), 'ram_util_percent': np.float64(82.1)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 36, Result: {'timers': {'training_iteration': 1.8204838872706133, 'restore_env_runners': 8.068212906219787e-06, 'training_step': 1.8203627472989485, 'env_runner_sampling_timer': 1.1395172752302396, 'learner_update_timer': 0.6787576173550568, 'synch_weights': 0.0010025606482550339, 'synch_env_connectors': 0.0008894106588430502}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -26.401422229432647, 'agent_0': -26.347672229432646, 'agent_1': -26.443922229432648}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.34466016006355), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 711, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06489190227678678), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.150109279478308e-07), 'module_to_agent_unmapping': np.float64(2.109656580846345e-06), 'get_actions': np.float64(6.522013595261766e-05), 'normalize_and_clip_actions': np.float64(1.4662222259768668e-05), 'tensor_to_numpy': np.float64(2.507311469502876e-05), 'un_batch_to_individual_items': np.float64(1.132797313638077e-05), 'listify_data_for_vector_env': np.float64(5.1913398495384815e-06)}}, 'connector_pipeline_timer': np.float64(0.00016327574189013773)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 25559, 'agent_0': 24576, 'agent_1': 25559}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 73728, 'episode_return_mean': -79.19301668829792, 'env_to_module_sum_episodes_length_out': np.float64(32.34466016006355), 'num_module_steps_sampled': {'shared_policy': 2104}, 'episode_return_min': -122.17955419573488, 'weights_seq_no': 35.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.896171875788549e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.705680886839791e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4517317142312691e-05), 'numpy_to_tensor': np.float64(1.2888735975749217e-05), 'add_states_from_episodes_to_batch': np.float64(3.026349590524597e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.2173409569028424e-06), 'batch_individual_items': np.float64(8.488832462982181e-06)}}}, 'episode_return_max': -38.15833681339432, 'episode_duration_sec_mean': 0.037242812652500026, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.046625243349501765), 'episode_len_mean': 75.0, 'num_episodes': 28, 'env_step_timer': np.float64(7.430082928533714e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 75694}, 'module_episode_returns_mean': {'shared_policy': -41.125358086492064}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.127189211511422e-05), 'num_episodes_lifetime': 983, 'num_env_steps_sampled_lifetime_throughput': 1057.3159368853767}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(4.1524906), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.003575149), 'num_module_steps_trained': 21888, 'vf_explained_var': np.float32(-0.058071136), 'total_loss': np.float32(6.7919016), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 36.0, 'policy_loss': np.float32(0.12786976), 'vf_loss_unclipped': np.float32(71.464554), 'curr_kl_coeff': 2.9103830890414573e-12, 'entropy': np.float32(1.5593246), 'num_module_steps_trained_lifetime': 784640, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.6796255), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027914466923327125, 'add_one_ts_to_episodes_and_truncate': 0.007453004620119469, 'agent_to_module_mapping': 0.0018587997265738072, 'add_observations_from_episodes_to_batch': 0.0008105960238300246, 'add_states_from_episodes_to_batch': 5.677667294529617e-06, 'numpy_to_tensor': 0.0003553152151354247, 'batch_individual_items': 0.019017890786064497, 'add_time_dim_to_batch_and_zero_pad': 1.4529086664788206e-05, 'general_advantage_estimation': 0.008916318004096285}}, 'connector_pipeline_timer': 0.06655235563851776}, 'num_module_steps_trained': 21888, 'num_env_steps_trained': 350208, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 784640, 'num_env_steps_trained_lifetime': 12554240, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 73728, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1057.3159368853767, 'done': False, 'training_iteration': 36, 'trial_id': 'default', 'date': '2025-05-29_16-36-01', 'timestamp': 1748529361, 'time_this_iter_s': 1.9264321327209473, 'time_total_s': 64.77693510055542, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 64.77693510055542, 'iterations_since_restore': 36, 'perf': {'cpu_util_percent': np.float64(25.96666666666667), 'ram_util_percent': np.float64(82.2)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 37, Result: {'timers': {'training_iteration': 1.8199431525679073, 'restore_env_runners': 8.064610777140332e-06, 'training_step': 1.819821768155959, 'env_runner_sampling_timer': 1.1394616691379371, 'learner_update_timer': 0.6782715691015063, 'synch_weights': 0.0010020408717725353, 'synch_env_connectors': 0.0008902086322546274}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -24.8363718281584, 'agent_0': -25.063871828158398, 'agent_1': -24.915121828158394}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.340109897756456), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 710, 'agent_0': 682}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06487139551016272), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.147835190821846e-07), 'module_to_agent_unmapping': np.float64(2.1086641128645048e-06), 'get_actions': np.float64(6.504299609928542e-05), 'normalize_and_clip_actions': np.float64(1.465083927201601e-05), 'tensor_to_numpy': np.float64(2.5053319553748214e-05), 'un_batch_to_individual_items': np.float64(1.1322483288912481e-05), 'listify_data_for_vector_env': np.float64(5.191564616803741e-06)}}, 'connector_pipeline_timer': np.float64(0.0001630332154446805)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 26269, 'agent_0': 25258, 'agent_1': 26269}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 75776, 'episode_return_mean': -74.81536548447517, 'env_to_module_sum_episodes_length_out': np.float64(32.340109897756456), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -139.19067414547726, 'weights_seq_no': 36.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.89284637432193e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.704484724061611e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4508516402145489e-05), 'numpy_to_tensor': np.float64(1.2874526472071063e-05), 'add_states_from_episodes_to_batch': np.float64(3.0258134930484334e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.213438775282126e-06), 'batch_individual_items': np.float64(8.486633540398006e-06)}}}, 'episode_return_max': -40.46390081885304, 'episode_duration_sec_mean': 0.036176353697500614, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.04688074484664232), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.424849049710521e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 77796}, 'module_episode_returns_mean': {'shared_policy': -36.968685905162424}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.118068340789499e-05), 'num_episodes_lifetime': 1010, 'num_env_steps_sampled_lifetime_throughput': 1151.6758934266256}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(3.6998267), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0037335227), 'num_module_steps_trained': 21888, 'vf_explained_var': np.float32(0.007907331), 'total_loss': np.float32(6.1308093), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 37.0, 'policy_loss': np.float32(0.06109503), 'vf_loss_unclipped': np.float32(56.35723), 'curr_kl_coeff': 1.4551915445207286e-12, 'entropy': np.float32(1.5613711), 'num_module_steps_trained_lifetime': 806528, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.085328), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027916576444378643, 'add_one_ts_to_episodes_and_truncate': 0.007451903880948501, 'agent_to_module_mapping': 0.0018588212547224817, 'add_observations_from_episodes_to_batch': 0.0008106155194256575, 'add_states_from_episodes_to_batch': 5.67389895632451e-06, 'numpy_to_tensor': 0.0003546406819118176, 'batch_individual_items': 0.019065717125710223, 'add_time_dim_to_batch_and_zero_pad': 1.4528635299355627e-05, 'general_advantage_estimation': 0.00890410035334437}}, 'connector_pipeline_timer': 0.06658804766238828}, 'num_module_steps_trained': 21888, 'num_env_steps_trained': 350208, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 806528, 'num_env_steps_trained_lifetime': 12904448, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 75776, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1151.6758934266256, 'done': False, 'training_iteration': 37, 'trial_id': 'default', 'date': '2025-05-29_16-36-03', 'timestamp': 1748529363, 'time_this_iter_s': 1.7699358463287354, 'time_total_s': 66.54687094688416, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 66.54687094688416, 'iterations_since_restore': 37, 'perf': {'cpu_util_percent': np.float64(25.0), 'ram_util_percent': np.float64(82.05)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 38, Result: {'timers': {'training_iteration': 1.8198846960422284, 'restore_env_runners': 8.05271466933746e-06, 'training_step': 1.8197630688143995, 'env_runner_sampling_timer': 1.1394457166165577, 'learner_update_timer': 0.6782279917404912, 'synch_weights': 0.0010019887930548307, 'synch_env_connectors': 0.0008900402959320573}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -28.404542837623, 'agent_0': -28.420792837623004, 'agent_1': -28.498292837623}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.36985481516908), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 709, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.0648520060383327), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.151963717949628e-07), 'module_to_agent_unmapping': np.float64(2.1079538492452946e-06), 'get_actions': np.float64(6.493154649507096e-05), 'normalize_and_clip_actions': np.float64(1.4647529867493112e-05), 'tensor_to_numpy': np.float64(2.505088733292763e-05), 'un_batch_to_individual_items': np.float64(1.1322998200569778e-05), 'listify_data_for_vector_env': np.float64(5.190726057702087e-06)}}, 'connector_pipeline_timer': np.float64(0.00016290741683498754)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 26978, 'agent_0': 25941, 'agent_1': 26979}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 77824, 'episode_return_mean': -85.32362851286905, 'env_to_module_sum_episodes_length_out': np.float64(32.36985481516908), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -138.89759528497004, 'weights_seq_no': 37.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.893320790678673e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7036948767956685e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4506992180238696e-05), 'numpy_to_tensor': np.float64(1.2879335968520963e-05), 'add_states_from_episodes_to_batch': np.float64(3.0256121055810604e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.21483170720212e-06), 'batch_individual_items': np.float64(8.488166866070687e-06)}}}, 'episode_return_max': -40.46390081885304, 'episode_duration_sec_mean': 0.036409186424999615, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.04706090762770837), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.42422401626861e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 79898}, 'module_episode_returns_mean': {'shared_policy': -41.40613331797024}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.113715199119907e-05), 'num_episodes_lifetime': 1037, 'num_env_steps_sampled_lifetime_throughput': 1121.953736666063}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(2.5626662), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0034184633), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(-0.058176875), 'total_loss': np.float32(7.0487013), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 38.0, 'policy_loss': np.float32(0.06851058), 'vf_loss_unclipped': np.float32(64.005325), 'curr_kl_coeff': 7.275957722603643e-13, 'entropy': np.float32(1.558995), 'num_module_steps_trained_lifetime': 828288, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.9957805), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027918710965816797, 'add_one_ts_to_episodes_and_truncate': 0.0074507684018989394, 'agent_to_module_mapping': 0.0018588410182355248, 'add_observations_from_episodes_to_batch': 0.000810633523906994, 'add_states_from_episodes_to_batch': 5.670050718154433e-06, 'numpy_to_tensor': 0.000353952824531168, 'batch_individual_items': 0.019112476303684425, 'add_time_dim_to_batch_and_zero_pad': 1.4527902552565129e-05, 'general_advantage_estimation': 0.00889166437790708}}, 'connector_pipeline_timer': 0.06662242124771753}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 828288, 'num_env_steps_trained_lifetime': 13252608, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 77824, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1121.953736666063, 'done': False, 'training_iteration': 38, 'trial_id': 'default', 'date': '2025-05-29_16-36-05', 'timestamp': 1748529365, 'time_this_iter_s': 1.8177411556243896, 'time_total_s': 68.36461210250854, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 68.36461210250854, 'iterations_since_restore': 38, 'perf': {'cpu_util_percent': np.float64(22.03333333333333), 'ram_util_percent': np.float64(81.9)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 39, Result: {'timers': {'training_iteration': 1.819270669911806, 'restore_env_runners': 8.041767522645764e-06, 'training_step': 1.8191487914562556, 'env_runner_sampling_timer': 1.1393731644503922, 'learner_update_timer': 0.6776864539030865, 'synch_weights': 0.0010011226551241929, 'synch_env_connectors': 0.0008906748929728216}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -26.78793898125325, 'agent_0': -26.74543898125325, 'agent_1': -27.01168898125325}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.355823249397105), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 709, 'agent_2': 710, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06483016185073738), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.148727570180046e-07), 'module_to_agent_unmapping': np.float64(2.106360712246576e-06), 'get_actions': np.float64(6.479272603668876e-05), 'normalize_and_clip_actions': np.float64(1.4644438111602622e-05), 'tensor_to_numpy': np.float64(2.5034791497160725e-05), 'un_batch_to_individual_items': np.float64(1.1318899114923052e-05), 'listify_data_for_vector_env': np.float64(5.1880649598171115e-06)}}, 'connector_pipeline_timer': np.float64(0.00016272053593180963)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 27688, 'agent_0': 26624, 'agent_1': 27688}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 79872, 'episode_return_mean': -80.54506694375978, 'env_to_module_sum_episodes_length_out': np.float64(32.355823249397105), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -126.86238671048626, 'weights_seq_no': 38.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.888743103010715e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7014691457202182e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4493691520189384e-05), 'numpy_to_tensor': np.float64(1.2868266350849208e-05), 'add_states_from_episodes_to_batch': np.float64(3.025082186303183e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.210095391300708e-06), 'batch_individual_items': np.float64(8.484152191349886e-06)}}}, 'episode_return_max': -46.89538615544305, 'episode_duration_sec_mean': 0.036183351247501536, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.047244876705440864), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.419589150441278e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 82000}, 'module_episode_returns_mean': {'shared_policy': -39.84324229594003}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.105061920733903e-05), 'num_episodes_lifetime': 1064, 'num_env_steps_sampled_lifetime_throughput': 1156.2577207584993}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(2.5078552), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.00353749), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(0.07066232), 'total_loss': np.float32(6.9613743), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 39.0, 'policy_loss': np.float32(0.051928774), 'vf_loss_unclipped': np.float32(49.217087), 'curr_kl_coeff': 3.6379788613018216e-13, 'entropy': np.float32(1.5424825), 'num_module_steps_trained_lifetime': 850048, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.92487), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.02792087661838175, 'add_one_ts_to_episodes_and_truncate': 0.007449610612942276, 'agent_to_module_mapping': 0.0018588609709528352, 'add_observations_from_episodes_to_batch': 0.0008106502358467614, 'add_states_from_episodes_to_batch': 5.666128754852141e-06, 'numpy_to_tensor': 0.0003532532685299409, 'batch_individual_items': 0.01915823826808657, 'add_time_dim_to_batch_and_zero_pad': 1.4526964897180586e-05, 'general_advantage_estimation': 0.008879003691043202}}, 'connector_pipeline_timer': 0.06665556291487396}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 850048, 'num_env_steps_trained_lifetime': 13600768, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 79872, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1156.2577207584993, 'done': False, 'training_iteration': 39, 'trial_id': 'default', 'date': '2025-05-29_16-36-06', 'timestamp': 1748529366, 'time_this_iter_s': 1.7622129917144775, 'time_total_s': 70.12682509422302, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 70.12682509422302, 'iterations_since_restore': 39, 'perf': {'cpu_util_percent': np.float64(25.1), 'ram_util_percent': np.float64(81.55)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 40, Result: {'timers': {'training_iteration': 1.8187448752926878, 'restore_env_runners': 8.033429847414674e-06, 'training_step': 1.818622783121693, 'env_runner_sampling_timer': 1.1393186065558885, 'learner_update_timer': 0.6772138847740555, 'synch_weights': 0.0010003672585729233, 'synch_env_connectors': 0.0008918260640429596}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -26.532591358030405, 'agent_0': -26.603841358030408, 'agent_1': -26.58009135803041}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.32231909780917), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 711, 'agent_2': 711, 'agent_0': 682}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06480417943975815), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.155545672781614e-07), 'module_to_agent_unmapping': np.float64(2.103868257185231e-06), 'get_actions': np.float64(6.465468370706031e-05), 'normalize_and_clip_actions': np.float64(1.4640385918440283e-05), 'tensor_to_numpy': np.float64(2.5024792322792766e-05), 'un_batch_to_individual_items': np.float64(1.13149868723396e-05), 'listify_data_for_vector_env': np.float64(5.188889102404933e-06)}}, 'connector_pipeline_timer': np.float64(0.00016254212986466126)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 28399, 'agent_0': 27306, 'agent_1': 28399}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 81920, 'episode_return_mean': -79.71652407409121, 'env_to_module_sum_episodes_length_out': np.float64(32.32231909780917), 'num_module_steps_sampled': {'shared_policy': 2104}, 'episode_return_min': -128.57401375736012, 'weights_seq_no': 39.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.88658187825505e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.6997400311781944e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4495001587946211e-05), 'numpy_to_tensor': np.float64(1.2855619378286533e-05), 'add_states_from_episodes_to_batch': np.float64(3.024856569034445e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.207998860028729e-06), 'batch_individual_items': np.float64(8.481291962620473e-06)}}}, 'episode_return_max': -46.737131628120366, 'episode_duration_sec_mean': 0.03617195809999874, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.0473569871519734), 'episode_len_mean': 75.0, 'num_episodes': 28, 'env_step_timer': np.float64(7.414912805691713e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 84104}, 'module_episode_returns_mean': {'shared_policy': -39.66647567816918}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.0966319141475826e-05), 'num_episodes_lifetime': 1092, 'num_env_steps_sampled_lifetime_throughput': 1151.8251920978919}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(4.5213823), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0030346166), 'num_module_steps_trained': 21888, 'vf_explained_var': np.float32(-0.09188962), 'total_loss': np.float32(6.5267982), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0081967), 'weights_seq_no': 40.0, 'policy_loss': np.float32(-0.027490562), 'vf_loss_unclipped': np.float32(59.44981), 'curr_kl_coeff': 1.8189894306509108e-13, 'entropy': np.float32(1.5551239), 'num_module_steps_trained_lifetime': 871936, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.5698404), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.02792316579929882, 'add_one_ts_to_episodes_and_truncate': 0.0074484417820245554, 'agent_to_module_mapping': 0.0018588807364139756, 'add_observations_from_episodes_to_batch': 0.0008106704709953432, 'add_states_from_episodes_to_batch': 5.662134925744096e-06, 'numpy_to_tensor': 0.00035254253336628496, 'batch_individual_items': 0.019203021666370307, 'add_time_dim_to_batch_and_zero_pad': 1.4525747404648051e-05, 'general_advantage_estimation': 0.008866128255678812}}, 'connector_pipeline_timer': 0.06668761037736247}, 'num_module_steps_trained': 21888, 'num_env_steps_trained': 350208, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 871936, 'num_env_steps_trained_lifetime': 13950976, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 81920, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1151.8251920978919, 'done': False, 'training_iteration': 40, 'trial_id': 'default', 'date': '2025-05-29_16-36-08', 'timestamp': 1748529368, 'time_this_iter_s': 1.7702810764312744, 'time_total_s': 71.8971061706543, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 71.8971061706543, 'iterations_since_restore': 40, 'perf': {'cpu_util_percent': np.float64(24.23333333333333), 'ram_util_percent': np.float64(81.56666666666666)}}
Checkpoint saved at TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/tegan/ray_results/simple_spread_rllib), metrics={'timers': {'training_iteration': 1.8187448752926878, 'restore_env_runners': 8.033429847414674e-06, 'training_step': 1.818622783121693, 'env_runner_sampling_timer': 1.1393186065558885, 'learner_update_timer': 0.6772138847740555, 'synch_weights': 0.0010003672585729233, 'synch_env_connectors': 0.0008918260640429596}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -26.532591358030405, 'agent_0': -26.603841358030408, 'agent_1': -26.58009135803041}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.32231909780917), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 711, 'agent_2': 711, 'agent_0': 682}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06480417943975815), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.155545672781614e-07), 'module_to_agent_unmapping': np.float64(2.103868257185231e-06), 'get_actions': np.float64(6.465468370706031e-05), 'normalize_and_clip_actions': np.float64(1.4640385918440283e-05), 'tensor_to_numpy': np.float64(2.5024792322792766e-05), 'un_batch_to_individual_items': np.float64(1.13149868723396e-05), 'listify_data_for_vector_env': np.float64(5.188889102404933e-06)}}, 'connector_pipeline_timer': np.float64(0.00016254212986466126)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 28399, 'agent_0': 27306, 'agent_1': 28399}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 81920, 'episode_return_mean': -79.71652407409121, 'env_to_module_sum_episodes_length_out': np.float64(32.32231909780917), 'num_module_steps_sampled': {'shared_policy': 2104}, 'episode_return_min': -128.57401375736012, 'weights_seq_no': 39.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.88658187825505e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.6997400311781944e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4495001587946211e-05), 'numpy_to_tensor': np.float64(1.2855619378286533e-05), 'add_states_from_episodes_to_batch': np.float64(3.024856569034445e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.207998860028729e-06), 'batch_individual_items': np.float64(8.481291962620473e-06)}}}, 'episode_return_max': -46.737131628120366, 'episode_duration_sec_mean': 0.03617195809999874, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.0473569871519734), 'episode_len_mean': 75.0, 'num_episodes': 28, 'env_step_timer': np.float64(7.414912805691713e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 84104}, 'module_episode_returns_mean': {'shared_policy': -39.66647567816918}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.0966319141475826e-05), 'num_episodes_lifetime': 1092, 'num_env_steps_sampled_lifetime_throughput': 1151.8251920978919}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(4.5213823), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0030346166), 'num_module_steps_trained': 21888, 'vf_explained_var': np.float32(-0.09188962), 'total_loss': np.float32(6.5267982), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0081967), 'weights_seq_no': 40.0, 'policy_loss': np.float32(-0.027490562), 'vf_loss_unclipped': np.float32(59.44981), 'curr_kl_coeff': 1.8189894306509108e-13, 'entropy': np.float32(1.5551239), 'num_module_steps_trained_lifetime': 871936, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.5698404), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.02792316579929882, 'add_one_ts_to_episodes_and_truncate': 0.0074484417820245554, 'agent_to_module_mapping': 0.0018588807364139756, 'add_observations_from_episodes_to_batch': 0.0008106704709953432, 'add_states_from_episodes_to_batch': 5.662134925744096e-06, 'numpy_to_tensor': 0.00035254253336628496, 'batch_individual_items': 0.019203021666370307, 'add_time_dim_to_batch_and_zero_pad': 1.4525747404648051e-05, 'general_advantage_estimation': 0.008866128255678812}}, 'connector_pipeline_timer': 0.06668761037736247}, 'num_module_steps_trained': 21888, 'num_env_steps_trained': 350208, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 871936, 'num_env_steps_trained_lifetime': 13950976, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 81920, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1151.8251920978919, 'done': False, 'training_iteration': 40, 'trial_id': 'default', 'date': '2025-05-29_16-36-08', 'timestamp': 1748529368, 'time_this_iter_s': 1.7702810764312744, 'time_total_s': 71.8971061706543, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 71.8971061706543, 'iterations_since_restore': 40, 'perf': {'cpu_util_percent': np.float64(24.23333333333333), 'ram_util_percent': np.float64(81.56666666666666)}})
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 41, Result: {'timers': {'training_iteration': 1.8181189469597607, 'restore_env_runners': 8.033515548986459e-06, 'training_step': 1.817996654040476, 'env_runner_sampling_timer': 1.1392736575703295, 'learner_update_timer': 0.676632098846315, 'synch_weights': 0.0010003827459871219, 'synch_env_connectors': 0.0008919407234025683}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -28.36166088797035, 'agent_0': -28.30916088797035, 'agent_1': -28.404160887970352}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.34801108799435), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 709, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06477674660821008), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.166029572421351e-07), 'module_to_agent_unmapping': np.float64(2.1030174648387353e-06), 'get_actions': np.float64(6.455729739122297e-05), 'normalize_and_clip_actions': np.float64(1.4639914916140455e-05), 'tensor_to_numpy': np.float64(2.5030665319316224e-05), 'un_batch_to_individual_items': np.float64(1.1320710257801707e-05), 'listify_data_for_vector_env': np.float64(5.189491494076243e-06)}}, 'connector_pipeline_timer': np.float64(0.00016244931633651097)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 29108, 'agent_0': 27989, 'agent_1': 29109}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 83968, 'episode_return_mean': -85.07498266391113, 'env_to_module_sum_episodes_length_out': np.float64(32.34801108799435), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -130.68906530223882, 'weights_seq_no': 40.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.882789776420714e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.699949084754576e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4486723129622668e-05), 'numpy_to_tensor': np.float64(1.2846586750297756e-05), 'add_states_from_episodes_to_batch': np.float64(3.023594561764416e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.204054559545897e-06), 'batch_individual_items': np.float64(8.478879639730631e-06)}}}, 'episode_return_max': -34.45312896013382, 'episode_duration_sec_mean': 0.03619829093250182, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.04743383997688786), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.411087111131575e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 86206}, 'module_episode_returns_mean': {'shared_policy': -41.96541741252684}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.090877282322974e-05), 'num_episodes_lifetime': 1119, 'num_env_steps_sampled_lifetime_throughput': 1153.6530857297937}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(2.3560178), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0036599443), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(-0.08676267), 'total_loss': np.float32(6.6299186), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 41.0, 'policy_loss': np.float32(0.048740037), 'vf_loss_unclipped': np.float32(71.8115), 'curr_kl_coeff': 9.094947153254554e-14, 'entropy': np.float32(1.5311397), 'num_module_steps_trained_lifetime': 893696, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.59649), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027925473425635713, 'add_one_ts_to_episodes_and_truncate': 0.007447256062563894, 'agent_to_module_mapping': 0.001858898991268798, 'add_observations_from_episodes_to_batch': 0.0008106901656173688, 'add_states_from_episodes_to_batch': 5.658071060342744e-06, 'numpy_to_tensor': 0.0003518212541790488, 'batch_individual_items': 0.019246835477061557, 'add_time_dim_to_batch_and_zero_pad': 1.4524305665476957e-05, 'general_advantage_estimation': 0.008853046707852604}}, 'connector_pipeline_timer': 0.06671846566340973}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 893696, 'num_env_steps_trained_lifetime': 14299136, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 83968, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1153.6530857297937, 'done': False, 'training_iteration': 41, 'trial_id': 'default', 'date': '2025-05-29_16-36-10', 'timestamp': 1748529370, 'time_this_iter_s': 1.75972318649292, 'time_total_s': 73.65682935714722, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 73.65682935714722, 'iterations_since_restore': 41, 'perf': {'cpu_util_percent': np.float64(22.066666666666666), 'ram_util_percent': np.float64(81.56666666666666)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 42, Result: {'timers': {'training_iteration': 1.817602205820163, 'restore_env_runners': 8.021100393574088e-06, 'training_step': 1.8174797212500713, 'env_runner_sampling_timer': 1.139225695584626, 'learner_update_timer': 0.6761624661878518, 'synch_weights': 0.0010000105885273405, 'synch_env_connectors': 0.0008918817361685901}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -24.25754008806487, 'agent_0': -24.28504008806487, 'agent_1': -24.25629008806487}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.35800942552747), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 709, 'agent_2': 710, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06475216091991866), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.165236318781238e-07), 'module_to_agent_unmapping': np.float64(2.1023300257451613e-06), 'get_actions': np.float64(6.443812130099182e-05), 'normalize_and_clip_actions': np.float64(1.463839796832197e-05), 'tensor_to_numpy': np.float64(2.50088438770677e-05), 'un_batch_to_individual_items': np.float64(1.1317576832697942e-05), 'listify_data_for_vector_env': np.float64(5.18876846735141e-06)}}, 'connector_pipeline_timer': np.float64(0.00016228963853658117)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 29818, 'agent_0': 28672, 'agent_1': 29818}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 86016, 'episode_return_mean': -72.79887026419462, 'env_to_module_sum_episodes_length_out': np.float64(32.35800942552747), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -114.76650840593203, 'weights_seq_no': 41.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.882139193463646e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7025023197289722e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4486241415890639e-05), 'numpy_to_tensor': np.float64(1.2840542201132708e-05), 'add_states_from_episodes_to_batch': np.float64(3.0235978826075343e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.205319084022615e-06), 'batch_individual_items': np.float64(8.475189188476984e-06)}}}, 'episode_return_max': -31.278288077085815, 'episode_duration_sec_mean': 0.03627857879750167, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.0474586443073507), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.410368010122315e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 88308}, 'module_episode_returns_mean': {'shared_policy': -35.38534348446723}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.089222176445127e-05), 'num_episodes_lifetime': 1146, 'num_env_steps_sampled_lifetime_throughput': 1151.7698619844543}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(2.6520066), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0039314725), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(0.08682048), 'total_loss': np.float32(6.33132), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0085471), 'weights_seq_no': 42.0, 'policy_loss': np.float32(0.050175153), 'vf_loss_unclipped': np.float32(42.07238), 'curr_kl_coeff': 4.547473576627277e-14, 'entropy': np.float32(1.540265), 'num_module_steps_trained_lifetime': 915456, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.2965474), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.02792780875366594, 'add_one_ts_to_episodes_and_truncate': 0.007446054484214246, 'agent_to_module_mapping': 0.001858916209652882, 'add_observations_from_episodes_to_batch': 0.000810710661799854, 'add_states_from_episodes_to_batch': 5.653922258755835e-06, 'numpy_to_tensor': 0.0003510889671222218, 'batch_individual_items': 0.019289714276072345, 'add_time_dim_to_batch_and_zero_pad': 1.4522640186348632e-05, 'general_advantage_estimation': 0.008839751998957352}}, 'connector_pipeline_timer': 0.06674816789519833}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 915456, 'num_env_steps_trained_lifetime': 14647296, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 86016, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1151.7698619844543, 'done': False, 'training_iteration': 42, 'trial_id': 'default', 'date': '2025-05-29_16-36-12', 'timestamp': 1748529372, 'time_this_iter_s': 1.769958734512329, 'time_total_s': 75.42678809165955, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 75.42678809165955, 'iterations_since_restore': 42, 'perf': {'cpu_util_percent': np.float64(24.9), 'ram_util_percent': np.float64(81.8)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 43, Result: {'timers': {'training_iteration': 1.8170165387619615, 'restore_env_runners': 8.010049389676329e-06, 'training_step': 1.8168938319575705, 'env_runner_sampling_timer': 1.1391755511287798, 'learner_update_timer': 0.6756260881859733, 'synch_weights': 0.0009992821426420347, 'synch_env_connectors': 0.0008916941688068867}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -24.808760933565974, 'agent_0': -25.055010933565974, 'agent_1': -24.978760933565972}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.34025170241599), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 711, 'agent_2': 711, 'agent_0': 682}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06472574085480903), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.156076822646335e-07), 'module_to_agent_unmapping': np.float64(2.1021933695127856e-06), 'get_actions': np.float64(6.44012603499635e-05), 'normalize_and_clip_actions': np.float64(1.463600123698926e-05), 'tensor_to_numpy': np.float64(2.500919472469169e-05), 'un_batch_to_individual_items': np.float64(1.131602636772115e-05), 'listify_data_for_vector_env': np.float64(5.188080261135804e-06)}}, 'connector_pipeline_timer': np.float64(0.00016224629671361332)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 30529, 'agent_0': 29354, 'agent_1': 30529}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 88064, 'episode_return_mean': -74.8425328006979, 'env_to_module_sum_episodes_length_out': np.float64(32.34025170241599), 'num_module_steps_sampled': {'shared_policy': 2104}, 'episode_return_min': -141.86917239114211, 'weights_seq_no': 42.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.880367337846547e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7010287217226643e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4480366762580291e-05), 'numpy_to_tensor': np.float64(1.2832225724146252e-05), 'add_states_from_episodes_to_batch': np.float64(3.022364879650055e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.203061646186406e-06), 'batch_individual_items': np.float64(8.474690041491234e-06)}}}, 'episode_return_max': -38.907379655402345, 'episode_duration_sec_mean': 0.03623575809999931, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.047460712712691346), 'episode_len_mean': 75.0, 'num_episodes': 28, 'env_step_timer': np.float64(7.407303293645954e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 90412}, 'module_episode_returns_mean': {'shared_policy': -35.034579648908775}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.0843953242721534e-05), 'num_episodes_lifetime': 1174, 'num_env_steps_sampled_lifetime_throughput': 1155.4840461886106}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(1.795252), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.004739715), 'num_module_steps_trained': 21888, 'vf_explained_var': np.float32(-0.061855674), 'total_loss': np.float32(6.899465), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 43.0, 'policy_loss': np.float32(-0.0037378392), 'vf_loss_unclipped': np.float32(94.52024), 'curr_kl_coeff': 2.2737367883136385e-14, 'entropy': np.float32(1.538418), 'num_module_steps_trained_lifetime': 937344, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.9185867), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027930175173593, 'add_one_ts_to_episodes_and_truncate': 0.007444834741025332, 'agent_to_module_mapping': 0.0018589336978701563, 'add_observations_from_episodes_to_batch': 0.0008107319582421286, 'add_states_from_episodes_to_batch': 5.649690626093619e-06, 'numpy_to_tensor': 0.0003503458394811135, 'batch_individual_items': 0.01933162853225521, 'add_time_dim_to_batch_and_zero_pad': 1.4520726386236564e-05, 'general_advantage_estimation': 0.00882625580456922}}, 'connector_pipeline_timer': 0.0667767014899848}, 'num_module_steps_trained': 21888, 'num_env_steps_trained': 350208, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 937344, 'num_env_steps_trained_lifetime': 14997504, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 88064, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1155.4840461886106, 'done': False, 'training_iteration': 43, 'trial_id': 'default', 'date': '2025-05-29_16-36-13', 'timestamp': 1748529373, 'time_this_iter_s': 1.76265287399292, 'time_total_s': 77.18944096565247, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 77.18944096565247, 'iterations_since_restore': 43, 'perf': {'cpu_util_percent': np.float64(22.7), 'ram_util_percent': np.float64(81.73333333333333)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 44, Result: {'timers': {'training_iteration': 1.8194890233743417, 'restore_env_runners': 7.99536889586337e-06, 'training_step': 1.8193659436379948, 'env_runner_sampling_timer': 1.141064623117492, 'learner_update_timer': 0.6762060752241135, 'synch_weights': 0.001000951821215586, 'synch_env_connectors': 0.0008918184771188704}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -24.011738188904147, 'agent_0': -24.104238188904148, 'agent_1': -24.092988188904148}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.35581681491613), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 709, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06476488670950648), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.19361808776241e-07), 'module_to_agent_unmapping': np.float64(2.115003532460101e-06), 'get_actions': np.float64(6.498526796254701e-05), 'normalize_and_clip_actions': np.float64(1.4706506195968703e-05), 'tensor_to_numpy': np.float64(2.516343718168115e-05), 'un_batch_to_individual_items': np.float64(1.1358103101805563e-05), 'listify_data_for_vector_env': np.float64(5.203192435642045e-06)}}, 'connector_pipeline_timer': np.float64(0.00016332111161000584)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 31238, 'agent_0': 30037, 'agent_1': 31239}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 90112, 'episode_return_mean': -72.2089645667124, 'env_to_module_sum_episodes_length_out': np.float64(32.35581681491613), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -133.4560349023875, 'weights_seq_no': 43.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(7.933004802661468e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.713580626693654e-06), 'add_observations_from_episodes_to_batch': np.float64(1.456036347464382e-05), 'numpy_to_tensor': np.float64(1.2944694105099664e-05), 'add_states_from_episodes_to_batch': np.float64(3.11826621336271e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.2311810493909485e-06), 'batch_individual_items': np.float64(8.529605421884559e-06)}}}, 'episode_return_max': -40.985143425808445, 'episode_duration_sec_mean': 0.03794361099749896, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.04751439795067369), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.464297349553495e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 92514}, 'module_episode_returns_mean': {'shared_policy': -35.246762743392935}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.128452747789385e-05), 'num_episodes_lifetime': 1201, 'num_env_steps_sampled_lifetime_throughput': 986.5782051961241}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(2.1108773), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.00463738), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(-0.024070501), 'total_loss': np.float32(6.5990195), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 44.0, 'policy_loss': np.float32(0.11690903), 'vf_loss_unclipped': np.float32(75.6773), 'curr_kl_coeff': 1.1368683941568192e-14, 'entropy': np.float32(1.5343312), 'num_module_steps_trained_lifetime': 959104, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.4974546), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027932756046746148, 'add_one_ts_to_episodes_and_truncate': 0.007443623908051777, 'agent_to_module_mapping': 0.0018589614364021194, 'add_observations_from_episodes_to_batch': 0.0008107573159893781, 'add_states_from_episodes_to_batch': 5.645428233859057e-06, 'numpy_to_tensor': 0.00034959771549611645, 'batch_individual_items': 0.01937272052768681, 'add_time_dim_to_batch_and_zero_pad': 1.4518944398107394e-05, 'general_advantage_estimation': 0.008812716958868956}}, 'connector_pipeline_timer': 0.06680460539608603}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 959104, 'num_env_steps_trained_lifetime': 15345664, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 90112, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 986.5782051961241, 'done': False, 'training_iteration': 44, 'trial_id': 'default', 'date': '2025-05-29_16-36-16', 'timestamp': 1748529376, 'time_this_iter_s': 2.067957878112793, 'time_total_s': 79.25739884376526, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 79.25739884376526, 'iterations_since_restore': 44, 'perf': {'cpu_util_percent': np.float64(33.199999999999996), 'ram_util_percent': np.float64(81.43333333333334)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 45, Result: {'timers': {'training_iteration': 1.8207791652205982, 'restore_env_runners': 8.009585206915954e-06, 'training_step': 1.8206556275416148, 'env_runner_sampling_timer': 1.142258974386317, 'learner_update_timer': 0.6762957478018723, 'synch_weights': 0.001002788553003364, 'synch_env_connectors': 0.0008922715423476116}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -26.62721666841346, 'agent_0': -26.74346666841346, 'agent_1': -26.678466668413463}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.36903693648237), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 709, 'agent_2': 710, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06486196852446943), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.287855717996878e-07), 'module_to_agent_unmapping': np.float64(2.1331227993420537e-06), 'get_actions': np.float64(6.647966390443352e-05), 'normalize_and_clip_actions': np.float64(1.4902261367203236e-05), 'tensor_to_numpy': np.float64(2.568029674269631e-05), 'un_batch_to_individual_items': np.float64(1.1580881408351696e-05), 'listify_data_for_vector_env': np.float64(5.241971799371581e-06)}}, 'connector_pipeline_timer': np.float64(0.00016622685861211208)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 31948, 'agent_0': 30720, 'agent_1': 31948}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 92160, 'episode_return_mean': -80.04915000524038, 'env_to_module_sum_episodes_length_out': np.float64(32.36903693648237), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -146.08173033660967, 'weights_seq_no': 44.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(8.060218863221248e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7366640219341234e-06), 'add_observations_from_episodes_to_batch': np.float64(1.472413690175844e-05), 'numpy_to_tensor': np.float64(1.3411255174321483e-05), 'add_states_from_episodes_to_batch': np.float64(3.135045507760439e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.315343567728008e-06), 'batch_individual_items': np.float64(8.75045795716656e-06)}}}, 'episode_return_max': -44.250002093786655, 'episode_duration_sec_mean': 0.04000109201999869, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.04779761037678808), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.566249607948487e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 94616}, 'module_episode_returns_mean': {'shared_policy': -39.779663773016615}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.233045664815429e-05), 'num_episodes_lifetime': 1228, 'num_env_steps_sampled_lifetime_throughput': 1044.746977254441}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(3.0202234), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.004691513), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(-0.22739291), 'total_loss': np.float32(6.1698637), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 45.0, 'policy_loss': np.float32(-0.068326816), 'vf_loss_unclipped': np.float32(65.37525), 'curr_kl_coeff': 5.684341970784096e-15, 'entropy': np.float32(1.5351459), 'num_module_steps_trained_lifetime': 980864, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.2535424), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027935420022418875, 'add_one_ts_to_episodes_and_truncate': 0.0074424155457635905, 'agent_to_module_mapping': 0.001858991276793656, 'add_observations_from_episodes_to_batch': 0.0008107863974858582, 'add_states_from_episodes_to_batch': 5.641223620406641e-06, 'numpy_to_tensor': 0.00034884044440687203, 'batch_individual_items': 0.019412895878656553, 'add_time_dim_to_batch_and_zero_pad': 1.4517741777101762e-05, 'general_advantage_estimation': 0.00879901206450224}}, 'connector_pipeline_timer': 0.06683150812891624}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 980864, 'num_env_steps_trained_lifetime': 15693824, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 92160, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1044.746977254441, 'done': False, 'training_iteration': 45, 'trial_id': 'default', 'date': '2025-05-29_16-36-17', 'timestamp': 1748529377, 'time_this_iter_s': 1.9522850513458252, 'time_total_s': 81.20968389511108, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 81.20968389511108, 'iterations_since_restore': 45, 'perf': {'cpu_util_percent': np.float64(32.0), 'ram_util_percent': np.float64(82.0)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 46, Result: {'timers': {'training_iteration': 1.8203987948183922, 'restore_env_runners': 8.03865935482014e-06, 'training_step': 1.8202748733461986, 'env_runner_sampling_timer': 1.1423598683924538, 'learner_update_timer': 0.6758131449138536, 'synch_weights': 0.0010024506674733082, 'synch_env_connectors': 0.0008936184069241063}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -24.440683700197436, 'agent_0': -24.416933700197433, 'agent_1': -24.376933700197437}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.35429572039532), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 711, 'agent_2': 711, 'agent_0': 682}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06503385671346097), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.281208390865706e-07), 'module_to_agent_unmapping': np.float64(2.133145852102694e-06), 'get_actions': np.float64(6.62585710597657e-05), 'normalize_and_clip_actions': np.float64(1.4890268566802955e-05), 'tensor_to_numpy': np.float64(2.5630508627392862e-05), 'un_batch_to_individual_items': np.float64(1.15563360545819e-05), 'listify_data_for_vector_env': np.float64(5.2425041057756604e-06)}}, 'connector_pipeline_timer': np.float64(0.00016588490692314592)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 32659, 'agent_0': 31402, 'agent_1': 32659}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 94208, 'episode_return_mean': -73.23455110059231, 'env_to_module_sum_episodes_length_out': np.float64(32.35429572039532), 'num_module_steps_sampled': {'shared_policy': 2104}, 'episode_return_min': -158.0122199970419, 'weights_seq_no': 45.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(8.047365507932531e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7351262130595295e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4713232638312707e-05), 'numpy_to_tensor': np.float64(1.3350271506435699e-05), 'add_states_from_episodes_to_batch': np.float64(3.1217147946425607e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.306922009213516e-06), 'batch_individual_items': np.float64(8.727336830471483e-06)}}}, 'episode_return_max': -41.42398547443218, 'episode_duration_sec_mean': 0.03685488270750298, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.04806572855744318), 'episode_len_mean': 75.0, 'num_episodes': 28, 'env_step_timer': np.float64(7.555010105893143e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 96720}, 'module_episode_returns_mean': {'shared_policy': -37.41778845330455}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.223172422818434e-05), 'num_episodes_lifetime': 1256, 'num_env_steps_sampled_lifetime_throughput': 1140.2310958362716}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(3.074399), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0031453816), 'num_module_steps_trained': 21888, 'vf_explained_var': np.float32(-0.022291541), 'total_loss': np.float32(6.118206), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 46.0, 'policy_loss': np.float32(0.046755355), 'vf_loss_unclipped': np.float32(61.887577), 'curr_kl_coeff': 2.842170985392048e-15, 'entropy': np.float32(1.5373508), 'num_module_steps_trained_lifetime': 1002752, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.086824), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027938136305473472, 'add_one_ts_to_episodes_and_truncate': 0.007441204221630362, 'agent_to_module_mapping': 0.0018592573783337224, 'add_observations_from_episodes_to_batch': 0.0008108171341208099, 'add_states_from_episodes_to_batch': 5.636984356400536e-06, 'numpy_to_tensor': 0.00034807269646786347, 'batch_individual_items': 0.019452178446354135, 'add_time_dim_to_batch_and_zero_pad': 1.4516515514076798e-05, 'general_advantage_estimation': 0.008785131946326971}}, 'connector_pipeline_timer': 0.06685761596325022}, 'num_module_steps_trained': 21888, 'num_env_steps_trained': 350208, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 1002752, 'num_env_steps_trained_lifetime': 16044032, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 94208, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1140.2310958362716, 'done': False, 'training_iteration': 46, 'trial_id': 'default', 'date': '2025-05-29_16-36-19', 'timestamp': 1748529379, 'time_this_iter_s': 1.7863261699676514, 'time_total_s': 82.99601006507874, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 82.99601006507874, 'iterations_since_restore': 46, 'perf': {'cpu_util_percent': np.float64(26.2), 'ram_util_percent': np.float64(82.03333333333333)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 47, Result: {'timers': {'training_iteration': 1.8198224168702082, 'restore_env_runners': 8.038692761175763e-06, 'training_step': 1.8196982458627367, 'env_runner_sampling_timer': 1.1422752130485292, 'learner_update_timer': 0.6753210580447151, 'synch_weights': 0.0010021195007984738, 'synch_env_connectors': 0.0008938830528548343}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -25.955764589118434, 'agent_0': -26.008264589118436, 'agent_1': -25.965764589118436}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.35872181450021), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 709, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06515124143335731), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.25795837815852e-07), 'module_to_agent_unmapping': np.float64(2.1293106492117833e-06), 'get_actions': np.float64(6.592384869427004e-05), 'normalize_and_clip_actions': np.float64(1.4849209336046779e-05), 'tensor_to_numpy': np.float64(2.552155035161758e-05), 'un_batch_to_individual_items': np.float64(1.1518620105265375e-05), 'listify_data_for_vector_env': np.float64(5.233746044016994e-06)}}, 'connector_pipeline_timer': np.float64(0.00016524782450606608)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 33368, 'agent_0': 32085, 'agent_1': 33369}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 96256, 'episode_return_mean': -77.9297937673553, 'env_to_module_sum_episodes_length_out': np.float64(32.35872181450021), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -151.4648821485248, 'weights_seq_no': 46.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(8.023368850361593e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7295955011214956e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4685398007879232e-05), 'numpy_to_tensor': np.float64(1.3274354586500295e-05), 'add_states_from_episodes_to_batch': np.float64(3.1090124072676146e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.2924320624861285e-06), 'batch_individual_items': np.float64(8.690284284783922e-06)}}}, 'episode_return_max': -42.878719167089955, 'episode_duration_sec_mean': 0.036236277087500886, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.04822784621211971), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.533572770190524e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 98822}, 'module_episode_returns_mean': {'shared_policy': -38.37748429738626}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.20011977216274e-05), 'num_episodes_lifetime': 1283, 'num_env_steps_sampled_lifetime_throughput': 1154.340587437289}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(5.0873623), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.004138002), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(0.054998815), 'total_loss': np.float32(5.9906282), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 47.0, 'policy_loss': np.float32(-0.023652706), 'vf_loss_unclipped': np.float32(44.80183), 'curr_kl_coeff': 1.421085492696024e-15, 'entropy': np.float32(1.5366025), 'num_module_steps_trained_lifetime': 1024512, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.029648), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027940871679164737, 'add_one_ts_to_episodes_and_truncate': 0.007439963840725222, 'agent_to_module_mapping': 0.001859519096215308, 'add_observations_from_episodes_to_batch': 0.0008108458523833146, 'add_states_from_episodes_to_batch': 5.632669955312559e-06, 'numpy_to_tensor': 0.0003472957777431942, 'batch_individual_items': 0.019490571635609896, 'add_time_dim_to_batch_and_zero_pad': 1.4515028702135587e-05, 'general_advantage_estimation': 0.008771081366808757}}, 'connector_pipeline_timer': 0.06688263325678463}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 1024512, 'num_env_steps_trained_lifetime': 16392192, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 96256, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1154.340587437289, 'done': False, 'training_iteration': 47, 'trial_id': 'default', 'date': '2025-05-29_16-36-21', 'timestamp': 1748529381, 'time_this_iter_s': 1.7662689685821533, 'time_total_s': 84.76227903366089, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 84.76227903366089, 'iterations_since_restore': 47, 'perf': {'cpu_util_percent': np.float64(20.2), 'ram_util_percent': np.float64(81.95)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 48, Result: {'timers': {'training_iteration': 1.819315942281506, 'restore_env_runners': 8.031635833556216e-06, 'training_step': 1.8191915584041092, 'env_runner_sampling_timer': 1.142273174258044, 'learner_update_timer': 0.6748156532942677, 'synch_weights': 0.001002152055790543, 'synch_env_connectors': 0.0008929983823263431}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -25.774561165622007, 'agent_0': -25.974561165622013, 'agent_1': -25.964561165622012}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.37232319215132), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 709, 'agent_2': 710, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06522497339174649), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.240110473406247e-07), 'module_to_agent_unmapping': np.float64(2.1263179584588776e-06), 'get_actions': np.float64(6.576401331898306e-05), 'normalize_and_clip_actions': np.float64(1.4832243509484508e-05), 'tensor_to_numpy': np.float64(2.5470221581453837e-05), 'un_batch_to_individual_items': np.float64(1.1493425621158421e-05), 'listify_data_for_vector_env': np.float64(5.229613394252187e-06)}}, 'connector_pipeline_timer': np.float64(0.0001649479860041429)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 34078, 'agent_0': 32768, 'agent_1': 34078}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 98304, 'episode_return_mean': -77.71368349686604, 'env_to_module_sum_episodes_length_out': np.float64(32.37232319215132), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -109.36499818087438, 'weights_seq_no': 47.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(8.009199524823817e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7274609718075618e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4665106656451006e-05), 'numpy_to_tensor': np.float64(1.3224258562235357e-05), 'add_states_from_episodes_to_batch': np.float64(3.0977373811888413e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.2842960320953046e-06), 'batch_individual_items': np.float64(8.671648482324999e-06)}}}, 'episode_return_max': -47.37362721996207, 'episode_duration_sec_mean': 0.036524812280000346, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.04830691226728428), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.520639177813309e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 100924}, 'module_episode_returns_mean': {'shared_policy': -36.758420488885825}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.186241605696156e-05), 'num_episodes_lifetime': 1310, 'num_env_steps_sampled_lifetime_throughput': 1149.9417930683487}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(5.739793), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0041318843), 'num_module_steps_trained': 21760, 'vf_explained_var': np.float32(-0.08944881), 'total_loss': np.float32(7.082211), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 48.0, 'policy_loss': np.float32(0.014151752), 'vf_loss_unclipped': np.float32(61.148598), 'curr_kl_coeff': 7.10542746348012e-16, 'entropy': np.float32(1.5346272), 'num_module_steps_trained_lifetime': 1046272, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(7.0834055), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.02794362791925163, 'add_one_ts_to_episodes_and_truncate': 0.007438705817816021, 'agent_to_module_mapping': 0.0018597770832014283, 'add_observations_from_episodes_to_batch': 0.0008108730686671573, 'add_states_from_episodes_to_batch': 5.628273943811477e-06, 'numpy_to_tensor': 0.00034650875262337116, 'batch_individual_items': 0.01952808833073591, 'add_time_dim_to_batch_and_zero_pad': 1.4513215774882221e-05, 'general_advantage_estimation': 0.008756862885686275}}, 'connector_pipeline_timer': 0.06690658846785204}, 'num_module_steps_trained': 21760, 'num_env_steps_trained': 348160, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 1046272, 'num_env_steps_trained_lifetime': 16740352, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 98304, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1149.9417930683487, 'done': False, 'training_iteration': 48, 'trial_id': 'default', 'date': '2025-05-29_16-36-23', 'timestamp': 1748529383, 'time_this_iter_s': 1.7727680206298828, 'time_total_s': 86.53504705429077, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 86.53504705429077, 'iterations_since_restore': 48, 'perf': {'cpu_util_percent': np.float64(23.366666666666664), 'ram_util_percent': np.float64(81.9)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 49, Result: {'timers': {'training_iteration': 1.820377095778691, 'restore_env_runners': 8.035479475220764e-06, 'training_step': 1.820252144070068, 'env_runner_sampling_timer': 1.1426807887654638, 'learner_update_timer': 0.675456777181325, 'synch_weights': 0.0010103055352325091, 'synch_env_connectors': 0.0008934708985030727}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -27.470513538052582, 'agent_0': -27.531763538052576, 'agent_1': -27.470513538052582}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.348129628340914), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 711, 'agent_2': 711, 'agent_0': 682}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06529521036836032), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.253036770727856e-07), 'module_to_agent_unmapping': np.float64(2.1322751631797126e-06), 'get_actions': np.float64(6.600665695037091e-05), 'normalize_and_clip_actions': np.float64(1.4874792573024096e-05), 'tensor_to_numpy': np.float64(2.552594551170913e-05), 'un_batch_to_individual_items': np.float64(1.1510058494094562e-05), 'listify_data_for_vector_env': np.float64(5.241797353174816e-06)}}, 'connector_pipeline_timer': np.float64(0.00016537718059263134)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 34789, 'agent_0': 33450, 'agent_1': 34789}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 100352, 'episode_return_mean': -82.47279061415772, 'env_to_module_sum_episodes_length_out': np.float64(32.348129628340914), 'num_module_steps_sampled': {'shared_policy': 2104}, 'episode_return_min': -194.336580799172, 'weights_seq_no': 48.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(8.030092763528375e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.7331085640157987e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4721396400431428e-05), 'numpy_to_tensor': np.float64(1.3262138288198656e-05), 'add_states_from_episodes_to_batch': np.float64(3.0956172199428747e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.300413994068685e-06), 'batch_individual_items': np.float64(8.700542051129947e-06)}}}, 'episode_return_max': -39.94518649095801, 'episode_duration_sec_mean': 0.03743243166000077, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.04832482025974352), 'episode_len_mean': 75.0, 'num_episodes': 28, 'env_step_timer': np.float64(7.545137653447238e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 103028}, 'module_episode_returns_mean': {'shared_policy': -39.92145072374579}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.2037635333310115e-05), 'num_episodes_lifetime': 1338, 'num_env_steps_sampled_lifetime_throughput': 1056.7776998158888}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(2.093801), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0042119757), 'num_module_steps_trained': 21888, 'vf_explained_var': np.float32(0.10018003), 'total_loss': np.float32(5.9667425), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 49.0, 'policy_loss': np.float32(0.11406448), 'vf_loss_unclipped': np.float32(119.55019), 'curr_kl_coeff': 3.55271373174006e-16, 'entropy': np.float32(1.525894), 'num_module_steps_trained_lifetime': 1068160, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(5.8679366), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027946486384868862, 'add_one_ts_to_episodes_and_truncate': 0.007437470133980931, 'agent_to_module_mapping': 0.0018600344210382056, 'add_observations_from_episodes_to_batch': 0.0008109035977400845, 'add_states_from_episodes_to_batch': 5.62383178554487e-06, 'numpy_to_tensor': 0.0003457137884281707, 'batch_individual_items': 0.01956478478479584, 'add_time_dim_to_batch_and_zero_pad': 1.4511541703303332e-05, 'general_advantage_estimation': 0.008742504216049562}}, 'connector_pipeline_timer': 0.06692970266137241}, 'num_module_steps_trained': 21888, 'num_env_steps_trained': 350208, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 1068160, 'num_env_steps_trained_lifetime': 17090560, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 100352, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1056.7776998158888, 'done': False, 'training_iteration': 49, 'trial_id': 'default', 'date': '2025-05-29_16-36-25', 'timestamp': 1748529385, 'time_this_iter_s': 1.9322211742401123, 'time_total_s': 88.46726822853088, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 88.46726822853088, 'iterations_since_restore': 49, 'perf': {'cpu_util_percent': np.float64(30.266666666666666), 'ram_util_percent': np.float64(81.8)}}
RLlib Result Keys: dict_keys(['timers', 'env_runners', 'learners', 'num_training_step_calls_per_iteration', 'num_env_steps_sampled_lifetime', 'fault_tolerance', 'env_runner_group', 'num_env_steps_sampled_lifetime_throughput', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'config', 'time_since_restore', 'iterations_since_restore', 'perf'])
Iter: 50, Result: {'timers': {'training_iteration': 1.8207123414809039, 'restore_env_runners': 8.076374680446647e-06, 'training_step': 1.8205868088793673, 'env_runner_sampling_timer': 1.1429532887978089, 'learner_update_timer': 0.6755187623295116, 'synch_weights': 0.0010092033098800894, 'synch_env_connectors': 0.0009122411895180109}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -29.244140990971854, 'agent_0': -28.970390990971854, 'agent_1': -29.211640990971855}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.33428030271921), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 709, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06538191432357947), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.276930779782257e-07), 'module_to_agent_unmapping': np.float64(2.136174350578993e-06), 'get_actions': np.float64(6.610526222821799e-05), 'normalize_and_clip_actions': np.float64(1.4901962148790382e-05), 'tensor_to_numpy': np.float64(2.5547271009306005e-05), 'un_batch_to_individual_items': np.float64(1.1513713918597243e-05), 'listify_data_for_vector_env': np.float64(5.247112198796875e-06)}}, 'connector_pipeline_timer': np.float64(0.00016554888745862594)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 35498, 'agent_0': 34133, 'agent_1': 35499}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 102400, 'episode_return_mean': -87.42617297291561, 'env_to_module_sum_episodes_length_out': np.float64(32.33428030271921), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -127.56570830382633, 'weights_seq_no': 49.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(8.034450136593418e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.734964517154026e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4744770359806009e-05), 'numpy_to_tensor': np.float64(1.3263701512798624e-05), 'add_states_from_episodes_to_batch': np.float64(3.089432196752782e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.305595210845325e-06), 'batch_individual_items': np.float64(8.709724584307908e-06)}}}, 'episode_return_max': -51.509651329944305, 'episode_duration_sec_mean': 0.03718242424750045, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.048470200936086866), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.554231034927391e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 105130}, 'module_episode_returns_mean': {'shared_policy': -41.17727722083897}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.2084558513455534e-05), 'num_episodes_lifetime': 1365, 'num_env_steps_sampled_lifetime_throughput': 1095.6398982430408}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(3.743285), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0037409829), 'num_module_steps_trained': 21888, 'vf_explained_var': np.float32(-0.1206975), 'total_loss': np.float32(6.767703), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0081301), 'weights_seq_no': 50.0, 'policy_loss': np.float32(0.013001791), 'vf_loss_unclipped': np.float32(110.880295), 'curr_kl_coeff': 1.77635686587003e-16, 'entropy': np.float32(1.5373683), 'num_module_steps_trained_lifetime': 1090048, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.770075), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027949448176681827, 'add_one_ts_to_episodes_and_truncate': 0.0074362268140407625, 'agent_to_module_mapping': 0.0018602978260099272, 'add_observations_from_episodes_to_batch': 0.0008109347330246855, 'add_states_from_episodes_to_batch': 5.61935314304953e-06, 'numpy_to_tensor': 0.0003449108976416131, 'batch_individual_items': 0.019600689275941503, 'add_time_dim_to_batch_and_zero_pad': 1.4510112291578598e-05, 'general_advantage_estimation': 0.008728031029317011}}, 'connector_pipeline_timer': 0.06695200554137559}, 'num_module_steps_trained': 21888, 'num_env_steps_trained': 350208, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 1090048, 'num_env_steps_trained_lifetime': 17440768, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 102400, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1095.6398982430408, 'done': False, 'training_iteration': 50, 'trial_id': 'default', 'date': '2025-05-29_16-36-27', 'timestamp': 1748529387, 'time_this_iter_s': 1.85760498046875, 'time_total_s': 90.32487320899963, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 90.32487320899963, 'iterations_since_restore': 50, 'perf': {'cpu_util_percent': np.float64(29.85), 'ram_util_percent': np.float64(81.75)}}
Checkpoint saved at TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/Users/tegan/ray_results/simple_spread_rllib), metrics={'timers': {'training_iteration': 1.8207123414809039, 'restore_env_runners': 8.076374680446647e-06, 'training_step': 1.8205868088793673, 'env_runner_sampling_timer': 1.1429532887978089, 'learner_update_timer': 0.6755187623295116, 'synch_weights': 0.0010092033098800894, 'synch_env_connectors': 0.0009122411895180109}, 'env_runners': {'agent_episode_returns_mean': {'agent_2': -29.244140990971854, 'agent_0': -28.970390990971854, 'agent_1': -29.211640990971855}, 'num_env_steps_sampled': 2048, 'env_to_module_sum_episodes_length_in': np.float64(32.33428030271921), 'agent_steps': {'agent_1': 25.0, 'agent_2': 25.0, 'agent_0': 25.0}, 'num_agent_steps_sampled': {'agent_1': 710, 'agent_2': 709, 'agent_0': 683}, 'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(1.0917000000887356e-05), 'batch_individual_items': np.float64(1.7958000000817265e-05), 'numpy_to_tensor': np.float64(2.3458000001141954e-05), 'add_observations_from_episodes_to_batch': np.float64(2.595800000015913e-05), 'agent_to_module_mapping': np.float64(4.290999999767564e-06), 'add_states_from_episodes_to_batch': np.float64(5.707999999771118e-06)}}, 'sample': np.float64(0.06538191432357947), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(9.276930779782257e-07), 'module_to_agent_unmapping': np.float64(2.136174350578993e-06), 'get_actions': np.float64(6.610526222821799e-05), 'normalize_and_clip_actions': np.float64(1.4901962148790382e-05), 'tensor_to_numpy': np.float64(2.5547271009306005e-05), 'un_batch_to_individual_items': np.float64(1.1513713918597243e-05), 'listify_data_for_vector_env': np.float64(5.247112198796875e-06)}}, 'connector_pipeline_timer': np.float64(0.00016554888745862594)}, 'num_agent_steps_sampled_lifetime': {'agent_2': 35498, 'agent_0': 34133, 'agent_1': 35499}, 'env_reset_timer': np.float64(9.508299999971825e-05), 'connector_pipeline_timer': np.float64(0.0002429590000012638), 'num_env_steps_sampled_lifetime': 102400, 'episode_return_mean': -87.42617297291561, 'env_to_module_sum_episodes_length_out': np.float64(32.33428030271921), 'num_module_steps_sampled': {'shared_policy': 2102}, 'episode_return_min': -127.56570830382633, 'weights_seq_no': 49.0, 'env_to_module_connector': {'connector_pipeline_timer': np.float64(8.034450136593418e-05), 'timers': {'connectors': {'agent_to_module_mapping': np.float64(2.734964517154026e-06), 'add_observations_from_episodes_to_batch': np.float64(1.4744770359806009e-05), 'numpy_to_tensor': np.float64(1.3263701512798624e-05), 'add_states_from_episodes_to_batch': np.float64(3.089432196752782e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.305595210845325e-06), 'batch_individual_items': np.float64(8.709724584307908e-06)}}}, 'episode_return_max': -51.509651329944305, 'episode_duration_sec_mean': 0.03718242424750045, 'episode_len_max': 75, 'time_between_sampling': np.float64(0.048470200936086866), 'episode_len_mean': 75.0, 'num_episodes': 27, 'env_step_timer': np.float64(7.554231034927391e-05), 'num_module_steps_sampled_lifetime': {'shared_policy': 105130}, 'module_episode_returns_mean': {'shared_policy': -41.17727722083897}, 'episode_len_min': 75, 'rlmodule_inference_timer': np.float64(5.2084558513455534e-05), 'num_episodes_lifetime': 1365, 'num_env_steps_sampled_lifetime_throughput': 1095.6398982430408}, 'learners': {'shared_policy': {'gradients_default_optimizer_global_norm': np.float32(3.743285), 'curr_entropy_coeff': 0.01, 'mean_kl_loss': np.float32(0.0037409829), 'num_module_steps_trained': 21888, 'vf_explained_var': np.float32(-0.1206975), 'total_loss': np.float32(6.767703), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0081301), 'weights_seq_no': 50.0, 'policy_loss': np.float32(0.013001791), 'vf_loss_unclipped': np.float32(110.880295), 'curr_kl_coeff': 1.77635686587003e-16, 'entropy': np.float32(1.5373683), 'num_module_steps_trained_lifetime': 1090048, 'module_train_batch_size_mean': 128.0, 'vf_loss': np.float32(6.770075), 'num_trainable_parameters': 142854.0, 'default_optimizer_learning_rate': 0.0005}, '__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.027949448176681827, 'add_one_ts_to_episodes_and_truncate': 0.0074362268140407625, 'agent_to_module_mapping': 0.0018602978260099272, 'add_observations_from_episodes_to_batch': 0.0008109347330246855, 'add_states_from_episodes_to_batch': 5.61935314304953e-06, 'numpy_to_tensor': 0.0003449108976416131, 'batch_individual_items': 0.019600689275941503, 'add_time_dim_to_batch_and_zero_pad': 1.4510112291578598e-05, 'general_advantage_estimation': 0.008728031029317011}}, 'connector_pipeline_timer': 0.06695200554137559}, 'num_module_steps_trained': 21888, 'num_env_steps_trained': 350208, 'learner_connector_sum_episodes_length_out': 2048.0, 'num_module_steps_trained_lifetime': 1090048, 'num_env_steps_trained_lifetime': 17440768, 'num_trainable_parameters': 142854.0, 'num_non_trainable_parameters': 0.0, 'learner_connector_sum_episodes_length_in': 2048.0, 'num_env_steps_trained_lifetime_throughput': 0.0}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 102400, 'fault_tolerance': {'num_healthy_workers': 1, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 1095.6398982430408, 'done': False, 'training_iteration': 50, 'trial_id': 'default', 'date': '2025-05-29_16-36-27', 'timestamp': 1748529387, 'time_this_iter_s': 1.85760498046875, 'time_total_s': 90.32487320899963, 'pid': 22674, 'hostname': 'Tegans-MacBook-Air.local', 'node_ip': '127.0.0.1', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'aot_eager', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'aot_eager', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'simple_spread_pz', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 1, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 128, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 2048, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [64, 64], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function policy_mapping_fn at 0x16be018b0>, 'policies_to_train': ['shared_policy'], 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': True, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'clip_param': 0.1, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'shared_policy': (None, Box(-inf, inf, (18,), float32), Discrete(5), {})}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 90.32487320899963, 'iterations_since_restore': 50, 'perf': {'cpu_util_percent': np.float64(29.85), 'ram_util_percent': np.float64(81.75)}})
Training finished.

--- Starting RLlib Evaluation ---
Running evaluation for 5 episodes...

--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---

Episode 1 finished with total reward: -53.90

--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---

Episode 2 finished with total reward: -61.87

--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---

Episode 3 finished with total reward: -43.74

--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 2
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 2
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 2
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 2
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 2
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 2
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 1
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---

Episode 4 finished with total reward: -39.96

--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_0'
    Action: 3
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_1'
    Action: 0
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---


--- Inspecting 'actions' variable before env.step ---
Type of actions: <class 'dict'>
Actions is a dictionary (multi-agent actions). Contents:
  Agent ID: 'agent_2'
    Action: 4
    Action Type: <class 'numpy.int64'>
    Is Scalar: True
--------------------
--- End of 'actions' inspection ---

Episode 5 finished with total reward: -58.03
